{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlp_mixer_pytorch in /beegfs/tlehella/anaconda3/lib/python3.9/site-packages (0.1.1)\n",
      "Requirement already satisfied: torch>=1.6 in /beegfs/tlehella/anaconda3/lib/python3.9/site-packages (from mlp_mixer_pytorch) (1.13.0)\n",
      "Requirement already satisfied: einops>=0.3 in /beegfs/tlehella/anaconda3/lib/python3.9/site-packages (from mlp_mixer_pytorch) (0.6.0)\n",
      "Requirement already satisfied: typing_extensions in /beegfs/tlehella/anaconda3/lib/python3.9/site-packages (from torch>=1.6->mlp_mixer_pytorch) (4.1.1)\n",
      "device : cuda\n"
     ]
    }
   ],
   "source": [
    "!pip install mlp_mixer_pytorch\n",
    "import os\n",
    "os.chdir(\"/home/tlehella/rotor_checkmate/\")\n",
    "import torch\n",
    "import pgb\n",
    "from exp_utils import test_pgb\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device : {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93e06214",
   "metadata": {},
   "source": [
    "## -> GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from example_modules import GPT2\n",
    "\n",
    "mod_gpt2 = GPT2(nlayers=8,dropout=0)\n",
    "mod_gpt2.to(device)\n",
    "input_gpt2 = torch.randint(5400,(100,20),device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated all the graphs !\n",
      "\n",
      "Equiv classes are : [[0], [1, 2, 3, 4, 5, 6, 7], [8], [9]]\n",
      "So we have only 4 blocks to solve ILP on, instead of 10\n",
      "\n",
      "CONCERNING K_graph_list :\n",
      "10 K_graphs in seq, with :\n",
      "8+25+25+25+25+25+25+25+25+3 = 211 Comp nodes\n",
      "7+28+28+28+28+28+28+28+29+3 = 235 Data nodes\n",
      "=> total of 446 nodes\n",
      "\n",
      "CONCERNING phantoms impossible to restore :\n",
      "Total nb of special phantoms :  0\n"
     ]
    }
   ],
   "source": [
    "import warnings ; warnings.filterwarnings(\"ignore\")\n",
    "pgb_on_gpt2 = test_pgb(mod_gpt2,input_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mod_gpt2,input_gpt2,pgb_on_gpt2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93e06214",
   "metadata": {},
   "source": [
    "## -> Resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet101\n",
    "\n",
    "mod_resnet101 = resnet101()\n",
    "mod_resnet101.to(device)\n",
    "input_resnet101 = torch.randn((100,3,100,100),device=device,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated all the graphs !\n",
      "\n",
      "Equiv classes are : [[0], [1], [2], [3], [4, 5], [6], [7, 8, 9], [10], [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], [33], [34, 35], [36], [37]]\n",
      "So we have only 13 blocks to solve ILP on, instead of 38\n",
      "\n",
      "CONCERNING K_graph_list :\n",
      "38 K_graphs in seq, with :\n",
      "3+3+3+17+13+13+17+13+13+13+17+13+13+13+13+13+13+13+13+13+13+13+13+13+13+13+13+13+13+13+13+13+13+17+13+13+3+3 = 460 Comp nodes\n",
      "2+2+3+17+12+12+17+12+12+12+17+12+12+12+12+12+12+12+12+12+12+12+12+12+12+12+12+12+12+12+12+12+12+17+12+12+2+3 = 428 Data nodes\n",
      "=> total of 888 nodes\n",
      "\n",
      "CONCERNING phantoms impossible to restore :\n",
      "Total nb of special phantoms :  0\n"
     ]
    }
   ],
   "source": [
    "import warnings ; warnings.filterwarnings(\"ignore\")\n",
    "pgb_on_resnet101 = test_pgb(mod_resnet101,input_resnet101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mod_resnet101,input_resnet101,pgb_on_resnet101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> MLP Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp_mixer_pytorch import MLPMixer\n",
    "\n",
    "mod_MLP = MLPMixer(\n",
    "    image_size = 256,\n",
    "    channels = 3,\n",
    "    patch_size = 16,\n",
    "    dim = 512,\n",
    "    depth = 12,\n",
    "    num_classes = 1000\n",
    ")\n",
    "mod_MLP.to(device)\n",
    "\n",
    "input_MLP = torch.randn(1, 3, 256, 256,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated all the graphs !\n",
      "\n",
      "Equiv classes are : [[0], [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23], [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22], [24], [25], [26]]\n",
      "So we have only 6 blocks to solve ILP on, instead of 27\n",
      "\n",
      "CONCERNING K_graph_list :\n",
      "27 K_graphs in seq, with :\n",
      "4+11+11+11+11+11+11+11+11+11+11+11+11+11+11+11+11+11+11+11+11+11+11+11+11+3+3 = 274 Comp nodes\n",
      "3+11+13+11+13+11+13+11+13+11+13+11+13+11+13+11+13+11+13+11+13+11+13+11+14+2+3 = 297 Data nodes\n",
      "=> total of 571 nodes\n",
      "\n",
      "CONCERNING phantoms impossible to restore :\n",
      "Total nb of special phantoms :  0\n"
     ]
    }
   ],
   "source": [
    "import warnings ; warnings.filterwarnings(\"ignore\")\n",
    "pgb_on_MLP = test_pgb(mod_MLP,input_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mod_MLP,input_MLP,pgb_on_MLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> RegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import regnet_x_32gf\n",
    "\n",
    "mod_regnet32 = regnet_x_32gf()\n",
    "mod_regnet32.to(device)\n",
    "\n",
    "input_regnet32 = torch.randn(1, 3, 224, 224,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated all the graphs !\n",
      "\n",
      "Equiv classes are : [[0], [1], [2], [3], [4], [5, 6, 7, 8, 9, 10], [11], [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], [24], [25], [26]]\n",
      "So we have only 11 blocks to solve ILP on, instead of 27\n",
      "\n",
      "CONCERNING K_graph_list :\n",
      "27 K_graphs in seq, with :\n",
      "3+3+19+15+19+15+15+15+15+15+15+19+15+15+15+15+15+15+15+15+15+15+15+15+19+3+3 = 373 Comp nodes\n",
      "2+2+20+15+20+15+15+15+15+15+15+20+15+15+15+15+15+15+15+15+15+15+15+15+20+2+3 = 374 Data nodes\n",
      "=> total of 747 nodes\n",
      "\n",
      "CONCERNING phantoms impossible to restore :\n",
      "Total nb of special phantoms :  0\n"
     ]
    }
   ],
   "source": [
    "import warnings ; warnings.filterwarnings(\"ignore\")\n",
    "pgb_on_regnet32 = test_pgb(mod_regnet32,input_regnet32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mod_regnet32,input_regnet32,pgb_on_regnet32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac941e8de4770c351ec8aa5bb342c24e4201410dfd46cbc3d9b5be6c94f8ee8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
