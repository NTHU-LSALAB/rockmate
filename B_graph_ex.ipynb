{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c044db-f13a-4ef1-8d35-12c1b2fdcb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import read_trace_code\n",
    "import tools_on_B_graph as Btools\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c623a-c360-49d5-98e1-ae95177f3a53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test on mymod :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52ce50ca-6a8a-4f37-adc9-cd305b6e99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubMod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential (\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,512),\n",
    "        )\n",
    "    \n",
    "    def forward(self,p1,p2,p3):\n",
    "        y1 = self.linear_stack(p1)\n",
    "        y2 = self.linear_stack(p2)\n",
    "        y3 = self.linear_stack(p3)\n",
    "        return y1+y2,y1-y2+y3,y1\n",
    "\n",
    "class MyMod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.op = SubMod()\n",
    "    def forward(self,x):\n",
    "        (z1,z2,z3) = self.op(x,-x,p3=torch.ones_like(x))\n",
    "        return z1 + 2*z3 + z2*x.size(-1)\n",
    "\n",
    "mymod = MyMod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8a1263a-3fba-4547-9c6f-018d227fbc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== MYMOD =====\n",
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  op = self.op\n",
      "  input = torch.neg(x)\n",
      "  input0 = torch.ones_like(x, dtype=6, layout=0, device=torch.device(\"cpu\"), pin_memory=False)\n",
      "  _0, _1, _2, = (op).forward(x, input, input0, )\n",
      "  _3 = torch.add(_1, torch.mul(_0, CONSTANTS.c0))\n",
      "  _4 = ops.prim.NumToTensor(torch.size(x, -1))\n",
      "  return torch.add(_3, torch.mul(_2, _4))\n",
      "\n",
      "===== SUB CODE : self.op.forward =====\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    input: Tensor,\n",
      "    input0: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
      "  linear_stack = self.linear_stack\n",
      "  _0 = (linear_stack).forward(x, )\n",
      "  _1 = (linear_stack).forward1(input, )\n",
      "  _2 = (linear_stack).forward2(input0, )\n",
      "  z1 = torch.add(_0, _1)\n",
      "  z2 = torch.add(torch.sub(_0, _1), _2)\n",
      "  return (_0, z1, z2)\n",
      "\n",
      "===== SUB SUB CODE =====\n",
      "def forward1(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  _1 = getattr(self, \"1\")\n",
      "  _0 = getattr(self, \"0\")\n",
      "  _2 = (_1).forward1((_0).forward1(input, ), )\n",
      "  return _2\n",
      "\n",
      "===== SUB SUB SUB CODE =====\n",
      "== to debug : getattr(self.op.linear_stack,\"1\").forward2 ==\n",
      "def forward2(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  bias = self.bias\n",
      "  weight = self.weight\n",
      "  y3 = torch.linear(argument_1, weight, bias)\n",
      "  return y3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_mymod = torch.rand((128))\n",
    "script_mymod = torch.jit.trace_module(mymod, {'forward': (src_mymod,)},check_trace=False)\n",
    "print(\"===== MYMOD =====\")\n",
    "print(script_mymod.forward.code)\n",
    "\n",
    "print(\"===== SUB CODE : self.op.forward =====\")\n",
    "print(script_mymod.op.code)\n",
    "\n",
    "print(\"===== SUB SUB CODE =====\")\n",
    "print(script_mymod.op.linear_stack.forward1.code)\n",
    "\n",
    "print(\"===== SUB SUB SUB CODE =====\")\n",
    "print(\"== to debug : getattr(self.op.linear_stack,\\\"1\\\").forward2 ==\")\n",
    "print(getattr(script_mymod.op.linear_stack,\"1\").forward2.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10c08759-bec7-4227-b6de-6375fa19dffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def main(x):\n",
      "\t__10_fv = torch.relu(x)\n",
      "\t__13_y1 = torch.nn.functional.linear(__10_fv,self.op.linear_stack[1].weight,self.op.linear_stack[1].bias)\n",
      "\t__2_input = torch.neg(x)\n",
      "\t__18_fv = torch.relu(__2_input)\n",
      "\t__21_y2 = torch.nn.functional.linear(__18_fv,self.op.linear_stack[1].weight,self.op.linear_stack[1].bias)\n",
      "\t__30_z1 = torch.add(__13_y1,__21_y2)\n",
      "\t__32_fv = torch.sub(__13_y1,__21_y2)\n",
      "\t__4_fv = torch.device(\"cpu\")\n",
      "\t__3_input0 = torch.ones_like(x,device = __4_fv,pin_memory = False)\n",
      "\t__26_fv = torch.relu(__3_input0)\n",
      "\t__29_y3 = torch.nn.functional.linear(__26_fv,self.op.linear_stack[1].weight,self.op.linear_stack[1].bias)\n",
      "\t__31_z2 = torch.add(__32_fv,__29_y3)\n",
      "\t__33_fv = (__13_y1,__30_z1,__31_z2)\n",
      "\t__35__1 = __33_fv[1]\n",
      "\t__34__0 = __33_fv[0]\n",
      "\t__38_fv = torch.mul(__34__0,tensor(2))\n",
      "\t__37__3 = torch.add(__35__1,__38_fv)\n",
      "\t__36__2 = __33_fv[2]\n",
      "\t__39__4 = torch.Tensor.size(x,-1)\n",
      "\t__40_fv = torch.mul(__36__2,__39__4)\n",
      "\t__41_fv = torch.add(__37__3,__40_fv)\n",
      "\treturn __41_fv\n"
     ]
    }
   ],
   "source": [
    "reload(read_trace_code)\n",
    "reload(Btools)\n",
    "mymod_Bg = read_trace_code.main(mymod,(src_mymod,))\n",
    "mymod_Dg = Btools.B_to_D(mymod_Bg)\n",
    "Btools.print_code(mymod_Dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46788840-e78c-4da6-a5df-c9ea2f96d451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Original module ==\n",
      "tensor([ 109.5877,  -16.9878, -108.7730,   90.9153, -121.8676,  -25.9335,\n",
      "         153.3468,  -78.8924,   31.2294,  136.2355], grad_fn=<SliceBackward0>)\n",
      "== Through D_graph ==\n",
      "tensor([ 109.5877,  -16.9878, -108.7730,   90.9153, -121.8676,  -25.9335,\n",
      "         153.3468,  -78.8924,   31.2294,  136.2355], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "reload(Btools)\n",
    "print(\"== Original module ==\")\n",
    "print(mymod(src_mymod)[:10])\n",
    "print(\"== Through D_graph ==\")\n",
    "print(Btools.test_code(mymod_Dg,mymod,{\"x\":src_mymod})[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83f8b8-dbcc-43f1-bdee-88580e64a0e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test on torch.nn.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f8989c-fd89-4f87-a903-739c1f7a62d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In self.forward try to sub open self.encoder.forward\n",
      "In self.encoder.forward try to sub open self.encoder.layers[0].forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].self_attn.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].dropout1.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].norm1.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].linear1.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].dropout.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].linear2.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].dropout2.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].norm2.forward\n",
      "In self.encoder.forward try to sub open self.encoder.norm.forward\n",
      "In self.forward try to sub open self.decoder.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[0].forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].self_attn.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].dropout1.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].norm1.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].multihead_attn.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].dropout2.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].norm2.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].linear1.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].dropout.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].linear2.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].dropout3.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[1].forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].self_attn.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].dropout1.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].norm1.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].multihead_attn.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].dropout2.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].norm2.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].linear1.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].dropout.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].linear2.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].dropout3.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[2].forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].self_attn.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].dropout1.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].norm1.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].multihead_attn.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].dropout2.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].norm2.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].linear1.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].dropout.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].linear2.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].dropout3.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[3].forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].self_attn.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].dropout1.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].norm1.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].multihead_attn.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].dropout2.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].norm2.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].linear1.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].dropout.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].linear2.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].dropout3.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[4].forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].self_attn.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].dropout1.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].norm1.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].multihead_attn.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].dropout2.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].norm2.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].linear1.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].dropout.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].linear2.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].dropout3.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[5].forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].self_attn.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].dropout1.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].norm1.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].multihead_attn.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].dropout2.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].norm2.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].linear1.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].dropout.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].linear2.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].dropout3.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.norm.forward\n",
      "def main(tgt,src):\n",
      "\t__135__7 = torch.nn.functional.linear(tgt,self.decoder.layers[0].self_attn.in_proj_weight,self.decoder.layers[0].self_attn.in_proj_bias)\n",
      "\t__136_fv = torch.chunk(__135__7,3,-1)\n",
      "\t__137_q = __136_fv[0]\n",
      "\t__140__8 = torch.Tensor.contiguous(__137_q)\n",
      "\t__124_tgt_len = torch.Tensor.size(tgt,0)\n",
      "\t__127_bsz = torch.Tensor.size(tgt,1)\n",
      "\t__142_fv = torch.mul(__127_bsz,tensor(16))\n",
      "\t__129_embed_dim = torch.Tensor.size(tgt,2)\n",
      "\t__131_head_dim = torch.div(__129_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__141__9 = [__124_tgt_len,__142_fv,__131_head_dim]\n",
      "\t__144_fv = torch.Tensor.view(__140__8,__141__9)\n",
      "\t__143_q0 = torch.transpose(__144_fv,0,1)\n",
      "\t__157_q1 = torch.div(__143_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__138_k = __136_fv[1]\n",
      "\t__145__10 = torch.Tensor.contiguous(__138_k)\n",
      "\t__146__11 = torch.Tensor.size(__138_k,0)\n",
      "\t__148_fv = torch.mul(__127_bsz,tensor(16))\n",
      "\t__147__12 = [__146__11,__148_fv,__131_head_dim]\n",
      "\t__150_fv = torch.Tensor.view(__145__10,__147__12)\n",
      "\t__149_k0 = torch.transpose(__150_fv,0,1)\n",
      "\t__159_fv = torch.transpose(__149_k0,-2,-1)\n",
      "\t__158_input = torch.bmm(__157_q1,__159_fv)\n",
      "\t__160_input0 = torch.softmax(__158_input,-1)\n",
      "\t__161_attn = torch.dropout(__160_input0,0.1,True)\n",
      "\t__139_v = __136_fv[2]\n",
      "\t__151__13 = torch.Tensor.contiguous(__139_v)\n",
      "\t__152__14 = torch.Tensor.size(__139_v,0)\n",
      "\t__154_fv = torch.mul(__127_bsz,tensor(16))\n",
      "\t__153__15 = [__152__14,__154_fv,__131_head_dim]\n",
      "\t__156_fv = torch.Tensor.view(__151__13,__153__15)\n",
      "\t__155_v0 = torch.transpose(__156_fv,0,1)\n",
      "\t__162_attn_output = torch.bmm(__161_attn,__155_v0)\n",
      "\t__164_fv = torch.transpose(__162_attn_output,0,1)\n",
      "\t__163__16 = torch.Tensor.contiguous(__164_fv)\n",
      "\t__166_fv = [__124_tgt_len,__127_bsz,__129_embed_dim]\n",
      "\t__165_attn_output0 = torch.Tensor.view(__163__16,__166_fv)\n",
      "\t__167_input1 = torch.nn.functional.linear(__165_attn_output0,self.decoder.layers[0].self_attn.out_proj.weight,self.decoder.layers[0].self_attn.out_proj.bias)\n",
      "\t__168__0 = torch.dropout(__167_input1,0.1,True)\n",
      "\t__169_input = torch.add(tgt,__168__0)\n",
      "\t__174_fv = [512]\n",
      "\t__173_query = torch.layer_norm(__169_input,__174_fv,self.decoder.layers[0].norm1.weight,self.decoder.layers[0].norm1.bias)\n",
      "\t__193_E = torch.Tensor.size(__173_query,-1)\n",
      "\t__196_fv = torch.mul(__193_E,tensor(2))\n",
      "\t__195__8 = [__193_E,__196_fv]\n",
      "\t__197__9 = torch.split_with_sizes(self.decoder.layers[0].multihead_attn.in_proj_weight,__195__8)\n",
      "\t__199_w_q = __197__9[0]\n",
      "\t__203_fv = torch.mul(__193_E,tensor(2))\n",
      "\t__202_fv = [__193_E,__203_fv]\n",
      "\t__201__10 = torch.split_with_sizes(self.decoder.layers[0].multihead_attn.in_proj_bias,__202_fv)\n",
      "\t__205_b_q = __201__10[0]\n",
      "\t__207_q = torch.nn.functional.linear(__173_query,__199_w_q,__205_b_q)\n",
      "\t__213_q0 = torch.Tensor.contiguous(__207_q)\n",
      "\t__182_tgt_len = torch.Tensor.size(__173_query,0)\n",
      "\t__185_bsz = torch.Tensor.size(__173_query,1)\n",
      "\t__215_fv = torch.mul(__185_bsz,tensor(16))\n",
      "\t__187_embed_dim = torch.Tensor.size(__173_query,2)\n",
      "\t__189_head_dim = torch.div(__187_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__214__12 = [__182_tgt_len,__215_fv,__189_head_dim]\n",
      "\t__217_fv = torch.Tensor.view(__213_q0,__214__12)\n",
      "\t__216_q1 = torch.transpose(__217_fv,0,1)\n",
      "\t__230_q2 = torch.div(__216_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__33__7 = torch.nn.functional.linear(src,self.encoder.layers[0].self_attn.in_proj_weight,self.encoder.layers[0].self_attn.in_proj_bias)\n",
      "\t__34_fv = torch.chunk(__33__7,3,-1)\n",
      "\t__35_q = __34_fv[0]\n",
      "\t__38__8 = torch.Tensor.contiguous(__35_q)\n",
      "\t__22_tgt_len = torch.Tensor.size(src,0)\n",
      "\t__25_bsz = torch.Tensor.size(src,1)\n",
      "\t__40_fv = torch.mul(__25_bsz,tensor(16))\n",
      "\t__27_embed_dim = torch.Tensor.size(src,2)\n",
      "\t__29_head_dim = torch.div(__27_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__39__9 = [__22_tgt_len,__40_fv,__29_head_dim]\n",
      "\t__42_fv = torch.Tensor.view(__38__8,__39__9)\n",
      "\t__41_q0 = torch.transpose(__42_fv,0,1)\n",
      "\t__55_q1 = torch.div(__41_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__36_k = __34_fv[1]\n",
      "\t__43__10 = torch.Tensor.contiguous(__36_k)\n",
      "\t__44__11 = torch.Tensor.size(__36_k,0)\n",
      "\t__46_fv = torch.mul(__25_bsz,tensor(16))\n",
      "\t__45__12 = [__44__11,__46_fv,__29_head_dim]\n",
      "\t__48_fv = torch.Tensor.view(__43__10,__45__12)\n",
      "\t__47_k0 = torch.transpose(__48_fv,0,1)\n",
      "\t__57_fv = torch.transpose(__47_k0,-2,-1)\n",
      "\t__56_input = torch.bmm(__55_q1,__57_fv)\n",
      "\t__58_input0 = torch.softmax(__56_input,-1)\n",
      "\t__59_attn = torch.dropout(__58_input0,0.1,True)\n",
      "\t__37_v = __34_fv[2]\n",
      "\t__49__13 = torch.Tensor.contiguous(__37_v)\n",
      "\t__50__14 = torch.Tensor.size(__37_v,0)\n",
      "\t__52_fv = torch.mul(__25_bsz,tensor(16))\n",
      "\t__51__15 = [__50__14,__52_fv,__29_head_dim]\n",
      "\t__54_fv = torch.Tensor.view(__49__13,__51__15)\n",
      "\t__53_v0 = torch.transpose(__54_fv,0,1)\n",
      "\t__60_attn_output = torch.bmm(__59_attn,__53_v0)\n",
      "\t__62_fv = torch.transpose(__60_attn_output,0,1)\n",
      "\t__61__16 = torch.Tensor.contiguous(__62_fv)\n",
      "\t__64_fv = [__22_tgt_len,__25_bsz,__27_embed_dim]\n",
      "\t__63_attn_output0 = torch.Tensor.view(__61__16,__64_fv)\n",
      "\t__65_input1 = torch.nn.functional.linear(__63_attn_output0,self.encoder.layers[0].self_attn.out_proj.weight,self.encoder.layers[0].self_attn.out_proj.bias)\n",
      "\t__66__0 = torch.dropout(__65_input1,0.1,True)\n",
      "\t__67_input = torch.add(src,__66__0)\n",
      "\t__72_fv = [512]\n",
      "\t__71_input0 = torch.layer_norm(__67_input,__72_fv,self.encoder.layers[0].norm1.weight,self.encoder.layers[0].norm1.bias)\n",
      "\t__76_input = torch.nn.functional.linear(__71_input0,self.encoder.layers[0].linear1.weight,self.encoder.layers[0].linear1.bias)\n",
      "\t__73_input0 = torch.relu(__76_input)\n",
      "\t__78_input0 = torch.dropout(__73_input0,0.1,True)\n",
      "\t__81_input = torch.nn.functional.linear(__78_input0,self.encoder.layers[0].linear2.weight,self.encoder.layers[0].linear2.bias)\n",
      "\t__83__0 = torch.dropout(__81_input,0.1,True)\n",
      "\t__82_input1 = torch.add(__71_input0,__83__0)\n",
      "\t__87_fv = [512]\n",
      "\t__86_input0 = torch.layer_norm(__82_input1,__87_fv,self.encoder.layers[0].norm2.weight,self.encoder.layers[0].norm2.bias)\n",
      "\t__91_fv = [512]\n",
      "\t__90_key = torch.layer_norm(__86_input0,__91_fv,self.encoder.norm.weight,self.encoder.norm.bias)\n",
      "\t__200_w_kv = __197__9[1]\n",
      "\t__206_b_kv = __201__10[1]\n",
      "\t__209_fv = torch.nn.functional.linear(__90_key,__200_w_kv,__206_b_kv)\n",
      "\t__208__11 = torch.chunk(__209_fv,2,-1)\n",
      "\t__211_k = __208__11[0]\n",
      "\t__218__13 = torch.Tensor.contiguous(__211_k)\n",
      "\t__219__14 = torch.Tensor.size(__211_k,0)\n",
      "\t__221_fv = torch.mul(__185_bsz,tensor(16))\n",
      "\t__220__15 = [__219__14,__221_fv,__189_head_dim]\n",
      "\t__223_fv = torch.Tensor.view(__218__13,__220__15)\n",
      "\t__222_k0 = torch.transpose(__223_fv,0,1)\n",
      "\t__232_fv = torch.transpose(__222_k0,-2,-1)\n",
      "\t__231_input = torch.bmm(__230_q2,__232_fv)\n",
      "\t__233_input0 = torch.softmax(__231_input,-1)\n",
      "\t__234_attn = torch.dropout(__233_input0,0.1,True)\n",
      "\t__212_v = __208__11[1]\n",
      "\t__224__16 = torch.Tensor.contiguous(__212_v)\n",
      "\t__225__17 = torch.Tensor.size(__212_v,0)\n",
      "\t__227_fv = torch.mul(__185_bsz,tensor(16))\n",
      "\t__226__18 = [__225__17,__227_fv,__189_head_dim]\n",
      "\t__229_fv = torch.Tensor.view(__224__16,__226__18)\n",
      "\t__228_v0 = torch.transpose(__229_fv,0,1)\n",
      "\t__235_attn_output = torch.bmm(__234_attn,__228_v0)\n",
      "\t__237_fv = torch.transpose(__235_attn_output,0,1)\n",
      "\t__236__19 = torch.Tensor.contiguous(__237_fv)\n",
      "\t__239_fv = [__182_tgt_len,__185_bsz,__187_embed_dim]\n",
      "\t__238_attn_output0 = torch.Tensor.view(__236__19,__239_fv)\n",
      "\t__240_input1 = torch.nn.functional.linear(__238_attn_output0,self.decoder.layers[0].multihead_attn.out_proj.weight,self.decoder.layers[0].multihead_attn.out_proj.bias)\n",
      "\t__242__0 = torch.dropout(__240_input1,0.1,True)\n",
      "\t__241_input0 = torch.add(__173_query,__242__0)\n",
      "\t__247_fv = [512]\n",
      "\t__246_input0 = torch.layer_norm(__241_input0,__247_fv,self.decoder.layers[0].norm2.weight,self.decoder.layers[0].norm2.bias)\n",
      "\t__251_input = torch.nn.functional.linear(__246_input0,self.decoder.layers[0].linear1.weight,self.decoder.layers[0].linear1.bias)\n",
      "\t__248_input1 = torch.relu(__251_input)\n",
      "\t__253_input0 = torch.dropout(__248_input1,0.1,True)\n",
      "\t__256_input = torch.nn.functional.linear(__253_input0,self.decoder.layers[0].linear2.weight,self.decoder.layers[0].linear2.bias)\n",
      "\t__258__0 = torch.dropout(__256_input,0.1,True)\n",
      "\t__257_input2 = torch.add(__246_input0,__258__0)\n",
      "\t__262_fv = [512]\n",
      "\t__261_query = torch.layer_norm(__257_input2,__262_fv,self.decoder.layers[0].norm3.weight,self.decoder.layers[0].norm3.bias)\n",
      "\t__292__7 = torch.nn.functional.linear(__261_query,self.decoder.layers[1].self_attn.in_proj_weight,self.decoder.layers[1].self_attn.in_proj_bias)\n",
      "\t__293_fv = torch.chunk(__292__7,3,-1)\n",
      "\t__294_q = __293_fv[0]\n",
      "\t__297__8 = torch.Tensor.contiguous(__294_q)\n",
      "\t__281_tgt_len = torch.Tensor.size(__261_query,0)\n",
      "\t__284_bsz = torch.Tensor.size(__261_query,1)\n",
      "\t__299_fv = torch.mul(__284_bsz,tensor(16))\n",
      "\t__286_embed_dim = torch.Tensor.size(__261_query,2)\n",
      "\t__288_head_dim = torch.div(__286_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__298__9 = [__281_tgt_len,__299_fv,__288_head_dim]\n",
      "\t__301_fv = torch.Tensor.view(__297__8,__298__9)\n",
      "\t__300_q0 = torch.transpose(__301_fv,0,1)\n",
      "\t__314_q1 = torch.div(__300_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__295_k = __293_fv[1]\n",
      "\t__302__10 = torch.Tensor.contiguous(__295_k)\n",
      "\t__303__11 = torch.Tensor.size(__295_k,0)\n",
      "\t__305_fv = torch.mul(__284_bsz,tensor(16))\n",
      "\t__304__12 = [__303__11,__305_fv,__288_head_dim]\n",
      "\t__307_fv = torch.Tensor.view(__302__10,__304__12)\n",
      "\t__306_k0 = torch.transpose(__307_fv,0,1)\n",
      "\t__316_fv = torch.transpose(__306_k0,-2,-1)\n",
      "\t__315_input = torch.bmm(__314_q1,__316_fv)\n",
      "\t__317_input0 = torch.softmax(__315_input,-1)\n",
      "\t__318_attn = torch.dropout(__317_input0,0.1,True)\n",
      "\t__296_v = __293_fv[2]\n",
      "\t__308__13 = torch.Tensor.contiguous(__296_v)\n",
      "\t__309__14 = torch.Tensor.size(__296_v,0)\n",
      "\t__311_fv = torch.mul(__284_bsz,tensor(16))\n",
      "\t__310__15 = [__309__14,__311_fv,__288_head_dim]\n",
      "\t__313_fv = torch.Tensor.view(__308__13,__310__15)\n",
      "\t__312_v0 = torch.transpose(__313_fv,0,1)\n",
      "\t__319_attn_output = torch.bmm(__318_attn,__312_v0)\n",
      "\t__321_fv = torch.transpose(__319_attn_output,0,1)\n",
      "\t__320__16 = torch.Tensor.contiguous(__321_fv)\n",
      "\t__323_fv = [__281_tgt_len,__284_bsz,__286_embed_dim]\n",
      "\t__322_attn_output0 = torch.Tensor.view(__320__16,__323_fv)\n",
      "\t__324_input1 = torch.nn.functional.linear(__322_attn_output0,self.decoder.layers[1].self_attn.out_proj.weight,self.decoder.layers[1].self_attn.out_proj.bias)\n",
      "\t__325__0 = torch.dropout(__324_input1,0.1,True)\n",
      "\t__326_input = torch.add(__261_query,__325__0)\n",
      "\t__331_fv = [512]\n",
      "\t__330_query = torch.layer_norm(__326_input,__331_fv,self.decoder.layers[1].norm1.weight,self.decoder.layers[1].norm1.bias)\n",
      "\t__350_E = torch.Tensor.size(__330_query,-1)\n",
      "\t__353_fv = torch.mul(__350_E,tensor(2))\n",
      "\t__352__8 = [__350_E,__353_fv]\n",
      "\t__354__9 = torch.split_with_sizes(self.decoder.layers[1].multihead_attn.in_proj_weight,__352__8)\n",
      "\t__356_w_q = __354__9[0]\n",
      "\t__360_fv = torch.mul(__350_E,tensor(2))\n",
      "\t__359_fv = [__350_E,__360_fv]\n",
      "\t__358__10 = torch.split_with_sizes(self.decoder.layers[1].multihead_attn.in_proj_bias,__359_fv)\n",
      "\t__362_b_q = __358__10[0]\n",
      "\t__364_q = torch.nn.functional.linear(__330_query,__356_w_q,__362_b_q)\n",
      "\t__370_q0 = torch.Tensor.contiguous(__364_q)\n",
      "\t__339_tgt_len = torch.Tensor.size(__330_query,0)\n",
      "\t__342_bsz = torch.Tensor.size(__330_query,1)\n",
      "\t__372_fv = torch.mul(__342_bsz,tensor(16))\n",
      "\t__344_embed_dim = torch.Tensor.size(__330_query,2)\n",
      "\t__346_head_dim = torch.div(__344_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__371__12 = [__339_tgt_len,__372_fv,__346_head_dim]\n",
      "\t__374_fv = torch.Tensor.view(__370_q0,__371__12)\n",
      "\t__373_q1 = torch.transpose(__374_fv,0,1)\n",
      "\t__387_q2 = torch.div(__373_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__357_w_kv = __354__9[1]\n",
      "\t__363_b_kv = __358__10[1]\n",
      "\t__366_fv = torch.nn.functional.linear(__90_key,__357_w_kv,__363_b_kv)\n",
      "\t__365__11 = torch.chunk(__366_fv,2,-1)\n",
      "\t__368_k = __365__11[0]\n",
      "\t__375__13 = torch.Tensor.contiguous(__368_k)\n",
      "\t__376__14 = torch.Tensor.size(__368_k,0)\n",
      "\t__378_fv = torch.mul(__342_bsz,tensor(16))\n",
      "\t__377__15 = [__376__14,__378_fv,__346_head_dim]\n",
      "\t__380_fv = torch.Tensor.view(__375__13,__377__15)\n",
      "\t__379_k0 = torch.transpose(__380_fv,0,1)\n",
      "\t__389_fv = torch.transpose(__379_k0,-2,-1)\n",
      "\t__388_input = torch.bmm(__387_q2,__389_fv)\n",
      "\t__390_input0 = torch.softmax(__388_input,-1)\n",
      "\t__391_attn = torch.dropout(__390_input0,0.1,True)\n",
      "\t__369_v = __365__11[1]\n",
      "\t__381__16 = torch.Tensor.contiguous(__369_v)\n",
      "\t__382__17 = torch.Tensor.size(__369_v,0)\n",
      "\t__384_fv = torch.mul(__342_bsz,tensor(16))\n",
      "\t__383__18 = [__382__17,__384_fv,__346_head_dim]\n",
      "\t__386_fv = torch.Tensor.view(__381__16,__383__18)\n",
      "\t__385_v0 = torch.transpose(__386_fv,0,1)\n",
      "\t__392_attn_output = torch.bmm(__391_attn,__385_v0)\n",
      "\t__394_fv = torch.transpose(__392_attn_output,0,1)\n",
      "\t__393__19 = torch.Tensor.contiguous(__394_fv)\n",
      "\t__396_fv = [__339_tgt_len,__342_bsz,__344_embed_dim]\n",
      "\t__395_attn_output0 = torch.Tensor.view(__393__19,__396_fv)\n",
      "\t__397_input1 = torch.nn.functional.linear(__395_attn_output0,self.decoder.layers[1].multihead_attn.out_proj.weight,self.decoder.layers[1].multihead_attn.out_proj.bias)\n",
      "\t__399__0 = torch.dropout(__397_input1,0.1,True)\n",
      "\t__398_input0 = torch.add(__330_query,__399__0)\n",
      "\t__404_fv = [512]\n",
      "\t__403_input0 = torch.layer_norm(__398_input0,__404_fv,self.decoder.layers[1].norm2.weight,self.decoder.layers[1].norm2.bias)\n",
      "\t__408_input = torch.nn.functional.linear(__403_input0,self.decoder.layers[1].linear1.weight,self.decoder.layers[1].linear1.bias)\n",
      "\t__405_input1 = torch.relu(__408_input)\n",
      "\t__410_input0 = torch.dropout(__405_input1,0.1,True)\n",
      "\t__413_input = torch.nn.functional.linear(__410_input0,self.decoder.layers[1].linear2.weight,self.decoder.layers[1].linear2.bias)\n",
      "\t__415__0 = torch.dropout(__413_input,0.1,True)\n",
      "\t__414_input2 = torch.add(__403_input0,__415__0)\n",
      "\t__419_fv = [512]\n",
      "\t__418_query = torch.layer_norm(__414_input2,__419_fv,self.decoder.layers[1].norm3.weight,self.decoder.layers[1].norm3.bias)\n",
      "\t__450__7 = torch.nn.functional.linear(__418_query,self.decoder.layers[2].self_attn.in_proj_weight,self.decoder.layers[2].self_attn.in_proj_bias)\n",
      "\t__451_fv = torch.chunk(__450__7,3,-1)\n",
      "\t__452_q = __451_fv[0]\n",
      "\t__455__8 = torch.Tensor.contiguous(__452_q)\n",
      "\t__439_tgt_len = torch.Tensor.size(__418_query,0)\n",
      "\t__442_bsz = torch.Tensor.size(__418_query,1)\n",
      "\t__457_fv = torch.mul(__442_bsz,tensor(16))\n",
      "\t__444_embed_dim = torch.Tensor.size(__418_query,2)\n",
      "\t__446_head_dim = torch.div(__444_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__456__9 = [__439_tgt_len,__457_fv,__446_head_dim]\n",
      "\t__459_fv = torch.Tensor.view(__455__8,__456__9)\n",
      "\t__458_q0 = torch.transpose(__459_fv,0,1)\n",
      "\t__472_q1 = torch.div(__458_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__453_k = __451_fv[1]\n",
      "\t__460__10 = torch.Tensor.contiguous(__453_k)\n",
      "\t__461__11 = torch.Tensor.size(__453_k,0)\n",
      "\t__463_fv = torch.mul(__442_bsz,tensor(16))\n",
      "\t__462__12 = [__461__11,__463_fv,__446_head_dim]\n",
      "\t__465_fv = torch.Tensor.view(__460__10,__462__12)\n",
      "\t__464_k0 = torch.transpose(__465_fv,0,1)\n",
      "\t__474_fv = torch.transpose(__464_k0,-2,-1)\n",
      "\t__473_input = torch.bmm(__472_q1,__474_fv)\n",
      "\t__475_input0 = torch.softmax(__473_input,-1)\n",
      "\t__476_attn = torch.dropout(__475_input0,0.1,True)\n",
      "\t__454_v = __451_fv[2]\n",
      "\t__466__13 = torch.Tensor.contiguous(__454_v)\n",
      "\t__467__14 = torch.Tensor.size(__454_v,0)\n",
      "\t__469_fv = torch.mul(__442_bsz,tensor(16))\n",
      "\t__468__15 = [__467__14,__469_fv,__446_head_dim]\n",
      "\t__471_fv = torch.Tensor.view(__466__13,__468__15)\n",
      "\t__470_v0 = torch.transpose(__471_fv,0,1)\n",
      "\t__477_attn_output = torch.bmm(__476_attn,__470_v0)\n",
      "\t__479_fv = torch.transpose(__477_attn_output,0,1)\n",
      "\t__478__16 = torch.Tensor.contiguous(__479_fv)\n",
      "\t__481_fv = [__439_tgt_len,__442_bsz,__444_embed_dim]\n",
      "\t__480_attn_output0 = torch.Tensor.view(__478__16,__481_fv)\n",
      "\t__482_input1 = torch.nn.functional.linear(__480_attn_output0,self.decoder.layers[2].self_attn.out_proj.weight,self.decoder.layers[2].self_attn.out_proj.bias)\n",
      "\t__483__0 = torch.dropout(__482_input1,0.1,True)\n",
      "\t__484_input = torch.add(__418_query,__483__0)\n",
      "\t__489_fv = [512]\n",
      "\t__488_query = torch.layer_norm(__484_input,__489_fv,self.decoder.layers[2].norm1.weight,self.decoder.layers[2].norm1.bias)\n",
      "\t__508_E = torch.Tensor.size(__488_query,-1)\n",
      "\t__511_fv = torch.mul(__508_E,tensor(2))\n",
      "\t__510__8 = [__508_E,__511_fv]\n",
      "\t__512__9 = torch.split_with_sizes(self.decoder.layers[2].multihead_attn.in_proj_weight,__510__8)\n",
      "\t__514_w_q = __512__9[0]\n",
      "\t__518_fv = torch.mul(__508_E,tensor(2))\n",
      "\t__517_fv = [__508_E,__518_fv]\n",
      "\t__516__10 = torch.split_with_sizes(self.decoder.layers[2].multihead_attn.in_proj_bias,__517_fv)\n",
      "\t__520_b_q = __516__10[0]\n",
      "\t__522_q = torch.nn.functional.linear(__488_query,__514_w_q,__520_b_q)\n",
      "\t__528_q0 = torch.Tensor.contiguous(__522_q)\n",
      "\t__497_tgt_len = torch.Tensor.size(__488_query,0)\n",
      "\t__500_bsz = torch.Tensor.size(__488_query,1)\n",
      "\t__530_fv = torch.mul(__500_bsz,tensor(16))\n",
      "\t__502_embed_dim = torch.Tensor.size(__488_query,2)\n",
      "\t__504_head_dim = torch.div(__502_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__529__12 = [__497_tgt_len,__530_fv,__504_head_dim]\n",
      "\t__532_fv = torch.Tensor.view(__528_q0,__529__12)\n",
      "\t__531_q1 = torch.transpose(__532_fv,0,1)\n",
      "\t__545_q2 = torch.div(__531_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__515_w_kv = __512__9[1]\n",
      "\t__521_b_kv = __516__10[1]\n",
      "\t__524_fv = torch.nn.functional.linear(__90_key,__515_w_kv,__521_b_kv)\n",
      "\t__523__11 = torch.chunk(__524_fv,2,-1)\n",
      "\t__526_k = __523__11[0]\n",
      "\t__533__13 = torch.Tensor.contiguous(__526_k)\n",
      "\t__534__14 = torch.Tensor.size(__526_k,0)\n",
      "\t__536_fv = torch.mul(__500_bsz,tensor(16))\n",
      "\t__535__15 = [__534__14,__536_fv,__504_head_dim]\n",
      "\t__538_fv = torch.Tensor.view(__533__13,__535__15)\n",
      "\t__537_k0 = torch.transpose(__538_fv,0,1)\n",
      "\t__547_fv = torch.transpose(__537_k0,-2,-1)\n",
      "\t__546_input = torch.bmm(__545_q2,__547_fv)\n",
      "\t__548_input0 = torch.softmax(__546_input,-1)\n",
      "\t__549_attn = torch.dropout(__548_input0,0.1,True)\n",
      "\t__527_v = __523__11[1]\n",
      "\t__539__16 = torch.Tensor.contiguous(__527_v)\n",
      "\t__540__17 = torch.Tensor.size(__527_v,0)\n",
      "\t__542_fv = torch.mul(__500_bsz,tensor(16))\n",
      "\t__541__18 = [__540__17,__542_fv,__504_head_dim]\n",
      "\t__544_fv = torch.Tensor.view(__539__16,__541__18)\n",
      "\t__543_v0 = torch.transpose(__544_fv,0,1)\n",
      "\t__550_attn_output = torch.bmm(__549_attn,__543_v0)\n",
      "\t__552_fv = torch.transpose(__550_attn_output,0,1)\n",
      "\t__551__19 = torch.Tensor.contiguous(__552_fv)\n",
      "\t__554_fv = [__497_tgt_len,__500_bsz,__502_embed_dim]\n",
      "\t__553_attn_output0 = torch.Tensor.view(__551__19,__554_fv)\n",
      "\t__555_input1 = torch.nn.functional.linear(__553_attn_output0,self.decoder.layers[2].multihead_attn.out_proj.weight,self.decoder.layers[2].multihead_attn.out_proj.bias)\n",
      "\t__557__0 = torch.dropout(__555_input1,0.1,True)\n",
      "\t__556_input0 = torch.add(__488_query,__557__0)\n",
      "\t__562_fv = [512]\n",
      "\t__561_input0 = torch.layer_norm(__556_input0,__562_fv,self.decoder.layers[2].norm2.weight,self.decoder.layers[2].norm2.bias)\n",
      "\t__566_input = torch.nn.functional.linear(__561_input0,self.decoder.layers[2].linear1.weight,self.decoder.layers[2].linear1.bias)\n",
      "\t__563_input1 = torch.relu(__566_input)\n",
      "\t__568_input0 = torch.dropout(__563_input1,0.1,True)\n",
      "\t__571_input = torch.nn.functional.linear(__568_input0,self.decoder.layers[2].linear2.weight,self.decoder.layers[2].linear2.bias)\n",
      "\t__573__0 = torch.dropout(__571_input,0.1,True)\n",
      "\t__572_input2 = torch.add(__561_input0,__573__0)\n",
      "\t__577_fv = [512]\n",
      "\t__576_query = torch.layer_norm(__572_input2,__577_fv,self.decoder.layers[2].norm3.weight,self.decoder.layers[2].norm3.bias)\n",
      "\t__607__7 = torch.nn.functional.linear(__576_query,self.decoder.layers[3].self_attn.in_proj_weight,self.decoder.layers[3].self_attn.in_proj_bias)\n",
      "\t__608_fv = torch.chunk(__607__7,3,-1)\n",
      "\t__609_q = __608_fv[0]\n",
      "\t__612__8 = torch.Tensor.contiguous(__609_q)\n",
      "\t__596_tgt_len = torch.Tensor.size(__576_query,0)\n",
      "\t__599_bsz = torch.Tensor.size(__576_query,1)\n",
      "\t__614_fv = torch.mul(__599_bsz,tensor(16))\n",
      "\t__601_embed_dim = torch.Tensor.size(__576_query,2)\n",
      "\t__603_head_dim = torch.div(__601_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__613__9 = [__596_tgt_len,__614_fv,__603_head_dim]\n",
      "\t__616_fv = torch.Tensor.view(__612__8,__613__9)\n",
      "\t__615_q0 = torch.transpose(__616_fv,0,1)\n",
      "\t__629_q1 = torch.div(__615_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__610_k = __608_fv[1]\n",
      "\t__617__10 = torch.Tensor.contiguous(__610_k)\n",
      "\t__618__11 = torch.Tensor.size(__610_k,0)\n",
      "\t__620_fv = torch.mul(__599_bsz,tensor(16))\n",
      "\t__619__12 = [__618__11,__620_fv,__603_head_dim]\n",
      "\t__622_fv = torch.Tensor.view(__617__10,__619__12)\n",
      "\t__621_k0 = torch.transpose(__622_fv,0,1)\n",
      "\t__631_fv = torch.transpose(__621_k0,-2,-1)\n",
      "\t__630_input = torch.bmm(__629_q1,__631_fv)\n",
      "\t__632_input0 = torch.softmax(__630_input,-1)\n",
      "\t__633_attn = torch.dropout(__632_input0,0.1,True)\n",
      "\t__611_v = __608_fv[2]\n",
      "\t__623__13 = torch.Tensor.contiguous(__611_v)\n",
      "\t__624__14 = torch.Tensor.size(__611_v,0)\n",
      "\t__626_fv = torch.mul(__599_bsz,tensor(16))\n",
      "\t__625__15 = [__624__14,__626_fv,__603_head_dim]\n",
      "\t__628_fv = torch.Tensor.view(__623__13,__625__15)\n",
      "\t__627_v0 = torch.transpose(__628_fv,0,1)\n",
      "\t__634_attn_output = torch.bmm(__633_attn,__627_v0)\n",
      "\t__636_fv = torch.transpose(__634_attn_output,0,1)\n",
      "\t__635__16 = torch.Tensor.contiguous(__636_fv)\n",
      "\t__638_fv = [__596_tgt_len,__599_bsz,__601_embed_dim]\n",
      "\t__637_attn_output0 = torch.Tensor.view(__635__16,__638_fv)\n",
      "\t__639_input1 = torch.nn.functional.linear(__637_attn_output0,self.decoder.layers[3].self_attn.out_proj.weight,self.decoder.layers[3].self_attn.out_proj.bias)\n",
      "\t__640__0 = torch.dropout(__639_input1,0.1,True)\n",
      "\t__641_input = torch.add(__576_query,__640__0)\n",
      "\t__646_fv = [512]\n",
      "\t__645_query = torch.layer_norm(__641_input,__646_fv,self.decoder.layers[3].norm1.weight,self.decoder.layers[3].norm1.bias)\n",
      "\t__665_E = torch.Tensor.size(__645_query,-1)\n",
      "\t__668_fv = torch.mul(__665_E,tensor(2))\n",
      "\t__667__8 = [__665_E,__668_fv]\n",
      "\t__669__9 = torch.split_with_sizes(self.decoder.layers[3].multihead_attn.in_proj_weight,__667__8)\n",
      "\t__671_w_q = __669__9[0]\n",
      "\t__675_fv = torch.mul(__665_E,tensor(2))\n",
      "\t__674_fv = [__665_E,__675_fv]\n",
      "\t__673__10 = torch.split_with_sizes(self.decoder.layers[3].multihead_attn.in_proj_bias,__674_fv)\n",
      "\t__677_b_q = __673__10[0]\n",
      "\t__679_q = torch.nn.functional.linear(__645_query,__671_w_q,__677_b_q)\n",
      "\t__685_q0 = torch.Tensor.contiguous(__679_q)\n",
      "\t__654_tgt_len = torch.Tensor.size(__645_query,0)\n",
      "\t__657_bsz = torch.Tensor.size(__645_query,1)\n",
      "\t__687_fv = torch.mul(__657_bsz,tensor(16))\n",
      "\t__659_embed_dim = torch.Tensor.size(__645_query,2)\n",
      "\t__661_head_dim = torch.div(__659_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__686__12 = [__654_tgt_len,__687_fv,__661_head_dim]\n",
      "\t__689_fv = torch.Tensor.view(__685_q0,__686__12)\n",
      "\t__688_q1 = torch.transpose(__689_fv,0,1)\n",
      "\t__702_q2 = torch.div(__688_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__672_w_kv = __669__9[1]\n",
      "\t__678_b_kv = __673__10[1]\n",
      "\t__681_fv = torch.nn.functional.linear(__90_key,__672_w_kv,__678_b_kv)\n",
      "\t__680__11 = torch.chunk(__681_fv,2,-1)\n",
      "\t__683_k = __680__11[0]\n",
      "\t__690__13 = torch.Tensor.contiguous(__683_k)\n",
      "\t__691__14 = torch.Tensor.size(__683_k,0)\n",
      "\t__693_fv = torch.mul(__657_bsz,tensor(16))\n",
      "\t__692__15 = [__691__14,__693_fv,__661_head_dim]\n",
      "\t__695_fv = torch.Tensor.view(__690__13,__692__15)\n",
      "\t__694_k0 = torch.transpose(__695_fv,0,1)\n",
      "\t__704_fv = torch.transpose(__694_k0,-2,-1)\n",
      "\t__703_input = torch.bmm(__702_q2,__704_fv)\n",
      "\t__705_input0 = torch.softmax(__703_input,-1)\n",
      "\t__706_attn = torch.dropout(__705_input0,0.1,True)\n",
      "\t__684_v = __680__11[1]\n",
      "\t__696__16 = torch.Tensor.contiguous(__684_v)\n",
      "\t__697__17 = torch.Tensor.size(__684_v,0)\n",
      "\t__699_fv = torch.mul(__657_bsz,tensor(16))\n",
      "\t__698__18 = [__697__17,__699_fv,__661_head_dim]\n",
      "\t__701_fv = torch.Tensor.view(__696__16,__698__18)\n",
      "\t__700_v0 = torch.transpose(__701_fv,0,1)\n",
      "\t__707_attn_output = torch.bmm(__706_attn,__700_v0)\n",
      "\t__709_fv = torch.transpose(__707_attn_output,0,1)\n",
      "\t__708__19 = torch.Tensor.contiguous(__709_fv)\n",
      "\t__711_fv = [__654_tgt_len,__657_bsz,__659_embed_dim]\n",
      "\t__710_attn_output0 = torch.Tensor.view(__708__19,__711_fv)\n",
      "\t__712_input1 = torch.nn.functional.linear(__710_attn_output0,self.decoder.layers[3].multihead_attn.out_proj.weight,self.decoder.layers[3].multihead_attn.out_proj.bias)\n",
      "\t__714__0 = torch.dropout(__712_input1,0.1,True)\n",
      "\t__713_input0 = torch.add(__645_query,__714__0)\n",
      "\t__719_fv = [512]\n",
      "\t__718_input0 = torch.layer_norm(__713_input0,__719_fv,self.decoder.layers[3].norm2.weight,self.decoder.layers[3].norm2.bias)\n",
      "\t__723_input = torch.nn.functional.linear(__718_input0,self.decoder.layers[3].linear1.weight,self.decoder.layers[3].linear1.bias)\n",
      "\t__720_input1 = torch.relu(__723_input)\n",
      "\t__725_input0 = torch.dropout(__720_input1,0.1,True)\n",
      "\t__728_input = torch.nn.functional.linear(__725_input0,self.decoder.layers[3].linear2.weight,self.decoder.layers[3].linear2.bias)\n",
      "\t__730__0 = torch.dropout(__728_input,0.1,True)\n",
      "\t__729_input2 = torch.add(__718_input0,__730__0)\n",
      "\t__734_fv = [512]\n",
      "\t__733_query = torch.layer_norm(__729_input2,__734_fv,self.decoder.layers[3].norm3.weight,self.decoder.layers[3].norm3.bias)\n",
      "\t__765__7 = torch.nn.functional.linear(__733_query,self.decoder.layers[4].self_attn.in_proj_weight,self.decoder.layers[4].self_attn.in_proj_bias)\n",
      "\t__766_fv = torch.chunk(__765__7,3,-1)\n",
      "\t__767_q = __766_fv[0]\n",
      "\t__770__8 = torch.Tensor.contiguous(__767_q)\n",
      "\t__754_tgt_len = torch.Tensor.size(__733_query,0)\n",
      "\t__757_bsz = torch.Tensor.size(__733_query,1)\n",
      "\t__772_fv = torch.mul(__757_bsz,tensor(16))\n",
      "\t__759_embed_dim = torch.Tensor.size(__733_query,2)\n",
      "\t__761_head_dim = torch.div(__759_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__771__9 = [__754_tgt_len,__772_fv,__761_head_dim]\n",
      "\t__774_fv = torch.Tensor.view(__770__8,__771__9)\n",
      "\t__773_q0 = torch.transpose(__774_fv,0,1)\n",
      "\t__787_q1 = torch.div(__773_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__768_k = __766_fv[1]\n",
      "\t__775__10 = torch.Tensor.contiguous(__768_k)\n",
      "\t__776__11 = torch.Tensor.size(__768_k,0)\n",
      "\t__778_fv = torch.mul(__757_bsz,tensor(16))\n",
      "\t__777__12 = [__776__11,__778_fv,__761_head_dim]\n",
      "\t__780_fv = torch.Tensor.view(__775__10,__777__12)\n",
      "\t__779_k0 = torch.transpose(__780_fv,0,1)\n",
      "\t__789_fv = torch.transpose(__779_k0,-2,-1)\n",
      "\t__788_input = torch.bmm(__787_q1,__789_fv)\n",
      "\t__790_input0 = torch.softmax(__788_input,-1)\n",
      "\t__791_attn = torch.dropout(__790_input0,0.1,True)\n",
      "\t__769_v = __766_fv[2]\n",
      "\t__781__13 = torch.Tensor.contiguous(__769_v)\n",
      "\t__782__14 = torch.Tensor.size(__769_v,0)\n",
      "\t__784_fv = torch.mul(__757_bsz,tensor(16))\n",
      "\t__783__15 = [__782__14,__784_fv,__761_head_dim]\n",
      "\t__786_fv = torch.Tensor.view(__781__13,__783__15)\n",
      "\t__785_v0 = torch.transpose(__786_fv,0,1)\n",
      "\t__792_attn_output = torch.bmm(__791_attn,__785_v0)\n",
      "\t__794_fv = torch.transpose(__792_attn_output,0,1)\n",
      "\t__793__16 = torch.Tensor.contiguous(__794_fv)\n",
      "\t__796_fv = [__754_tgt_len,__757_bsz,__759_embed_dim]\n",
      "\t__795_attn_output0 = torch.Tensor.view(__793__16,__796_fv)\n",
      "\t__797_input1 = torch.nn.functional.linear(__795_attn_output0,self.decoder.layers[4].self_attn.out_proj.weight,self.decoder.layers[4].self_attn.out_proj.bias)\n",
      "\t__798__0 = torch.dropout(__797_input1,0.1,True)\n",
      "\t__799_input = torch.add(__733_query,__798__0)\n",
      "\t__804_fv = [512]\n",
      "\t__803_query = torch.layer_norm(__799_input,__804_fv,self.decoder.layers[4].norm1.weight,self.decoder.layers[4].norm1.bias)\n",
      "\t__823_E = torch.Tensor.size(__803_query,-1)\n",
      "\t__826_fv = torch.mul(__823_E,tensor(2))\n",
      "\t__825__8 = [__823_E,__826_fv]\n",
      "\t__827__9 = torch.split_with_sizes(self.decoder.layers[4].multihead_attn.in_proj_weight,__825__8)\n",
      "\t__829_w_q = __827__9[0]\n",
      "\t__833_fv = torch.mul(__823_E,tensor(2))\n",
      "\t__832_fv = [__823_E,__833_fv]\n",
      "\t__831__10 = torch.split_with_sizes(self.decoder.layers[4].multihead_attn.in_proj_bias,__832_fv)\n",
      "\t__835_b_q = __831__10[0]\n",
      "\t__837_q = torch.nn.functional.linear(__803_query,__829_w_q,__835_b_q)\n",
      "\t__843_q0 = torch.Tensor.contiguous(__837_q)\n",
      "\t__812_tgt_len = torch.Tensor.size(__803_query,0)\n",
      "\t__815_bsz = torch.Tensor.size(__803_query,1)\n",
      "\t__845_fv = torch.mul(__815_bsz,tensor(16))\n",
      "\t__817_embed_dim = torch.Tensor.size(__803_query,2)\n",
      "\t__819_head_dim = torch.div(__817_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__844__12 = [__812_tgt_len,__845_fv,__819_head_dim]\n",
      "\t__847_fv = torch.Tensor.view(__843_q0,__844__12)\n",
      "\t__846_q1 = torch.transpose(__847_fv,0,1)\n",
      "\t__860_q2 = torch.div(__846_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__830_w_kv = __827__9[1]\n",
      "\t__836_b_kv = __831__10[1]\n",
      "\t__839_fv = torch.nn.functional.linear(__90_key,__830_w_kv,__836_b_kv)\n",
      "\t__838__11 = torch.chunk(__839_fv,2,-1)\n",
      "\t__841_k = __838__11[0]\n",
      "\t__848__13 = torch.Tensor.contiguous(__841_k)\n",
      "\t__849__14 = torch.Tensor.size(__841_k,0)\n",
      "\t__851_fv = torch.mul(__815_bsz,tensor(16))\n",
      "\t__850__15 = [__849__14,__851_fv,__819_head_dim]\n",
      "\t__853_fv = torch.Tensor.view(__848__13,__850__15)\n",
      "\t__852_k0 = torch.transpose(__853_fv,0,1)\n",
      "\t__862_fv = torch.transpose(__852_k0,-2,-1)\n",
      "\t__861_input = torch.bmm(__860_q2,__862_fv)\n",
      "\t__863_input0 = torch.softmax(__861_input,-1)\n",
      "\t__864_attn = torch.dropout(__863_input0,0.1,True)\n",
      "\t__842_v = __838__11[1]\n",
      "\t__854__16 = torch.Tensor.contiguous(__842_v)\n",
      "\t__855__17 = torch.Tensor.size(__842_v,0)\n",
      "\t__857_fv = torch.mul(__815_bsz,tensor(16))\n",
      "\t__856__18 = [__855__17,__857_fv,__819_head_dim]\n",
      "\t__859_fv = torch.Tensor.view(__854__16,__856__18)\n",
      "\t__858_v0 = torch.transpose(__859_fv,0,1)\n",
      "\t__865_attn_output = torch.bmm(__864_attn,__858_v0)\n",
      "\t__867_fv = torch.transpose(__865_attn_output,0,1)\n",
      "\t__866__19 = torch.Tensor.contiguous(__867_fv)\n",
      "\t__869_fv = [__812_tgt_len,__815_bsz,__817_embed_dim]\n",
      "\t__868_attn_output0 = torch.Tensor.view(__866__19,__869_fv)\n",
      "\t__870_input1 = torch.nn.functional.linear(__868_attn_output0,self.decoder.layers[4].multihead_attn.out_proj.weight,self.decoder.layers[4].multihead_attn.out_proj.bias)\n",
      "\t__872__0 = torch.dropout(__870_input1,0.1,True)\n",
      "\t__871_input0 = torch.add(__803_query,__872__0)\n",
      "\t__877_fv = [512]\n",
      "\t__876_input0 = torch.layer_norm(__871_input0,__877_fv,self.decoder.layers[4].norm2.weight,self.decoder.layers[4].norm2.bias)\n",
      "\t__881_input = torch.nn.functional.linear(__876_input0,self.decoder.layers[4].linear1.weight,self.decoder.layers[4].linear1.bias)\n",
      "\t__878_input1 = torch.relu(__881_input)\n",
      "\t__883_input0 = torch.dropout(__878_input1,0.1,True)\n",
      "\t__886_input = torch.nn.functional.linear(__883_input0,self.decoder.layers[4].linear2.weight,self.decoder.layers[4].linear2.bias)\n",
      "\t__888__0 = torch.dropout(__886_input,0.1,True)\n",
      "\t__887_input2 = torch.add(__876_input0,__888__0)\n",
      "\t__892_fv = [512]\n",
      "\t__891_query = torch.layer_norm(__887_input2,__892_fv,self.decoder.layers[4].norm3.weight,self.decoder.layers[4].norm3.bias)\n",
      "\t__922__7 = torch.nn.functional.linear(__891_query,self.decoder.layers[5].self_attn.in_proj_weight,self.decoder.layers[5].self_attn.in_proj_bias)\n",
      "\t__923_fv = torch.chunk(__922__7,3,-1)\n",
      "\t__924_q = __923_fv[0]\n",
      "\t__927__8 = torch.Tensor.contiguous(__924_q)\n",
      "\t__911_tgt_len = torch.Tensor.size(__891_query,0)\n",
      "\t__914_bsz = torch.Tensor.size(__891_query,1)\n",
      "\t__929_fv = torch.mul(__914_bsz,tensor(16))\n",
      "\t__916_embed_dim = torch.Tensor.size(__891_query,2)\n",
      "\t__918_head_dim = torch.div(__916_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__928__9 = [__911_tgt_len,__929_fv,__918_head_dim]\n",
      "\t__931_fv = torch.Tensor.view(__927__8,__928__9)\n",
      "\t__930_q0 = torch.transpose(__931_fv,0,1)\n",
      "\t__944_q1 = torch.div(__930_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__925_k = __923_fv[1]\n",
      "\t__932__10 = torch.Tensor.contiguous(__925_k)\n",
      "\t__933__11 = torch.Tensor.size(__925_k,0)\n",
      "\t__935_fv = torch.mul(__914_bsz,tensor(16))\n",
      "\t__934__12 = [__933__11,__935_fv,__918_head_dim]\n",
      "\t__937_fv = torch.Tensor.view(__932__10,__934__12)\n",
      "\t__936_k0 = torch.transpose(__937_fv,0,1)\n",
      "\t__946_fv = torch.transpose(__936_k0,-2,-1)\n",
      "\t__945_input = torch.bmm(__944_q1,__946_fv)\n",
      "\t__947_input0 = torch.softmax(__945_input,-1)\n",
      "\t__948_attn = torch.dropout(__947_input0,0.1,True)\n",
      "\t__926_v = __923_fv[2]\n",
      "\t__938__13 = torch.Tensor.contiguous(__926_v)\n",
      "\t__939__14 = torch.Tensor.size(__926_v,0)\n",
      "\t__941_fv = torch.mul(__914_bsz,tensor(16))\n",
      "\t__940__15 = [__939__14,__941_fv,__918_head_dim]\n",
      "\t__943_fv = torch.Tensor.view(__938__13,__940__15)\n",
      "\t__942_v0 = torch.transpose(__943_fv,0,1)\n",
      "\t__949_attn_output = torch.bmm(__948_attn,__942_v0)\n",
      "\t__951_fv = torch.transpose(__949_attn_output,0,1)\n",
      "\t__950__16 = torch.Tensor.contiguous(__951_fv)\n",
      "\t__953_fv = [__911_tgt_len,__914_bsz,__916_embed_dim]\n",
      "\t__952_attn_output0 = torch.Tensor.view(__950__16,__953_fv)\n",
      "\t__954_input1 = torch.nn.functional.linear(__952_attn_output0,self.decoder.layers[5].self_attn.out_proj.weight,self.decoder.layers[5].self_attn.out_proj.bias)\n",
      "\t__955__0 = torch.dropout(__954_input1,0.1,True)\n",
      "\t__956_input = torch.add(__891_query,__955__0)\n",
      "\t__961_fv = [512]\n",
      "\t__960_query = torch.layer_norm(__956_input,__961_fv,self.decoder.layers[5].norm1.weight,self.decoder.layers[5].norm1.bias)\n",
      "\t__980_E = torch.Tensor.size(__960_query,-1)\n",
      "\t__983_fv = torch.mul(__980_E,tensor(2))\n",
      "\t__982__8 = [__980_E,__983_fv]\n",
      "\t__984__9 = torch.split_with_sizes(self.decoder.layers[5].multihead_attn.in_proj_weight,__982__8)\n",
      "\t__986_w_q = __984__9[0]\n",
      "\t__990_fv = torch.mul(__980_E,tensor(2))\n",
      "\t__989_fv = [__980_E,__990_fv]\n",
      "\t__988__10 = torch.split_with_sizes(self.decoder.layers[5].multihead_attn.in_proj_bias,__989_fv)\n",
      "\t__992_b_q = __988__10[0]\n",
      "\t__994_q = torch.nn.functional.linear(__960_query,__986_w_q,__992_b_q)\n",
      "\t__1000_q0 = torch.Tensor.contiguous(__994_q)\n",
      "\t__969_tgt_len = torch.Tensor.size(__960_query,0)\n",
      "\t__972_bsz = torch.Tensor.size(__960_query,1)\n",
      "\t__1002_fv = torch.mul(__972_bsz,tensor(16))\n",
      "\t__974_embed_dim = torch.Tensor.size(__960_query,2)\n",
      "\t__976_head_dim = torch.div(__974_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__1001__12 = [__969_tgt_len,__1002_fv,__976_head_dim]\n",
      "\t__1004_fv = torch.Tensor.view(__1000_q0,__1001__12)\n",
      "\t__1003_q1 = torch.transpose(__1004_fv,0,1)\n",
      "\t__1017_q2 = torch.div(__1003_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__987_w_kv = __984__9[1]\n",
      "\t__993_b_kv = __988__10[1]\n",
      "\t__996_fv = torch.nn.functional.linear(__90_key,__987_w_kv,__993_b_kv)\n",
      "\t__995__11 = torch.chunk(__996_fv,2,-1)\n",
      "\t__998_k = __995__11[0]\n",
      "\t__1005__13 = torch.Tensor.contiguous(__998_k)\n",
      "\t__1006__14 = torch.Tensor.size(__998_k,0)\n",
      "\t__1008_fv = torch.mul(__972_bsz,tensor(16))\n",
      "\t__1007__15 = [__1006__14,__1008_fv,__976_head_dim]\n",
      "\t__1010_fv = torch.Tensor.view(__1005__13,__1007__15)\n",
      "\t__1009_k0 = torch.transpose(__1010_fv,0,1)\n",
      "\t__1019_fv = torch.transpose(__1009_k0,-2,-1)\n",
      "\t__1018_input = torch.bmm(__1017_q2,__1019_fv)\n",
      "\t__1020_input0 = torch.softmax(__1018_input,-1)\n",
      "\t__1021_attn = torch.dropout(__1020_input0,0.1,True)\n",
      "\t__999_v = __995__11[1]\n",
      "\t__1011__16 = torch.Tensor.contiguous(__999_v)\n",
      "\t__1012__17 = torch.Tensor.size(__999_v,0)\n",
      "\t__1014_fv = torch.mul(__972_bsz,tensor(16))\n",
      "\t__1013__18 = [__1012__17,__1014_fv,__976_head_dim]\n",
      "\t__1016_fv = torch.Tensor.view(__1011__16,__1013__18)\n",
      "\t__1015_v0 = torch.transpose(__1016_fv,0,1)\n",
      "\t__1022_attn_output = torch.bmm(__1021_attn,__1015_v0)\n",
      "\t__1024_fv = torch.transpose(__1022_attn_output,0,1)\n",
      "\t__1023__19 = torch.Tensor.contiguous(__1024_fv)\n",
      "\t__1026_fv = [__969_tgt_len,__972_bsz,__974_embed_dim]\n",
      "\t__1025_attn_output0 = torch.Tensor.view(__1023__19,__1026_fv)\n",
      "\t__1027_input1 = torch.nn.functional.linear(__1025_attn_output0,self.decoder.layers[5].multihead_attn.out_proj.weight,self.decoder.layers[5].multihead_attn.out_proj.bias)\n",
      "\t__1029__0 = torch.dropout(__1027_input1,0.1,True)\n",
      "\t__1028_input0 = torch.add(__960_query,__1029__0)\n",
      "\t__1034_fv = [512]\n",
      "\t__1033_input0 = torch.layer_norm(__1028_input0,__1034_fv,self.decoder.layers[5].norm2.weight,self.decoder.layers[5].norm2.bias)\n",
      "\t__1038_input = torch.nn.functional.linear(__1033_input0,self.decoder.layers[5].linear1.weight,self.decoder.layers[5].linear1.bias)\n",
      "\t__1035_input1 = torch.relu(__1038_input)\n",
      "\t__1040_input0 = torch.dropout(__1035_input1,0.1,True)\n",
      "\t__1043_input = torch.nn.functional.linear(__1040_input0,self.decoder.layers[5].linear2.weight,self.decoder.layers[5].linear2.bias)\n",
      "\t__1045__0 = torch.dropout(__1043_input,0.1,True)\n",
      "\t__1044_input2 = torch.add(__1033_input0,__1045__0)\n",
      "\t__1049_fv = [512]\n",
      "\t__1048_input0 = torch.layer_norm(__1044_input2,__1049_fv,self.decoder.layers[5].norm3.weight,self.decoder.layers[5].norm3.bias)\n",
      "\t__1053_fv = [512]\n",
      "\t__1052__0 = torch.layer_norm(__1048_input0,__1053_fv,self.decoder.norm.weight,self.decoder.norm.bias)\n",
      "\treturn __1052__0\n"
     ]
    }
   ],
   "source": [
    "mod_tf = nn.Transformer(nhead=16, num_encoder_layers=1)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((10, 32, 512))\n",
    "modtf_Bg = read_trace_code.main(mod_tf,(src,tgt),show_debug=True)\n",
    "modtf_Dg = Btools.B_to_D(modtf_Bg)\n",
    "Btools.print_code(modtf_Dg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24947c92-ff0a-4d0e-8b9a-f7c2e79d428f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test on GPT2 made from scratch with random and nlayers=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13addc3-bf67-40ee-b2d9-90eaf1db1f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import ModuleList\n",
    "from torch.nn.modules.normalization import LayerNorm\n",
    "\n",
    "class Conv1D(nn.Module):\n",
    "    def __init__(self, nx, nf):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        w = torch.empty(nx, nf)\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "        x = x.view(size_out)\n",
    "        return x\n",
    "    \n",
    "# Examples :\n",
    "\"\"\"\n",
    "d_model = 768\n",
    "conv1d  = Conv1D(d_model, d_model*3)\n",
    "x       = torch.rand(1,4,d_model) #represents a sequence of batch_size=1, seq_len=4 and embedding_sz=768, something like \"Hello how are you\"\n",
    "x       = conv1d(x)\n",
    "print(x.shape)\n",
    "\n",
    "query, key, value = x.split(d_model, dim=-1)\n",
    "\n",
    "print(query.shape, key.shape, value.shape)\n",
    "\"\"\"\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dropout, d_model=768, nx=768*4):\n",
    "        super().__init__()\n",
    "        self.c_fc    = Conv1D(d_model, nx)\n",
    "        self.c_proj  = Conv1D(nx, d_model)\n",
    "        self.act     = F.gelu\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.c_proj(self.act(self.c_fc(x))))\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, n_ctx=1024, d_head=64, bias=True, scale=False):\n",
    "        super().__init__()\n",
    "        self.n_head  = n_head\n",
    "        self.d_model = d_model\n",
    "        self.c_attn  = Conv1D(d_model, d_model*3)\n",
    "        self.scale   = scale\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.c_proj  = Conv1D(d_model, d_model)\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        \"return shape [`batch`, `head`, `sequence`, `features`]\"\n",
    "        new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head) \n",
    "        x = x.view(new_shape)\n",
    "        return x.permute(0, 2, 1, 3) \n",
    "    \n",
    "    def _attn(self, q, k, v, attn_mask=None):\n",
    "        scores  = torch.matmul(q, k.transpose(-2, -1))\n",
    "        if self.scale: scores = scores/math.sqrt(v.size(-1))\n",
    "        nd, ns  = scores.size(-2), scores.size(-1)\n",
    "        if attn_mask is not None: scores = scores + attn_mask\n",
    "        scores  = self.softmax(scores)\n",
    "        scores  = self.dropout(scores)\n",
    "        outputs = torch.matmul(scores, v)\n",
    "        return outputs\n",
    "    \n",
    "    def merge_heads(self, x):\n",
    "        x         = x.permute(0, 2, 1, 3).contiguous()\n",
    "        new_shape = x.size()[:-2] + (x.size(-2)*x.size(-1),)\n",
    "        return x.view(new_shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x        = self.c_attn(x) #new `x` shape - `[1,3,2304]`\n",
    "        q, k, v  = x.split(self.d_model, dim=2)\n",
    "        q, k, v  = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "        out      = self._attn(q, k, v)\n",
    "        out      = self.merge_heads(out)\n",
    "        out      = self.c_proj(out)\n",
    "        return out\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn        = Attention(d_model=768, n_head=12, d_head=64, n_ctx=1024, bias=True, scale=False)\n",
    "        self.feedforward = FeedForward(dropout=0.1, d_model=768, nx=768*4)\n",
    "        self.ln_1        = LayerNorm(d_model)\n",
    "        self.ln_2        = LayerNorm(d_model)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.feedforward(self.ln_2(x))\n",
    "        return x\n",
    "    \n",
    "def _get_clones(module, n):\n",
    "    return ModuleList([copy.deepcopy(module) for i in range(n)])\n",
    "\n",
    "class GPT2(nn.Module):\n",
    "    def __init__(self, nlayers=12, n_ctx=1024, d_model=768, vcb_sz=50257):\n",
    "        super(GPT2, self).__init__()\n",
    "        self.nlayers = nlayers\n",
    "        block        = TransformerBlock(d_model=768, n_head=12, dropout=0.1)\n",
    "        self.h       = _get_clones(block, 12)\n",
    "        self.wte     = nn.Embedding(vcb_sz, d_model)\n",
    "        self.wpe     = nn.Embedding(n_ctx, d_model)\n",
    "        self.drop    = nn.Dropout(0.1)\n",
    "        self.ln_f    = LayerNorm(d_model)\n",
    "        self.out     = nn.Linear(d_model, vcb_sz, bias=False)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.out.weight = self.wte.weight\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding, Conv1D)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if isinstance(module, (nn.Linear, Conv1D)) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, src, labels=None, pos_ids=None):\n",
    "        if pos_ids is None: pos_ids = torch.arange(0, src.size(-1)).unsqueeze(0)\n",
    "        inp = self.drop((self.wte(src)+self.wpe(pos_ids)))\n",
    "        for i in range(self.nlayers): inp = self.h[i](inp)\n",
    "        inp     = self.ln_f(inp)\n",
    "        logits  = self.out(inp)\n",
    "        outputs = (logits,) + (inp,)\n",
    "        \n",
    "        if labels is not None:\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            loss = self.loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "            return outputs\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb9c80c4-936b-41e9-9f41-035632acb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2(nlayers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "720d6915-4695-49f8-a4ed-68d92d689f18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "# load pretrained_weights from hugging face\n",
    "# download file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin to `.`\n",
    "\n",
    "model_dict = model.state_dict() #currently with random initialization\n",
    "state_dict = torch.load(\"./gpt2-pytorch_model.bin\") #pretrained weights\n",
    "\n",
    "old_keys = []\n",
    "new_keys = []\n",
    "for key in state_dict.keys(): \n",
    "    if \"mlp\" in key: #The hugging face state dict references the feedforward network as mlp, need to replace to `feedforward` be able to reuse these weights\n",
    "        new_key = key.replace(\"mlp\", \"feedforward\")\n",
    "        new_keys.append(new_key)\n",
    "        old_keys.append(key)\n",
    "\n",
    "for old_key, new_key in zip(old_keys, new_keys): \n",
    "    state_dict[new_key]=state_dict.pop(old_key)\n",
    "\n",
    "pretrained_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d342fb8-c558-4822-99ba-d38ba4e7e7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -5.6025,  -5.6418,  -8.2597,  ..., -11.7372, -11.0343,  -5.3123],\n",
       "         [-25.5171, -27.3682, -31.0964,  ..., -44.4331, -31.5699, -32.2924],\n",
       "         [-20.1869, -21.9760, -26.3721,  ..., -43.0404, -27.2938, -26.8470]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "context1  = torch.tensor([tokenizer.encode(\"The planet earth\")])\n",
    "context2  = torch.tensor([tokenizer.encode(\"I'm upset with those tools\")])\n",
    "model.forward(context1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ad9eaa0-6c77-4dd1-b24e-cdaddc51ff4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16439/3700145435.py:62: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  feedforward = self.feedforward\n",
      "  ln_2 = self.ln_2\n",
      "  attn = self.attn\n",
      "  ln_1 = self.ln_1\n",
      "  _0 = (attn).forward((ln_1).forward(argument_1, ), )\n",
      "  input = torch.add(argument_1, _0)\n",
      "  _1 = (feedforward).forward((ln_2).forward(input, ), )\n",
      "  return torch.add(input, _1)\n",
      "\n",
      "In self.forward try to sub open self.wte.forward\n",
      "In self.forward try to sub open self.wpe.forward\n",
      "In self.forward try to sub open self.drop.forward\n",
      "In self.forward try to sub open self.h[0].forward\n",
      "In self.h[0].forward try to sub open self.h[0].ln_1.forward\n",
      "In self.h[0].forward try to sub open self.h[0].attn.forward\n",
      "In self.h[0].attn.forward try to sub open self.h[0].attn.c_attn.forward\n",
      "In self.h[0].attn.forward try to sub open self.h[0].attn.softmax.forward\n",
      "In self.h[0].attn.forward try to sub open self.h[0].attn.dropout.forward\n",
      "In self.h[0].attn.forward try to sub open self.h[0].attn.c_proj.forward\n",
      "In self.h[0].forward try to sub open self.h[0].ln_2.forward\n",
      "In self.h[0].forward try to sub open self.h[0].feedforward.forward\n",
      "In self.h[0].feedforward.forward try to sub open self.h[0].feedforward.c_fc.forward\n",
      "In self.h[0].feedforward.forward try to sub open self.h[0].feedforward.c_proj.forward\n",
      "In self.h[0].feedforward.forward try to sub open self.h[0].feedforward.dropout.forward\n",
      "In self.forward try to sub open self.h[1].forward\n",
      "In self.h[1].forward try to sub open self.h[1].ln_1.forward\n",
      "In self.h[1].forward try to sub open self.h[1].attn.forward\n",
      "In self.h[1].attn.forward try to sub open self.h[1].attn.c_attn.forward\n",
      "In self.h[1].attn.forward try to sub open self.h[1].attn.softmax.forward\n",
      "In self.h[1].attn.forward try to sub open self.h[1].attn.dropout.forward\n",
      "In self.h[1].attn.forward try to sub open self.h[1].attn.c_proj.forward\n",
      "In self.h[1].forward try to sub open self.h[1].ln_2.forward\n",
      "In self.h[1].forward try to sub open self.h[1].feedforward.forward\n",
      "In self.h[1].feedforward.forward try to sub open self.h[1].feedforward.c_fc.forward\n",
      "In self.h[1].feedforward.forward try to sub open self.h[1].feedforward.c_proj.forward\n",
      "In self.h[1].feedforward.forward try to sub open self.h[1].feedforward.dropout.forward\n",
      "In self.forward try to sub open self.h[2].forward\n",
      "In self.h[2].forward try to sub open self.h[2].ln_1.forward\n",
      "In self.h[2].forward try to sub open self.h[2].attn.forward\n",
      "In self.h[2].attn.forward try to sub open self.h[2].attn.c_attn.forward\n",
      "In self.h[2].attn.forward try to sub open self.h[2].attn.softmax.forward\n",
      "In self.h[2].attn.forward try to sub open self.h[2].attn.dropout.forward\n",
      "In self.h[2].attn.forward try to sub open self.h[2].attn.c_proj.forward\n",
      "In self.h[2].forward try to sub open self.h[2].ln_2.forward\n",
      "In self.h[2].forward try to sub open self.h[2].feedforward.forward\n",
      "In self.h[2].feedforward.forward try to sub open self.h[2].feedforward.c_fc.forward\n",
      "In self.h[2].feedforward.forward try to sub open self.h[2].feedforward.c_proj.forward\n",
      "In self.h[2].feedforward.forward try to sub open self.h[2].feedforward.dropout.forward\n",
      "In self.forward try to sub open self.h[3].forward\n",
      "In self.h[3].forward try to sub open self.h[3].ln_1.forward\n",
      "In self.h[3].forward try to sub open self.h[3].attn.forward\n",
      "In self.h[3].attn.forward try to sub open self.h[3].attn.c_attn.forward\n",
      "In self.h[3].attn.forward try to sub open self.h[3].attn.softmax.forward\n",
      "In self.h[3].attn.forward try to sub open self.h[3].attn.dropout.forward\n",
      "In self.h[3].attn.forward try to sub open self.h[3].attn.c_proj.forward\n",
      "In self.h[3].forward try to sub open self.h[3].ln_2.forward\n",
      "In self.h[3].forward try to sub open self.h[3].feedforward.forward\n",
      "In self.h[3].feedforward.forward try to sub open self.h[3].feedforward.c_fc.forward\n",
      "In self.h[3].feedforward.forward try to sub open self.h[3].feedforward.c_proj.forward\n",
      "In self.h[3].feedforward.forward try to sub open self.h[3].feedforward.dropout.forward\n",
      "In self.forward try to sub open self.h[4].forward\n",
      "In self.h[4].forward try to sub open self.h[4].ln_1.forward\n",
      "In self.h[4].forward try to sub open self.h[4].attn.forward\n",
      "In self.h[4].attn.forward try to sub open self.h[4].attn.c_attn.forward\n",
      "In self.h[4].attn.forward try to sub open self.h[4].attn.softmax.forward\n",
      "In self.h[4].attn.forward try to sub open self.h[4].attn.dropout.forward\n",
      "In self.h[4].attn.forward try to sub open self.h[4].attn.c_proj.forward\n",
      "In self.h[4].forward try to sub open self.h[4].ln_2.forward\n",
      "In self.h[4].forward try to sub open self.h[4].feedforward.forward\n",
      "In self.h[4].feedforward.forward try to sub open self.h[4].feedforward.c_fc.forward\n",
      "In self.h[4].feedforward.forward try to sub open self.h[4].feedforward.c_proj.forward\n",
      "In self.h[4].feedforward.forward try to sub open self.h[4].feedforward.dropout.forward\n",
      "In self.forward try to sub open self.h[5].forward\n",
      "In self.h[5].forward try to sub open self.h[5].ln_1.forward\n",
      "In self.h[5].forward try to sub open self.h[5].attn.forward\n",
      "In self.h[5].attn.forward try to sub open self.h[5].attn.c_attn.forward\n",
      "In self.h[5].attn.forward try to sub open self.h[5].attn.softmax.forward\n",
      "In self.h[5].attn.forward try to sub open self.h[5].attn.dropout.forward\n",
      "In self.h[5].attn.forward try to sub open self.h[5].attn.c_proj.forward\n",
      "In self.h[5].forward try to sub open self.h[5].ln_2.forward\n",
      "In self.h[5].forward try to sub open self.h[5].feedforward.forward\n",
      "In self.h[5].feedforward.forward try to sub open self.h[5].feedforward.c_fc.forward\n",
      "In self.h[5].feedforward.forward try to sub open self.h[5].feedforward.c_proj.forward\n",
      "In self.h[5].feedforward.forward try to sub open self.h[5].feedforward.dropout.forward\n",
      "In self.forward try to sub open self.h[6].forward\n",
      "In self.h[6].forward try to sub open self.h[6].ln_1.forward\n",
      "In self.h[6].forward try to sub open self.h[6].attn.forward\n",
      "In self.h[6].attn.forward try to sub open self.h[6].attn.c_attn.forward\n",
      "In self.h[6].attn.forward try to sub open self.h[6].attn.softmax.forward\n",
      "In self.h[6].attn.forward try to sub open self.h[6].attn.dropout.forward\n",
      "In self.h[6].attn.forward try to sub open self.h[6].attn.c_proj.forward\n",
      "In self.h[6].forward try to sub open self.h[6].ln_2.forward\n",
      "In self.h[6].forward try to sub open self.h[6].feedforward.forward\n",
      "In self.h[6].feedforward.forward try to sub open self.h[6].feedforward.c_fc.forward\n",
      "In self.h[6].feedforward.forward try to sub open self.h[6].feedforward.c_proj.forward\n",
      "In self.h[6].feedforward.forward try to sub open self.h[6].feedforward.dropout.forward\n",
      "In self.forward try to sub open self.h[7].forward\n",
      "In self.h[7].forward try to sub open self.h[7].ln_1.forward\n",
      "In self.h[7].forward try to sub open self.h[7].attn.forward\n",
      "In self.h[7].attn.forward try to sub open self.h[7].attn.c_attn.forward\n",
      "In self.h[7].attn.forward try to sub open self.h[7].attn.softmax.forward\n",
      "In self.h[7].attn.forward try to sub open self.h[7].attn.dropout.forward\n",
      "In self.h[7].attn.forward try to sub open self.h[7].attn.c_proj.forward\n",
      "In self.h[7].forward try to sub open self.h[7].ln_2.forward\n",
      "In self.h[7].forward try to sub open self.h[7].feedforward.forward\n",
      "In self.h[7].feedforward.forward try to sub open self.h[7].feedforward.c_fc.forward\n",
      "In self.h[7].feedforward.forward try to sub open self.h[7].feedforward.c_proj.forward\n",
      "In self.h[7].feedforward.forward try to sub open self.h[7].feedforward.dropout.forward\n",
      "In self.forward try to sub open self.ln_f.forward\n",
      "In self.forward try to sub open self.out.forward\n",
      "def main(src):\n",
      "\t__30_fv = torch.embedding(self.wte.weight,src)\n",
      "\t__24__8 = torch.Tensor.size(src,-1)\n",
      "\t__26_fv = torch.device(\"cpu\")\n",
      "\t__25__9 = torch.arange(0,__24__8,1,dtype = None,device = __26_fv,pin_memory = False)\n",
      "\t__27_input = torch.unsqueeze(__25__9,0)\n",
      "\t__32_fv = torch.embedding(self.wpe.weight,__27_input)\n",
      "\t__28_input0 = torch.add(__30_fv,__32_fv)\n",
      "\t__34_input0 = torch.dropout(__28_input0,0.1,False)\n",
      "\t__43_fv = [768]\n",
      "\t__42_x = torch.layer_norm(__34_input0,__43_fv,self.h[0].ln_1.weight,self.h[0].ln_1.bias)\n",
      "\t__55__4 = torch.Tensor.size(__42_x,-1)\n",
      "\t__57_fv = [-1,__55__4]\n",
      "\t__58_fv = torch.Tensor.view(__42_x,__57_fv)\n",
      "\t__56_x = torch.addmm(self.h[0].attn.c_attn.bias,__58_fv,self.h[0].attn.c_attn.weight)\n",
      "\t__51__0 = torch.Tensor.size(__42_x,0)\n",
      "\t__53__2 = torch.Tensor.size(__42_x,1)\n",
      "\t__59_fv = [__51__0,__53__2,2304]\n",
      "\t__60_fv = torch.Tensor.view(__56_x,__59_fv)\n",
      "\t__48__0 = torch.split(__60_fv,768,2)\n",
      "\t__62_x = __48__0[0]\n",
      "\t__65__1 = torch.Tensor.size(__62_x,0)\n",
      "\t__67__3 = torch.Tensor.size(__62_x,1)\n",
      "\t__69__5 = torch.Tensor.size(__62_x,-1)\n",
      "\t__70__6 = torch.div(__69__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__72_fv = [__65__1,__67__3,12,__70__6]\n",
      "\t__71_x2 = torch.Tensor.view(__62_x,__72_fv)\n",
      "\t__74_fv = [0,2,1,3]\n",
      "\t__73_q = torch.permute(__71_x2,__74_fv)\n",
      "\t__63_x0 = __48__0[1]\n",
      "\t__75__7 = torch.Tensor.size(__63_x0,0)\n",
      "\t__77__9 = torch.Tensor.size(__63_x0,1)\n",
      "\t__79__11 = torch.Tensor.size(__63_x0,-1)\n",
      "\t__80__12 = torch.div(__79__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__82_fv = [__75__7,__77__9,12,__80__12]\n",
      "\t__81_x3 = torch.Tensor.view(__63_x0,__82_fv)\n",
      "\t__84_fv = [0,2,1,3]\n",
      "\t__83_k = torch.permute(__81_x3,__84_fv)\n",
      "\t__96_fv = torch.transpose(__83_k,-2,-1)\n",
      "\t__95_scores = torch.matmul(__73_q,__96_fv)\n",
      "\t__98_fv = torch.softmax(__95_scores,-1)\n",
      "\t__99_scores = torch.dropout(__98_fv,0.1,False)\n",
      "\t__64_x1 = __48__0[2]\n",
      "\t__85__13 = torch.Tensor.size(__64_x1,0)\n",
      "\t__87__15 = torch.Tensor.size(__64_x1,1)\n",
      "\t__89__17 = torch.Tensor.size(__64_x1,-1)\n",
      "\t__90__18 = torch.div(__89__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__92_fv = [__85__13,__87__15,12,__90__18]\n",
      "\t__91_x4 = torch.Tensor.view(__64_x1,__92_fv)\n",
      "\t__94_fv = [0,2,1,3]\n",
      "\t__93_v = torch.permute(__91_x4,__94_fv)\n",
      "\t__100_x5 = torch.matmul(__99_scores,__93_v)\n",
      "\t__102_fv = [0,2,1,3]\n",
      "\t__103_fv = torch.permute(__100_x5,__102_fv)\n",
      "\t__101_x6 = torch.Tensor.contiguous(__103_fv)\n",
      "\t__104__20 = torch.Tensor.size(__101_x6,0)\n",
      "\t__106__22 = torch.Tensor.size(__101_x6,1)\n",
      "\t__108__24 = torch.Tensor.size(__101_x6,-2)\n",
      "\t__109__25 = torch.Tensor.size(__101_x6,-1)\n",
      "\t__112_fv = torch.mul(__108__24,__109__25)\n",
      "\t__111_fv = [__104__20,__106__22,__112_fv]\n",
      "\t__110_x7 = torch.Tensor.view(__101_x6,__111_fv)\n",
      "\t__119__4 = torch.Tensor.size(__110_x7,-1)\n",
      "\t__121_fv = [-1,__119__4]\n",
      "\t__122_fv = torch.Tensor.view(__110_x7,__121_fv)\n",
      "\t__120_x0 = torch.addmm(self.h[0].attn.c_proj.bias,__122_fv,self.h[0].attn.c_proj.weight)\n",
      "\t__115__0 = torch.Tensor.size(__110_x7,0)\n",
      "\t__117__2 = torch.Tensor.size(__110_x7,1)\n",
      "\t__123_fv = [__115__0,__117__2,768]\n",
      "\t__124_fv = torch.Tensor.view(__120_x0,__123_fv)\n",
      "\t__125_input = torch.add(__34_input0,__124_fv)\n",
      "\t__130_fv = [768]\n",
      "\t__129_x = torch.layer_norm(__125_input,__130_fv,self.h[0].ln_2.weight,self.h[0].ln_2.bias)\n",
      "\t__141__4 = torch.Tensor.size(__129_x,-1)\n",
      "\t__143_fv = [-1,__141__4]\n",
      "\t__144_fv = torch.Tensor.view(__129_x,__143_fv)\n",
      "\t__142_x = torch.addmm(self.h[0].feedforward.c_fc.bias,__144_fv,self.h[0].feedforward.c_fc.weight)\n",
      "\t__137__0 = torch.Tensor.size(__129_x,0)\n",
      "\t__139__2 = torch.Tensor.size(__129_x,1)\n",
      "\t__145_fv = [__137__0,__139__2,3072]\n",
      "\t__146_fv = torch.Tensor.view(__142_x,__145_fv)\n",
      "\t__134_x = torch.nn.functional.gelu(__146_fv)\n",
      "\t__154__4 = torch.Tensor.size(__134_x,-1)\n",
      "\t__156_fv = [-1,__154__4]\n",
      "\t__157_fv = torch.Tensor.view(__134_x,__156_fv)\n",
      "\t__155_x0 = torch.addmm(self.h[0].feedforward.c_proj.bias,__157_fv,self.h[0].feedforward.c_proj.weight)\n",
      "\t__150__0 = torch.Tensor.size(__134_x,0)\n",
      "\t__152__2 = torch.Tensor.size(__134_x,1)\n",
      "\t__158_fv = [__150__0,__152__2,768]\n",
      "\t__159_fv = torch.Tensor.view(__155_x0,__158_fv)\n",
      "\t__160__0 = torch.dropout(__159_fv,0.1,False)\n",
      "\t__161_fv = torch.add(__125_input,__160__0)\n",
      "\t__171_fv = [768]\n",
      "\t__170_x = torch.layer_norm(__161_fv,__171_fv,self.h[1].ln_1.weight,self.h[1].ln_1.bias)\n",
      "\t__183__4 = torch.Tensor.size(__170_x,-1)\n",
      "\t__185_fv = [-1,__183__4]\n",
      "\t__186_fv = torch.Tensor.view(__170_x,__185_fv)\n",
      "\t__184_x = torch.addmm(self.h[1].attn.c_attn.bias,__186_fv,self.h[1].attn.c_attn.weight)\n",
      "\t__179__0 = torch.Tensor.size(__170_x,0)\n",
      "\t__181__2 = torch.Tensor.size(__170_x,1)\n",
      "\t__187_fv = [__179__0,__181__2,2304]\n",
      "\t__188_fv = torch.Tensor.view(__184_x,__187_fv)\n",
      "\t__176__0 = torch.split(__188_fv,768,2)\n",
      "\t__190_x = __176__0[0]\n",
      "\t__193__1 = torch.Tensor.size(__190_x,0)\n",
      "\t__195__3 = torch.Tensor.size(__190_x,1)\n",
      "\t__197__5 = torch.Tensor.size(__190_x,-1)\n",
      "\t__198__6 = torch.div(__197__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__200_fv = [__193__1,__195__3,12,__198__6]\n",
      "\t__199_x2 = torch.Tensor.view(__190_x,__200_fv)\n",
      "\t__202_fv = [0,2,1,3]\n",
      "\t__201_q = torch.permute(__199_x2,__202_fv)\n",
      "\t__191_x0 = __176__0[1]\n",
      "\t__203__7 = torch.Tensor.size(__191_x0,0)\n",
      "\t__205__9 = torch.Tensor.size(__191_x0,1)\n",
      "\t__207__11 = torch.Tensor.size(__191_x0,-1)\n",
      "\t__208__12 = torch.div(__207__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__210_fv = [__203__7,__205__9,12,__208__12]\n",
      "\t__209_x3 = torch.Tensor.view(__191_x0,__210_fv)\n",
      "\t__212_fv = [0,2,1,3]\n",
      "\t__211_k = torch.permute(__209_x3,__212_fv)\n",
      "\t__224_fv = torch.transpose(__211_k,-2,-1)\n",
      "\t__223_scores = torch.matmul(__201_q,__224_fv)\n",
      "\t__226_fv = torch.softmax(__223_scores,-1)\n",
      "\t__227_scores = torch.dropout(__226_fv,0.1,False)\n",
      "\t__192_x1 = __176__0[2]\n",
      "\t__213__13 = torch.Tensor.size(__192_x1,0)\n",
      "\t__215__15 = torch.Tensor.size(__192_x1,1)\n",
      "\t__217__17 = torch.Tensor.size(__192_x1,-1)\n",
      "\t__218__18 = torch.div(__217__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__220_fv = [__213__13,__215__15,12,__218__18]\n",
      "\t__219_x4 = torch.Tensor.view(__192_x1,__220_fv)\n",
      "\t__222_fv = [0,2,1,3]\n",
      "\t__221_v = torch.permute(__219_x4,__222_fv)\n",
      "\t__228_x5 = torch.matmul(__227_scores,__221_v)\n",
      "\t__230_fv = [0,2,1,3]\n",
      "\t__231_fv = torch.permute(__228_x5,__230_fv)\n",
      "\t__229_x6 = torch.Tensor.contiguous(__231_fv)\n",
      "\t__232__20 = torch.Tensor.size(__229_x6,0)\n",
      "\t__234__22 = torch.Tensor.size(__229_x6,1)\n",
      "\t__236__24 = torch.Tensor.size(__229_x6,-2)\n",
      "\t__237__25 = torch.Tensor.size(__229_x6,-1)\n",
      "\t__240_fv = torch.mul(__236__24,__237__25)\n",
      "\t__239_fv = [__232__20,__234__22,__240_fv]\n",
      "\t__238_x7 = torch.Tensor.view(__229_x6,__239_fv)\n",
      "\t__247__4 = torch.Tensor.size(__238_x7,-1)\n",
      "\t__249_fv = [-1,__247__4]\n",
      "\t__250_fv = torch.Tensor.view(__238_x7,__249_fv)\n",
      "\t__248_x0 = torch.addmm(self.h[1].attn.c_proj.bias,__250_fv,self.h[1].attn.c_proj.weight)\n",
      "\t__243__0 = torch.Tensor.size(__238_x7,0)\n",
      "\t__245__2 = torch.Tensor.size(__238_x7,1)\n",
      "\t__251_fv = [__243__0,__245__2,768]\n",
      "\t__252_fv = torch.Tensor.view(__248_x0,__251_fv)\n",
      "\t__253_input = torch.add(__161_fv,__252_fv)\n",
      "\t__258_fv = [768]\n",
      "\t__257_x = torch.layer_norm(__253_input,__258_fv,self.h[1].ln_2.weight,self.h[1].ln_2.bias)\n",
      "\t__269__4 = torch.Tensor.size(__257_x,-1)\n",
      "\t__271_fv = [-1,__269__4]\n",
      "\t__272_fv = torch.Tensor.view(__257_x,__271_fv)\n",
      "\t__270_x = torch.addmm(self.h[1].feedforward.c_fc.bias,__272_fv,self.h[1].feedforward.c_fc.weight)\n",
      "\t__265__0 = torch.Tensor.size(__257_x,0)\n",
      "\t__267__2 = torch.Tensor.size(__257_x,1)\n",
      "\t__273_fv = [__265__0,__267__2,3072]\n",
      "\t__274_fv = torch.Tensor.view(__270_x,__273_fv)\n",
      "\t__262_x = torch.nn.functional.gelu(__274_fv)\n",
      "\t__282__4 = torch.Tensor.size(__262_x,-1)\n",
      "\t__284_fv = [-1,__282__4]\n",
      "\t__285_fv = torch.Tensor.view(__262_x,__284_fv)\n",
      "\t__283_x0 = torch.addmm(self.h[1].feedforward.c_proj.bias,__285_fv,self.h[1].feedforward.c_proj.weight)\n",
      "\t__278__0 = torch.Tensor.size(__262_x,0)\n",
      "\t__280__2 = torch.Tensor.size(__262_x,1)\n",
      "\t__286_fv = [__278__0,__280__2,768]\n",
      "\t__287_fv = torch.Tensor.view(__283_x0,__286_fv)\n",
      "\t__288__0 = torch.dropout(__287_fv,0.1,False)\n",
      "\t__289_fv = torch.add(__253_input,__288__0)\n",
      "\t__298_fv = [768]\n",
      "\t__297_x = torch.layer_norm(__289_fv,__298_fv,self.h[2].ln_1.weight,self.h[2].ln_1.bias)\n",
      "\t__310__4 = torch.Tensor.size(__297_x,-1)\n",
      "\t__312_fv = [-1,__310__4]\n",
      "\t__313_fv = torch.Tensor.view(__297_x,__312_fv)\n",
      "\t__311_x = torch.addmm(self.h[2].attn.c_attn.bias,__313_fv,self.h[2].attn.c_attn.weight)\n",
      "\t__306__0 = torch.Tensor.size(__297_x,0)\n",
      "\t__308__2 = torch.Tensor.size(__297_x,1)\n",
      "\t__314_fv = [__306__0,__308__2,2304]\n",
      "\t__315_fv = torch.Tensor.view(__311_x,__314_fv)\n",
      "\t__303__0 = torch.split(__315_fv,768,2)\n",
      "\t__317_x = __303__0[0]\n",
      "\t__320__1 = torch.Tensor.size(__317_x,0)\n",
      "\t__322__3 = torch.Tensor.size(__317_x,1)\n",
      "\t__324__5 = torch.Tensor.size(__317_x,-1)\n",
      "\t__325__6 = torch.div(__324__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__327_fv = [__320__1,__322__3,12,__325__6]\n",
      "\t__326_x2 = torch.Tensor.view(__317_x,__327_fv)\n",
      "\t__329_fv = [0,2,1,3]\n",
      "\t__328_q = torch.permute(__326_x2,__329_fv)\n",
      "\t__318_x0 = __303__0[1]\n",
      "\t__330__7 = torch.Tensor.size(__318_x0,0)\n",
      "\t__332__9 = torch.Tensor.size(__318_x0,1)\n",
      "\t__334__11 = torch.Tensor.size(__318_x0,-1)\n",
      "\t__335__12 = torch.div(__334__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__337_fv = [__330__7,__332__9,12,__335__12]\n",
      "\t__336_x3 = torch.Tensor.view(__318_x0,__337_fv)\n",
      "\t__339_fv = [0,2,1,3]\n",
      "\t__338_k = torch.permute(__336_x3,__339_fv)\n",
      "\t__351_fv = torch.transpose(__338_k,-2,-1)\n",
      "\t__350_scores = torch.matmul(__328_q,__351_fv)\n",
      "\t__353_fv = torch.softmax(__350_scores,-1)\n",
      "\t__354_scores = torch.dropout(__353_fv,0.1,False)\n",
      "\t__319_x1 = __303__0[2]\n",
      "\t__340__13 = torch.Tensor.size(__319_x1,0)\n",
      "\t__342__15 = torch.Tensor.size(__319_x1,1)\n",
      "\t__344__17 = torch.Tensor.size(__319_x1,-1)\n",
      "\t__345__18 = torch.div(__344__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__347_fv = [__340__13,__342__15,12,__345__18]\n",
      "\t__346_x4 = torch.Tensor.view(__319_x1,__347_fv)\n",
      "\t__349_fv = [0,2,1,3]\n",
      "\t__348_v = torch.permute(__346_x4,__349_fv)\n",
      "\t__355_x5 = torch.matmul(__354_scores,__348_v)\n",
      "\t__357_fv = [0,2,1,3]\n",
      "\t__358_fv = torch.permute(__355_x5,__357_fv)\n",
      "\t__356_x6 = torch.Tensor.contiguous(__358_fv)\n",
      "\t__359__20 = torch.Tensor.size(__356_x6,0)\n",
      "\t__361__22 = torch.Tensor.size(__356_x6,1)\n",
      "\t__363__24 = torch.Tensor.size(__356_x6,-2)\n",
      "\t__364__25 = torch.Tensor.size(__356_x6,-1)\n",
      "\t__367_fv = torch.mul(__363__24,__364__25)\n",
      "\t__366_fv = [__359__20,__361__22,__367_fv]\n",
      "\t__365_x7 = torch.Tensor.view(__356_x6,__366_fv)\n",
      "\t__374__4 = torch.Tensor.size(__365_x7,-1)\n",
      "\t__376_fv = [-1,__374__4]\n",
      "\t__377_fv = torch.Tensor.view(__365_x7,__376_fv)\n",
      "\t__375_x0 = torch.addmm(self.h[2].attn.c_proj.bias,__377_fv,self.h[2].attn.c_proj.weight)\n",
      "\t__370__0 = torch.Tensor.size(__365_x7,0)\n",
      "\t__372__2 = torch.Tensor.size(__365_x7,1)\n",
      "\t__378_fv = [__370__0,__372__2,768]\n",
      "\t__379_fv = torch.Tensor.view(__375_x0,__378_fv)\n",
      "\t__380_input = torch.add(__289_fv,__379_fv)\n",
      "\t__385_fv = [768]\n",
      "\t__384_x = torch.layer_norm(__380_input,__385_fv,self.h[2].ln_2.weight,self.h[2].ln_2.bias)\n",
      "\t__396__4 = torch.Tensor.size(__384_x,-1)\n",
      "\t__398_fv = [-1,__396__4]\n",
      "\t__399_fv = torch.Tensor.view(__384_x,__398_fv)\n",
      "\t__397_x = torch.addmm(self.h[2].feedforward.c_fc.bias,__399_fv,self.h[2].feedforward.c_fc.weight)\n",
      "\t__392__0 = torch.Tensor.size(__384_x,0)\n",
      "\t__394__2 = torch.Tensor.size(__384_x,1)\n",
      "\t__400_fv = [__392__0,__394__2,3072]\n",
      "\t__401_fv = torch.Tensor.view(__397_x,__400_fv)\n",
      "\t__389_x = torch.nn.functional.gelu(__401_fv)\n",
      "\t__409__4 = torch.Tensor.size(__389_x,-1)\n",
      "\t__411_fv = [-1,__409__4]\n",
      "\t__412_fv = torch.Tensor.view(__389_x,__411_fv)\n",
      "\t__410_x0 = torch.addmm(self.h[2].feedforward.c_proj.bias,__412_fv,self.h[2].feedforward.c_proj.weight)\n",
      "\t__405__0 = torch.Tensor.size(__389_x,0)\n",
      "\t__407__2 = torch.Tensor.size(__389_x,1)\n",
      "\t__413_fv = [__405__0,__407__2,768]\n",
      "\t__414_fv = torch.Tensor.view(__410_x0,__413_fv)\n",
      "\t__415__0 = torch.dropout(__414_fv,0.1,False)\n",
      "\t__416_fv = torch.add(__380_input,__415__0)\n",
      "\t__425_fv = [768]\n",
      "\t__424_x = torch.layer_norm(__416_fv,__425_fv,self.h[3].ln_1.weight,self.h[3].ln_1.bias)\n",
      "\t__437__4 = torch.Tensor.size(__424_x,-1)\n",
      "\t__439_fv = [-1,__437__4]\n",
      "\t__440_fv = torch.Tensor.view(__424_x,__439_fv)\n",
      "\t__438_x = torch.addmm(self.h[3].attn.c_attn.bias,__440_fv,self.h[3].attn.c_attn.weight)\n",
      "\t__433__0 = torch.Tensor.size(__424_x,0)\n",
      "\t__435__2 = torch.Tensor.size(__424_x,1)\n",
      "\t__441_fv = [__433__0,__435__2,2304]\n",
      "\t__442_fv = torch.Tensor.view(__438_x,__441_fv)\n",
      "\t__430__0 = torch.split(__442_fv,768,2)\n",
      "\t__444_x = __430__0[0]\n",
      "\t__447__1 = torch.Tensor.size(__444_x,0)\n",
      "\t__449__3 = torch.Tensor.size(__444_x,1)\n",
      "\t__451__5 = torch.Tensor.size(__444_x,-1)\n",
      "\t__452__6 = torch.div(__451__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__454_fv = [__447__1,__449__3,12,__452__6]\n",
      "\t__453_x2 = torch.Tensor.view(__444_x,__454_fv)\n",
      "\t__456_fv = [0,2,1,3]\n",
      "\t__455_q = torch.permute(__453_x2,__456_fv)\n",
      "\t__445_x0 = __430__0[1]\n",
      "\t__457__7 = torch.Tensor.size(__445_x0,0)\n",
      "\t__459__9 = torch.Tensor.size(__445_x0,1)\n",
      "\t__461__11 = torch.Tensor.size(__445_x0,-1)\n",
      "\t__462__12 = torch.div(__461__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__464_fv = [__457__7,__459__9,12,__462__12]\n",
      "\t__463_x3 = torch.Tensor.view(__445_x0,__464_fv)\n",
      "\t__466_fv = [0,2,1,3]\n",
      "\t__465_k = torch.permute(__463_x3,__466_fv)\n",
      "\t__478_fv = torch.transpose(__465_k,-2,-1)\n",
      "\t__477_scores = torch.matmul(__455_q,__478_fv)\n",
      "\t__480_fv = torch.softmax(__477_scores,-1)\n",
      "\t__481_scores = torch.dropout(__480_fv,0.1,False)\n",
      "\t__446_x1 = __430__0[2]\n",
      "\t__467__13 = torch.Tensor.size(__446_x1,0)\n",
      "\t__469__15 = torch.Tensor.size(__446_x1,1)\n",
      "\t__471__17 = torch.Tensor.size(__446_x1,-1)\n",
      "\t__472__18 = torch.div(__471__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__474_fv = [__467__13,__469__15,12,__472__18]\n",
      "\t__473_x4 = torch.Tensor.view(__446_x1,__474_fv)\n",
      "\t__476_fv = [0,2,1,3]\n",
      "\t__475_v = torch.permute(__473_x4,__476_fv)\n",
      "\t__482_x5 = torch.matmul(__481_scores,__475_v)\n",
      "\t__484_fv = [0,2,1,3]\n",
      "\t__485_fv = torch.permute(__482_x5,__484_fv)\n",
      "\t__483_x6 = torch.Tensor.contiguous(__485_fv)\n",
      "\t__486__20 = torch.Tensor.size(__483_x6,0)\n",
      "\t__488__22 = torch.Tensor.size(__483_x6,1)\n",
      "\t__490__24 = torch.Tensor.size(__483_x6,-2)\n",
      "\t__491__25 = torch.Tensor.size(__483_x6,-1)\n",
      "\t__494_fv = torch.mul(__490__24,__491__25)\n",
      "\t__493_fv = [__486__20,__488__22,__494_fv]\n",
      "\t__492_x7 = torch.Tensor.view(__483_x6,__493_fv)\n",
      "\t__501__4 = torch.Tensor.size(__492_x7,-1)\n",
      "\t__503_fv = [-1,__501__4]\n",
      "\t__504_fv = torch.Tensor.view(__492_x7,__503_fv)\n",
      "\t__502_x0 = torch.addmm(self.h[3].attn.c_proj.bias,__504_fv,self.h[3].attn.c_proj.weight)\n",
      "\t__497__0 = torch.Tensor.size(__492_x7,0)\n",
      "\t__499__2 = torch.Tensor.size(__492_x7,1)\n",
      "\t__505_fv = [__497__0,__499__2,768]\n",
      "\t__506_fv = torch.Tensor.view(__502_x0,__505_fv)\n",
      "\t__507_input = torch.add(__416_fv,__506_fv)\n",
      "\t__512_fv = [768]\n",
      "\t__511_x = torch.layer_norm(__507_input,__512_fv,self.h[3].ln_2.weight,self.h[3].ln_2.bias)\n",
      "\t__523__4 = torch.Tensor.size(__511_x,-1)\n",
      "\t__525_fv = [-1,__523__4]\n",
      "\t__526_fv = torch.Tensor.view(__511_x,__525_fv)\n",
      "\t__524_x = torch.addmm(self.h[3].feedforward.c_fc.bias,__526_fv,self.h[3].feedforward.c_fc.weight)\n",
      "\t__519__0 = torch.Tensor.size(__511_x,0)\n",
      "\t__521__2 = torch.Tensor.size(__511_x,1)\n",
      "\t__527_fv = [__519__0,__521__2,3072]\n",
      "\t__528_fv = torch.Tensor.view(__524_x,__527_fv)\n",
      "\t__516_x = torch.nn.functional.gelu(__528_fv)\n",
      "\t__536__4 = torch.Tensor.size(__516_x,-1)\n",
      "\t__538_fv = [-1,__536__4]\n",
      "\t__539_fv = torch.Tensor.view(__516_x,__538_fv)\n",
      "\t__537_x0 = torch.addmm(self.h[3].feedforward.c_proj.bias,__539_fv,self.h[3].feedforward.c_proj.weight)\n",
      "\t__532__0 = torch.Tensor.size(__516_x,0)\n",
      "\t__534__2 = torch.Tensor.size(__516_x,1)\n",
      "\t__540_fv = [__532__0,__534__2,768]\n",
      "\t__541_fv = torch.Tensor.view(__537_x0,__540_fv)\n",
      "\t__542__0 = torch.dropout(__541_fv,0.1,False)\n",
      "\t__543_fv = torch.add(__507_input,__542__0)\n",
      "\t__553_fv = [768]\n",
      "\t__552_x = torch.layer_norm(__543_fv,__553_fv,self.h[4].ln_1.weight,self.h[4].ln_1.bias)\n",
      "\t__565__4 = torch.Tensor.size(__552_x,-1)\n",
      "\t__567_fv = [-1,__565__4]\n",
      "\t__568_fv = torch.Tensor.view(__552_x,__567_fv)\n",
      "\t__566_x = torch.addmm(self.h[4].attn.c_attn.bias,__568_fv,self.h[4].attn.c_attn.weight)\n",
      "\t__561__0 = torch.Tensor.size(__552_x,0)\n",
      "\t__563__2 = torch.Tensor.size(__552_x,1)\n",
      "\t__569_fv = [__561__0,__563__2,2304]\n",
      "\t__570_fv = torch.Tensor.view(__566_x,__569_fv)\n",
      "\t__558__0 = torch.split(__570_fv,768,2)\n",
      "\t__572_x = __558__0[0]\n",
      "\t__575__1 = torch.Tensor.size(__572_x,0)\n",
      "\t__577__3 = torch.Tensor.size(__572_x,1)\n",
      "\t__579__5 = torch.Tensor.size(__572_x,-1)\n",
      "\t__580__6 = torch.div(__579__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__582_fv = [__575__1,__577__3,12,__580__6]\n",
      "\t__581_x2 = torch.Tensor.view(__572_x,__582_fv)\n",
      "\t__584_fv = [0,2,1,3]\n",
      "\t__583_q = torch.permute(__581_x2,__584_fv)\n",
      "\t__573_x0 = __558__0[1]\n",
      "\t__585__7 = torch.Tensor.size(__573_x0,0)\n",
      "\t__587__9 = torch.Tensor.size(__573_x0,1)\n",
      "\t__589__11 = torch.Tensor.size(__573_x0,-1)\n",
      "\t__590__12 = torch.div(__589__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__592_fv = [__585__7,__587__9,12,__590__12]\n",
      "\t__591_x3 = torch.Tensor.view(__573_x0,__592_fv)\n",
      "\t__594_fv = [0,2,1,3]\n",
      "\t__593_k = torch.permute(__591_x3,__594_fv)\n",
      "\t__606_fv = torch.transpose(__593_k,-2,-1)\n",
      "\t__605_scores = torch.matmul(__583_q,__606_fv)\n",
      "\t__608_fv = torch.softmax(__605_scores,-1)\n",
      "\t__609_scores = torch.dropout(__608_fv,0.1,False)\n",
      "\t__574_x1 = __558__0[2]\n",
      "\t__595__13 = torch.Tensor.size(__574_x1,0)\n",
      "\t__597__15 = torch.Tensor.size(__574_x1,1)\n",
      "\t__599__17 = torch.Tensor.size(__574_x1,-1)\n",
      "\t__600__18 = torch.div(__599__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__602_fv = [__595__13,__597__15,12,__600__18]\n",
      "\t__601_x4 = torch.Tensor.view(__574_x1,__602_fv)\n",
      "\t__604_fv = [0,2,1,3]\n",
      "\t__603_v = torch.permute(__601_x4,__604_fv)\n",
      "\t__610_x5 = torch.matmul(__609_scores,__603_v)\n",
      "\t__612_fv = [0,2,1,3]\n",
      "\t__613_fv = torch.permute(__610_x5,__612_fv)\n",
      "\t__611_x6 = torch.Tensor.contiguous(__613_fv)\n",
      "\t__614__20 = torch.Tensor.size(__611_x6,0)\n",
      "\t__616__22 = torch.Tensor.size(__611_x6,1)\n",
      "\t__618__24 = torch.Tensor.size(__611_x6,-2)\n",
      "\t__619__25 = torch.Tensor.size(__611_x6,-1)\n",
      "\t__622_fv = torch.mul(__618__24,__619__25)\n",
      "\t__621_fv = [__614__20,__616__22,__622_fv]\n",
      "\t__620_x7 = torch.Tensor.view(__611_x6,__621_fv)\n",
      "\t__629__4 = torch.Tensor.size(__620_x7,-1)\n",
      "\t__631_fv = [-1,__629__4]\n",
      "\t__632_fv = torch.Tensor.view(__620_x7,__631_fv)\n",
      "\t__630_x0 = torch.addmm(self.h[4].attn.c_proj.bias,__632_fv,self.h[4].attn.c_proj.weight)\n",
      "\t__625__0 = torch.Tensor.size(__620_x7,0)\n",
      "\t__627__2 = torch.Tensor.size(__620_x7,1)\n",
      "\t__633_fv = [__625__0,__627__2,768]\n",
      "\t__634_fv = torch.Tensor.view(__630_x0,__633_fv)\n",
      "\t__635_input = torch.add(__543_fv,__634_fv)\n",
      "\t__640_fv = [768]\n",
      "\t__639_x = torch.layer_norm(__635_input,__640_fv,self.h[4].ln_2.weight,self.h[4].ln_2.bias)\n",
      "\t__651__4 = torch.Tensor.size(__639_x,-1)\n",
      "\t__653_fv = [-1,__651__4]\n",
      "\t__654_fv = torch.Tensor.view(__639_x,__653_fv)\n",
      "\t__652_x = torch.addmm(self.h[4].feedforward.c_fc.bias,__654_fv,self.h[4].feedforward.c_fc.weight)\n",
      "\t__647__0 = torch.Tensor.size(__639_x,0)\n",
      "\t__649__2 = torch.Tensor.size(__639_x,1)\n",
      "\t__655_fv = [__647__0,__649__2,3072]\n",
      "\t__656_fv = torch.Tensor.view(__652_x,__655_fv)\n",
      "\t__644_x = torch.nn.functional.gelu(__656_fv)\n",
      "\t__664__4 = torch.Tensor.size(__644_x,-1)\n",
      "\t__666_fv = [-1,__664__4]\n",
      "\t__667_fv = torch.Tensor.view(__644_x,__666_fv)\n",
      "\t__665_x0 = torch.addmm(self.h[4].feedforward.c_proj.bias,__667_fv,self.h[4].feedforward.c_proj.weight)\n",
      "\t__660__0 = torch.Tensor.size(__644_x,0)\n",
      "\t__662__2 = torch.Tensor.size(__644_x,1)\n",
      "\t__668_fv = [__660__0,__662__2,768]\n",
      "\t__669_fv = torch.Tensor.view(__665_x0,__668_fv)\n",
      "\t__670__0 = torch.dropout(__669_fv,0.1,False)\n",
      "\t__671_fv = torch.add(__635_input,__670__0)\n",
      "\t__680_fv = [768]\n",
      "\t__679_x = torch.layer_norm(__671_fv,__680_fv,self.h[5].ln_1.weight,self.h[5].ln_1.bias)\n",
      "\t__692__4 = torch.Tensor.size(__679_x,-1)\n",
      "\t__694_fv = [-1,__692__4]\n",
      "\t__695_fv = torch.Tensor.view(__679_x,__694_fv)\n",
      "\t__693_x = torch.addmm(self.h[5].attn.c_attn.bias,__695_fv,self.h[5].attn.c_attn.weight)\n",
      "\t__688__0 = torch.Tensor.size(__679_x,0)\n",
      "\t__690__2 = torch.Tensor.size(__679_x,1)\n",
      "\t__696_fv = [__688__0,__690__2,2304]\n",
      "\t__697_fv = torch.Tensor.view(__693_x,__696_fv)\n",
      "\t__685__0 = torch.split(__697_fv,768,2)\n",
      "\t__699_x = __685__0[0]\n",
      "\t__702__1 = torch.Tensor.size(__699_x,0)\n",
      "\t__704__3 = torch.Tensor.size(__699_x,1)\n",
      "\t__706__5 = torch.Tensor.size(__699_x,-1)\n",
      "\t__707__6 = torch.div(__706__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__709_fv = [__702__1,__704__3,12,__707__6]\n",
      "\t__708_x2 = torch.Tensor.view(__699_x,__709_fv)\n",
      "\t__711_fv = [0,2,1,3]\n",
      "\t__710_q = torch.permute(__708_x2,__711_fv)\n",
      "\t__700_x0 = __685__0[1]\n",
      "\t__712__7 = torch.Tensor.size(__700_x0,0)\n",
      "\t__714__9 = torch.Tensor.size(__700_x0,1)\n",
      "\t__716__11 = torch.Tensor.size(__700_x0,-1)\n",
      "\t__717__12 = torch.div(__716__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__719_fv = [__712__7,__714__9,12,__717__12]\n",
      "\t__718_x3 = torch.Tensor.view(__700_x0,__719_fv)\n",
      "\t__721_fv = [0,2,1,3]\n",
      "\t__720_k = torch.permute(__718_x3,__721_fv)\n",
      "\t__733_fv = torch.transpose(__720_k,-2,-1)\n",
      "\t__732_scores = torch.matmul(__710_q,__733_fv)\n",
      "\t__735_fv = torch.softmax(__732_scores,-1)\n",
      "\t__736_scores = torch.dropout(__735_fv,0.1,False)\n",
      "\t__701_x1 = __685__0[2]\n",
      "\t__722__13 = torch.Tensor.size(__701_x1,0)\n",
      "\t__724__15 = torch.Tensor.size(__701_x1,1)\n",
      "\t__726__17 = torch.Tensor.size(__701_x1,-1)\n",
      "\t__727__18 = torch.div(__726__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__729_fv = [__722__13,__724__15,12,__727__18]\n",
      "\t__728_x4 = torch.Tensor.view(__701_x1,__729_fv)\n",
      "\t__731_fv = [0,2,1,3]\n",
      "\t__730_v = torch.permute(__728_x4,__731_fv)\n",
      "\t__737_x5 = torch.matmul(__736_scores,__730_v)\n",
      "\t__739_fv = [0,2,1,3]\n",
      "\t__740_fv = torch.permute(__737_x5,__739_fv)\n",
      "\t__738_x6 = torch.Tensor.contiguous(__740_fv)\n",
      "\t__741__20 = torch.Tensor.size(__738_x6,0)\n",
      "\t__743__22 = torch.Tensor.size(__738_x6,1)\n",
      "\t__745__24 = torch.Tensor.size(__738_x6,-2)\n",
      "\t__746__25 = torch.Tensor.size(__738_x6,-1)\n",
      "\t__749_fv = torch.mul(__745__24,__746__25)\n",
      "\t__748_fv = [__741__20,__743__22,__749_fv]\n",
      "\t__747_x7 = torch.Tensor.view(__738_x6,__748_fv)\n",
      "\t__756__4 = torch.Tensor.size(__747_x7,-1)\n",
      "\t__758_fv = [-1,__756__4]\n",
      "\t__759_fv = torch.Tensor.view(__747_x7,__758_fv)\n",
      "\t__757_x0 = torch.addmm(self.h[5].attn.c_proj.bias,__759_fv,self.h[5].attn.c_proj.weight)\n",
      "\t__752__0 = torch.Tensor.size(__747_x7,0)\n",
      "\t__754__2 = torch.Tensor.size(__747_x7,1)\n",
      "\t__760_fv = [__752__0,__754__2,768]\n",
      "\t__761_fv = torch.Tensor.view(__757_x0,__760_fv)\n",
      "\t__762_input = torch.add(__671_fv,__761_fv)\n",
      "\t__767_fv = [768]\n",
      "\t__766_x = torch.layer_norm(__762_input,__767_fv,self.h[5].ln_2.weight,self.h[5].ln_2.bias)\n",
      "\t__778__4 = torch.Tensor.size(__766_x,-1)\n",
      "\t__780_fv = [-1,__778__4]\n",
      "\t__781_fv = torch.Tensor.view(__766_x,__780_fv)\n",
      "\t__779_x = torch.addmm(self.h[5].feedforward.c_fc.bias,__781_fv,self.h[5].feedforward.c_fc.weight)\n",
      "\t__774__0 = torch.Tensor.size(__766_x,0)\n",
      "\t__776__2 = torch.Tensor.size(__766_x,1)\n",
      "\t__782_fv = [__774__0,__776__2,3072]\n",
      "\t__783_fv = torch.Tensor.view(__779_x,__782_fv)\n",
      "\t__771_x = torch.nn.functional.gelu(__783_fv)\n",
      "\t__791__4 = torch.Tensor.size(__771_x,-1)\n",
      "\t__793_fv = [-1,__791__4]\n",
      "\t__794_fv = torch.Tensor.view(__771_x,__793_fv)\n",
      "\t__792_x0 = torch.addmm(self.h[5].feedforward.c_proj.bias,__794_fv,self.h[5].feedforward.c_proj.weight)\n",
      "\t__787__0 = torch.Tensor.size(__771_x,0)\n",
      "\t__789__2 = torch.Tensor.size(__771_x,1)\n",
      "\t__795_fv = [__787__0,__789__2,768]\n",
      "\t__796_fv = torch.Tensor.view(__792_x0,__795_fv)\n",
      "\t__797__0 = torch.dropout(__796_fv,0.1,False)\n",
      "\t__798_fv = torch.add(__762_input,__797__0)\n",
      "\t__807_fv = [768]\n",
      "\t__806_x = torch.layer_norm(__798_fv,__807_fv,self.h[6].ln_1.weight,self.h[6].ln_1.bias)\n",
      "\t__819__4 = torch.Tensor.size(__806_x,-1)\n",
      "\t__821_fv = [-1,__819__4]\n",
      "\t__822_fv = torch.Tensor.view(__806_x,__821_fv)\n",
      "\t__820_x = torch.addmm(self.h[6].attn.c_attn.bias,__822_fv,self.h[6].attn.c_attn.weight)\n",
      "\t__815__0 = torch.Tensor.size(__806_x,0)\n",
      "\t__817__2 = torch.Tensor.size(__806_x,1)\n",
      "\t__823_fv = [__815__0,__817__2,2304]\n",
      "\t__824_fv = torch.Tensor.view(__820_x,__823_fv)\n",
      "\t__812__0 = torch.split(__824_fv,768,2)\n",
      "\t__826_x = __812__0[0]\n",
      "\t__829__1 = torch.Tensor.size(__826_x,0)\n",
      "\t__831__3 = torch.Tensor.size(__826_x,1)\n",
      "\t__833__5 = torch.Tensor.size(__826_x,-1)\n",
      "\t__834__6 = torch.div(__833__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__836_fv = [__829__1,__831__3,12,__834__6]\n",
      "\t__835_x2 = torch.Tensor.view(__826_x,__836_fv)\n",
      "\t__838_fv = [0,2,1,3]\n",
      "\t__837_q = torch.permute(__835_x2,__838_fv)\n",
      "\t__827_x0 = __812__0[1]\n",
      "\t__839__7 = torch.Tensor.size(__827_x0,0)\n",
      "\t__841__9 = torch.Tensor.size(__827_x0,1)\n",
      "\t__843__11 = torch.Tensor.size(__827_x0,-1)\n",
      "\t__844__12 = torch.div(__843__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__846_fv = [__839__7,__841__9,12,__844__12]\n",
      "\t__845_x3 = torch.Tensor.view(__827_x0,__846_fv)\n",
      "\t__848_fv = [0,2,1,3]\n",
      "\t__847_k = torch.permute(__845_x3,__848_fv)\n",
      "\t__860_fv = torch.transpose(__847_k,-2,-1)\n",
      "\t__859_scores = torch.matmul(__837_q,__860_fv)\n",
      "\t__862_fv = torch.softmax(__859_scores,-1)\n",
      "\t__863_scores = torch.dropout(__862_fv,0.1,False)\n",
      "\t__828_x1 = __812__0[2]\n",
      "\t__849__13 = torch.Tensor.size(__828_x1,0)\n",
      "\t__851__15 = torch.Tensor.size(__828_x1,1)\n",
      "\t__853__17 = torch.Tensor.size(__828_x1,-1)\n",
      "\t__854__18 = torch.div(__853__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__856_fv = [__849__13,__851__15,12,__854__18]\n",
      "\t__855_x4 = torch.Tensor.view(__828_x1,__856_fv)\n",
      "\t__858_fv = [0,2,1,3]\n",
      "\t__857_v = torch.permute(__855_x4,__858_fv)\n",
      "\t__864_x5 = torch.matmul(__863_scores,__857_v)\n",
      "\t__866_fv = [0,2,1,3]\n",
      "\t__867_fv = torch.permute(__864_x5,__866_fv)\n",
      "\t__865_x6 = torch.Tensor.contiguous(__867_fv)\n",
      "\t__868__20 = torch.Tensor.size(__865_x6,0)\n",
      "\t__870__22 = torch.Tensor.size(__865_x6,1)\n",
      "\t__872__24 = torch.Tensor.size(__865_x6,-2)\n",
      "\t__873__25 = torch.Tensor.size(__865_x6,-1)\n",
      "\t__876_fv = torch.mul(__872__24,__873__25)\n",
      "\t__875_fv = [__868__20,__870__22,__876_fv]\n",
      "\t__874_x7 = torch.Tensor.view(__865_x6,__875_fv)\n",
      "\t__883__4 = torch.Tensor.size(__874_x7,-1)\n",
      "\t__885_fv = [-1,__883__4]\n",
      "\t__886_fv = torch.Tensor.view(__874_x7,__885_fv)\n",
      "\t__884_x0 = torch.addmm(self.h[6].attn.c_proj.bias,__886_fv,self.h[6].attn.c_proj.weight)\n",
      "\t__879__0 = torch.Tensor.size(__874_x7,0)\n",
      "\t__881__2 = torch.Tensor.size(__874_x7,1)\n",
      "\t__887_fv = [__879__0,__881__2,768]\n",
      "\t__888_fv = torch.Tensor.view(__884_x0,__887_fv)\n",
      "\t__889_input = torch.add(__798_fv,__888_fv)\n",
      "\t__894_fv = [768]\n",
      "\t__893_x = torch.layer_norm(__889_input,__894_fv,self.h[6].ln_2.weight,self.h[6].ln_2.bias)\n",
      "\t__905__4 = torch.Tensor.size(__893_x,-1)\n",
      "\t__907_fv = [-1,__905__4]\n",
      "\t__908_fv = torch.Tensor.view(__893_x,__907_fv)\n",
      "\t__906_x = torch.addmm(self.h[6].feedforward.c_fc.bias,__908_fv,self.h[6].feedforward.c_fc.weight)\n",
      "\t__901__0 = torch.Tensor.size(__893_x,0)\n",
      "\t__903__2 = torch.Tensor.size(__893_x,1)\n",
      "\t__909_fv = [__901__0,__903__2,3072]\n",
      "\t__910_fv = torch.Tensor.view(__906_x,__909_fv)\n",
      "\t__898_x = torch.nn.functional.gelu(__910_fv)\n",
      "\t__918__4 = torch.Tensor.size(__898_x,-1)\n",
      "\t__920_fv = [-1,__918__4]\n",
      "\t__921_fv = torch.Tensor.view(__898_x,__920_fv)\n",
      "\t__919_x0 = torch.addmm(self.h[6].feedforward.c_proj.bias,__921_fv,self.h[6].feedforward.c_proj.weight)\n",
      "\t__914__0 = torch.Tensor.size(__898_x,0)\n",
      "\t__916__2 = torch.Tensor.size(__898_x,1)\n",
      "\t__922_fv = [__914__0,__916__2,768]\n",
      "\t__923_fv = torch.Tensor.view(__919_x0,__922_fv)\n",
      "\t__924__0 = torch.dropout(__923_fv,0.1,False)\n",
      "\t__925_fv = torch.add(__889_input,__924__0)\n",
      "\t__935_fv = [768]\n",
      "\t__934_x = torch.layer_norm(__925_fv,__935_fv,self.h[7].ln_1.weight,self.h[7].ln_1.bias)\n",
      "\t__947__4 = torch.Tensor.size(__934_x,-1)\n",
      "\t__949_fv = [-1,__947__4]\n",
      "\t__950_fv = torch.Tensor.view(__934_x,__949_fv)\n",
      "\t__948_x = torch.addmm(self.h[7].attn.c_attn.bias,__950_fv,self.h[7].attn.c_attn.weight)\n",
      "\t__943__0 = torch.Tensor.size(__934_x,0)\n",
      "\t__945__2 = torch.Tensor.size(__934_x,1)\n",
      "\t__951_fv = [__943__0,__945__2,2304]\n",
      "\t__952_fv = torch.Tensor.view(__948_x,__951_fv)\n",
      "\t__940__0 = torch.split(__952_fv,768,2)\n",
      "\t__954_x = __940__0[0]\n",
      "\t__957__1 = torch.Tensor.size(__954_x,0)\n",
      "\t__959__3 = torch.Tensor.size(__954_x,1)\n",
      "\t__961__5 = torch.Tensor.size(__954_x,-1)\n",
      "\t__962__6 = torch.div(__961__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__964_fv = [__957__1,__959__3,12,__962__6]\n",
      "\t__963_x2 = torch.Tensor.view(__954_x,__964_fv)\n",
      "\t__966_fv = [0,2,1,3]\n",
      "\t__965_q = torch.permute(__963_x2,__966_fv)\n",
      "\t__955_x0 = __940__0[1]\n",
      "\t__967__7 = torch.Tensor.size(__955_x0,0)\n",
      "\t__969__9 = torch.Tensor.size(__955_x0,1)\n",
      "\t__971__11 = torch.Tensor.size(__955_x0,-1)\n",
      "\t__972__12 = torch.div(__971__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__974_fv = [__967__7,__969__9,12,__972__12]\n",
      "\t__973_x3 = torch.Tensor.view(__955_x0,__974_fv)\n",
      "\t__976_fv = [0,2,1,3]\n",
      "\t__975_k = torch.permute(__973_x3,__976_fv)\n",
      "\t__988_fv = torch.transpose(__975_k,-2,-1)\n",
      "\t__987_scores = torch.matmul(__965_q,__988_fv)\n",
      "\t__990_fv = torch.softmax(__987_scores,-1)\n",
      "\t__991_scores = torch.dropout(__990_fv,0.1,False)\n",
      "\t__956_x1 = __940__0[2]\n",
      "\t__977__13 = torch.Tensor.size(__956_x1,0)\n",
      "\t__979__15 = torch.Tensor.size(__956_x1,1)\n",
      "\t__981__17 = torch.Tensor.size(__956_x1,-1)\n",
      "\t__982__18 = torch.div(__981__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__984_fv = [__977__13,__979__15,12,__982__18]\n",
      "\t__983_x4 = torch.Tensor.view(__956_x1,__984_fv)\n",
      "\t__986_fv = [0,2,1,3]\n",
      "\t__985_v = torch.permute(__983_x4,__986_fv)\n",
      "\t__992_x5 = torch.matmul(__991_scores,__985_v)\n",
      "\t__994_fv = [0,2,1,3]\n",
      "\t__995_fv = torch.permute(__992_x5,__994_fv)\n",
      "\t__993_x6 = torch.Tensor.contiguous(__995_fv)\n",
      "\t__996__20 = torch.Tensor.size(__993_x6,0)\n",
      "\t__998__22 = torch.Tensor.size(__993_x6,1)\n",
      "\t__1000__24 = torch.Tensor.size(__993_x6,-2)\n",
      "\t__1001__25 = torch.Tensor.size(__993_x6,-1)\n",
      "\t__1004_fv = torch.mul(__1000__24,__1001__25)\n",
      "\t__1003_fv = [__996__20,__998__22,__1004_fv]\n",
      "\t__1002_x7 = torch.Tensor.view(__993_x6,__1003_fv)\n",
      "\t__1011__4 = torch.Tensor.size(__1002_x7,-1)\n",
      "\t__1013_fv = [-1,__1011__4]\n",
      "\t__1014_fv = torch.Tensor.view(__1002_x7,__1013_fv)\n",
      "\t__1012_x0 = torch.addmm(self.h[7].attn.c_proj.bias,__1014_fv,self.h[7].attn.c_proj.weight)\n",
      "\t__1007__0 = torch.Tensor.size(__1002_x7,0)\n",
      "\t__1009__2 = torch.Tensor.size(__1002_x7,1)\n",
      "\t__1015_fv = [__1007__0,__1009__2,768]\n",
      "\t__1016_fv = torch.Tensor.view(__1012_x0,__1015_fv)\n",
      "\t__1017_input = torch.add(__925_fv,__1016_fv)\n",
      "\t__1022_fv = [768]\n",
      "\t__1021_x = torch.layer_norm(__1017_input,__1022_fv,self.h[7].ln_2.weight,self.h[7].ln_2.bias)\n",
      "\t__1033__4 = torch.Tensor.size(__1021_x,-1)\n",
      "\t__1035_fv = [-1,__1033__4]\n",
      "\t__1036_fv = torch.Tensor.view(__1021_x,__1035_fv)\n",
      "\t__1034_x = torch.addmm(self.h[7].feedforward.c_fc.bias,__1036_fv,self.h[7].feedforward.c_fc.weight)\n",
      "\t__1029__0 = torch.Tensor.size(__1021_x,0)\n",
      "\t__1031__2 = torch.Tensor.size(__1021_x,1)\n",
      "\t__1037_fv = [__1029__0,__1031__2,3072]\n",
      "\t__1038_fv = torch.Tensor.view(__1034_x,__1037_fv)\n",
      "\t__1026_x = torch.nn.functional.gelu(__1038_fv)\n",
      "\t__1046__4 = torch.Tensor.size(__1026_x,-1)\n",
      "\t__1048_fv = [-1,__1046__4]\n",
      "\t__1049_fv = torch.Tensor.view(__1026_x,__1048_fv)\n",
      "\t__1047_x0 = torch.addmm(self.h[7].feedforward.c_proj.bias,__1049_fv,self.h[7].feedforward.c_proj.weight)\n",
      "\t__1042__0 = torch.Tensor.size(__1026_x,0)\n",
      "\t__1044__2 = torch.Tensor.size(__1026_x,1)\n",
      "\t__1050_fv = [__1042__0,__1044__2,768]\n",
      "\t__1051_fv = torch.Tensor.view(__1047_x0,__1050_fv)\n",
      "\t__1052__0 = torch.dropout(__1051_fv,0.1,False)\n",
      "\t__1053_fv = torch.add(__1017_input,__1052__0)\n",
      "\t__1057_fv = [768]\n",
      "\t__1056_input = torch.layer_norm(__1053_fv,__1057_fv,self.ln_f.weight,self.ln_f.bias)\n",
      "\t__1058_fv = torch.nn.functional.linear(__1056_input,self.wte.weight)\n",
      "\treturn __1058_fv\n"
     ]
    }
   ],
   "source": [
    "jit_tr_GPT2 = torch.jit.trace_module(model, inputs={\"forward\":context1},check_trace=False)\n",
    "print(getattr(getattr(jit_tr_GPT2,\"h\"),\"0\").code)\n",
    "reload(read_trace_code)\n",
    "reload(Btools)\n",
    "GPT2mod_Bg = read_trace_code.main(model,(context1,),show_debug=True)\n",
    "GPT2mod_Dg = Btools.B_to_D(GPT2mod_Bg)\n",
    "Btools.print_code(GPT2mod_Dg)\n",
    "#print(Btools.test_code(GPT2mod_Dg,model,{\"src\":context1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db982be3-9967-49ac-9bc4-a0cd818219a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Deterministic GPT2 from scratch n_layer=1, tests OK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2800776-bfd0-400b-9e6f-281a0cc48072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv1D(nn.Module):\n",
    "    def __init__(self, nx, nf):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        w = torch.empty(nx, nf)\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "        x = x.view(size_out)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dropout, d_model=768, nx=768*4):\n",
    "        super().__init__()\n",
    "        self.c_fc    = Conv1D(d_model, nx)\n",
    "        self.c_proj  = Conv1D(nx, d_model)\n",
    "        self.act     = F.gelu\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.c_proj(self.act(self.c_fc(x))))\n",
    "    \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, n_ctx=1024, d_head=64, bias=True, scale=False, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_head  = n_head\n",
    "        self.d_model = d_model\n",
    "        self.c_attn  = Conv1D(d_model, d_model*3)\n",
    "        self.scale   = scale\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.c_proj  = Conv1D(d_model, d_model)\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        \"return shape [`batch`, `head`, `sequence`, `features`]\"\n",
    "        new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head) \n",
    "        x = x.view(new_shape)\n",
    "        return x.permute(0, 2, 1, 3) \n",
    "    \n",
    "    def _attn(self, q, k, v, attn_mask=None):\n",
    "        scores  = torch.matmul(q, k.transpose(-2, -1))\n",
    "        if self.scale: scores = scores/math.sqrt(v.size(-1))\n",
    "        nd, ns  = scores.size(-2), scores.size(-1)\n",
    "        if attn_mask is not None: scores = scores + attn_mask\n",
    "        scores  = self.softmax(scores)\n",
    "        scores  = self.dropout(scores)\n",
    "        outputs = torch.matmul(scores, v)\n",
    "        return outputs\n",
    "    \n",
    "    def merge_heads(self, x):\n",
    "        x         = x.permute(0, 2, 1, 3).contiguous()\n",
    "        new_shape = x.size()[:-2] + (x.size(-2)*x.size(-1),)\n",
    "        return x.view(new_shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x        = self.c_attn(x) #new `x` shape - `[1,3,2304]`\n",
    "        q, k, v  = x.split(self.d_model, dim=2)\n",
    "        q, k, v  = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "        # out      = self._attn(q, k, v)\n",
    "        scores  = torch.matmul(q, k.transpose(-2, -1))\n",
    "        # if self.scale: scores = scores/math.sqrt(v.size(-1))\n",
    "        nd, ns  = scores.size(-2), scores.size(-1)\n",
    "        # if attn_mask is not None: scores = scores + attn_mask\n",
    "        scores  = self.softmax(scores)\n",
    "        scores  = self.dropout(scores)\n",
    "        out = torch.matmul(scores, v)\n",
    "        \n",
    "        out      = self.merge_heads(out)\n",
    "        out      = self.c_proj(out)\n",
    "        return out\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn        = Attention(d_model=d_model, n_head=n_head, d_head=64, n_ctx=1024, bias=True, scale=False, dropout=dropout)\n",
    "        self.feedforward = FeedForward(dropout=dropout, d_model=d_model, nx=d_model*4)\n",
    "        self.ln_1        = LayerNorm(d_model)\n",
    "        self.ln_2        = LayerNorm(d_model)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x1 = self.ln_1(x)\n",
    "        x2 = self.ln_2(x)\n",
    "        x = x + self.attn(x1)\n",
    "        x = x + self.feedforward(x2)\n",
    "        return x\n",
    "    \n",
    "def _get_clones(module, n):\n",
    "    return ModuleList([copy.deepcopy(module) for i in range(n)])\n",
    "\n",
    "class GPT2(nn.Module):\n",
    "    def __init__(self, nlayers=12, n_ctx=1024, d_model=768, vcb_sz=50257, dropout=0.1):\n",
    "        super(GPT2, self).__init__()\n",
    "        self.nlayers = nlayers\n",
    "        block        = TransformerBlock(d_model=d_model, n_head=12, dropout=dropout)\n",
    "        self.h       = _get_clones(block, nlayers)\n",
    "        self.wte     = nn.Embedding(vcb_sz, d_model)\n",
    "        self.wpe     = nn.Embedding(n_ctx, d_model)\n",
    "        self.drop    = nn.Dropout(dropout)\n",
    "        self.ln_f    = LayerNorm(d_model)\n",
    "        self.out     = nn.Linear(d_model, vcb_sz, bias=False)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.out.weight = self.wte.weight\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding, Conv1D)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if isinstance(module, (nn.Linear, Conv1D)) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, src, labels=None, pos_ids=None, return_inp=False, dropout=0.1):\n",
    "        if pos_ids is None: pos_ids = torch.arange(0, src.size(-1)).unsqueeze(0)\n",
    "        inp = self.drop((self.wte(src)+self.wpe(pos_ids)))\n",
    "        if return_inp: return inp \n",
    "        for i in range(self.nlayers): inp = self.h[0](inp)\n",
    "        inp     = self.ln_f(inp)\n",
    "        logits  = self.out(inp)\n",
    "        outputs = (logits,) + (inp,)\n",
    "        \n",
    "        if labels is not None:\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            loss = self.loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "            return outputs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba3c7b2f-935e-4cbd-aff3-58f85811a27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def main(src):\n",
      "\t__16_fv = torch.embedding(self.wte.weight,src)\n",
      "\t__10__1 = torch.Tensor.size(src,-1)\n",
      "\t__12_fv = torch.device(\"cpu\")\n",
      "\t__11__2 = torch.arange(0,__10__1,1,dtype = None,device = __12_fv,pin_memory = False)\n",
      "\t__13_input = torch.unsqueeze(__11__2,0)\n",
      "\t__18_fv = torch.embedding(self.wpe.weight,__13_input)\n",
      "\t__14_input0 = torch.add(__16_fv,__18_fv)\n",
      "\t__20_fv = torch.dropout(__14_input0,0.0,False)\n",
      "\t__29_fv = [768]\n",
      "\t__28_x = torch.layer_norm(__20_fv,__29_fv,self.h[0].ln_1.weight,self.h[0].ln_1.bias)\n",
      "\t__47__4 = torch.Tensor.size(__28_x,-1)\n",
      "\t__49_fv = [-1,__47__4]\n",
      "\t__50_fv = torch.Tensor.view(__28_x,__49_fv)\n",
      "\t__48_x = torch.addmm(self.h[0].attn.c_attn.bias,__50_fv,self.h[0].attn.c_attn.weight)\n",
      "\t__43__0 = torch.Tensor.size(__28_x,0)\n",
      "\t__45__2 = torch.Tensor.size(__28_x,1)\n",
      "\t__51_fv = [__43__0,__45__2,2304]\n",
      "\t__52_fv = torch.Tensor.view(__48_x,__51_fv)\n",
      "\t__40__0 = torch.split(__52_fv,768,2)\n",
      "\t__54_x = __40__0[0]\n",
      "\t__57__1 = torch.Tensor.size(__54_x,0)\n",
      "\t__59__3 = torch.Tensor.size(__54_x,1)\n",
      "\t__61__5 = torch.Tensor.size(__54_x,-1)\n",
      "\t__62__6 = torch.div(__61__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__64_fv = [__57__1,__59__3,12,__62__6]\n",
      "\t__63_x2 = torch.Tensor.view(__54_x,__64_fv)\n",
      "\t__66_fv = [0,2,1,3]\n",
      "\t__65_q = torch.permute(__63_x2,__66_fv)\n",
      "\t__55_x0 = __40__0[1]\n",
      "\t__67__7 = torch.Tensor.size(__55_x0,0)\n",
      "\t__69__9 = torch.Tensor.size(__55_x0,1)\n",
      "\t__71__11 = torch.Tensor.size(__55_x0,-1)\n",
      "\t__72__12 = torch.div(__71__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__74_fv = [__67__7,__69__9,12,__72__12]\n",
      "\t__73_x3 = torch.Tensor.view(__55_x0,__74_fv)\n",
      "\t__76_fv = [0,2,1,3]\n",
      "\t__75_k = torch.permute(__73_x3,__76_fv)\n",
      "\t__88_fv = torch.transpose(__75_k,-2,-1)\n",
      "\t__87_scores = torch.matmul(__65_q,__88_fv)\n",
      "\t__90_fv = torch.softmax(__87_scores,-1)\n",
      "\t__91_fv = torch.dropout(__90_fv,0.0,False)\n",
      "\t__56_x1 = __40__0[2]\n",
      "\t__77__13 = torch.Tensor.size(__56_x1,0)\n",
      "\t__79__15 = torch.Tensor.size(__56_x1,1)\n",
      "\t__81__17 = torch.Tensor.size(__56_x1,-1)\n",
      "\t__82__18 = torch.div(__81__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__84_fv = [__77__13,__79__15,12,__82__18]\n",
      "\t__83_x4 = torch.Tensor.view(__56_x1,__84_fv)\n",
      "\t__86_fv = [0,2,1,3]\n",
      "\t__85_v = torch.permute(__83_x4,__86_fv)\n",
      "\t__92_x5 = torch.matmul(__91_fv,__85_v)\n",
      "\t__94_fv = [0,2,1,3]\n",
      "\t__95_fv = torch.permute(__92_x5,__94_fv)\n",
      "\t__93_x6 = torch.Tensor.contiguous(__95_fv)\n",
      "\t__96__20 = torch.Tensor.size(__93_x6,0)\n",
      "\t__98__22 = torch.Tensor.size(__93_x6,1)\n",
      "\t__100__24 = torch.Tensor.size(__93_x6,-2)\n",
      "\t__101__25 = torch.Tensor.size(__93_x6,-1)\n",
      "\t__104_fv = torch.mul(__100__24,__101__25)\n",
      "\t__103_fv = [__96__20,__98__22,__104_fv]\n",
      "\t__102_x7 = torch.Tensor.view(__93_x6,__103_fv)\n",
      "\t__111__4 = torch.Tensor.size(__102_x7,-1)\n",
      "\t__113_fv = [-1,__111__4]\n",
      "\t__114_fv = torch.Tensor.view(__102_x7,__113_fv)\n",
      "\t__112_x0 = torch.addmm(self.h[0].attn.c_proj.bias,__114_fv,self.h[0].attn.c_proj.weight)\n",
      "\t__107__0 = torch.Tensor.size(__102_x7,0)\n",
      "\t__109__2 = torch.Tensor.size(__102_x7,1)\n",
      "\t__115_fv = [__107__0,__109__2,768]\n",
      "\t__116_fv = torch.Tensor.view(__112_x0,__115_fv)\n",
      "\t__35_x = torch.add(__20_fv,__116_fv)\n",
      "\t__34_fv = [768]\n",
      "\t__33_x = torch.layer_norm(__20_fv,__34_fv,self.h[0].ln_2.weight,self.h[0].ln_2.bias)\n",
      "\t__128__4 = torch.Tensor.size(__33_x,-1)\n",
      "\t__130_fv = [-1,__128__4]\n",
      "\t__131_fv = torch.Tensor.view(__33_x,__130_fv)\n",
      "\t__129_x = torch.addmm(self.h[0].feedforward.c_fc.bias,__131_fv,self.h[0].feedforward.c_fc.weight)\n",
      "\t__124__0 = torch.Tensor.size(__33_x,0)\n",
      "\t__126__2 = torch.Tensor.size(__33_x,1)\n",
      "\t__132_fv = [__124__0,__126__2,3072]\n",
      "\t__133_fv = torch.Tensor.view(__129_x,__132_fv)\n",
      "\t__121_x = torch.nn.functional.gelu(__133_fv)\n",
      "\t__141__4 = torch.Tensor.size(__121_x,-1)\n",
      "\t__143_fv = [-1,__141__4]\n",
      "\t__144_fv = torch.Tensor.view(__121_x,__143_fv)\n",
      "\t__142_x0 = torch.addmm(self.h[0].feedforward.c_proj.bias,__144_fv,self.h[0].feedforward.c_proj.weight)\n",
      "\t__137__0 = torch.Tensor.size(__121_x,0)\n",
      "\t__139__2 = torch.Tensor.size(__121_x,1)\n",
      "\t__145_fv = [__137__0,__139__2,768]\n",
      "\t__146_fv = torch.Tensor.view(__142_x0,__145_fv)\n",
      "\t__147_fv = torch.dropout(__146_fv,0.0,False)\n",
      "\t__117_input = torch.add(__35_x,__147_fv)\n",
      "\t__152_fv = [768]\n",
      "\t__151_input = torch.layer_norm(__117_input,__152_fv,self.ln_f.weight,self.ln_f.bias)\n",
      "\t__153_fv = torch.nn.functional.linear(__151_input,self.wte.weight)\n",
      "\treturn __153_fv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16439/4289802552.py:43: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head)\n"
     ]
    }
   ],
   "source": [
    "model2 = GPT2(nlayers=1,dropout=0)\n",
    "model2.eval()\n",
    "reload(read_trace_code)\n",
    "reload(Btools)\n",
    "GPT2mod_Bg2 = read_trace_code.main(model2,(context1,))\n",
    "GPT2mod_Dg2 = Btools.B_to_D(GPT2mod_Bg2)\n",
    "Btools.print_code(GPT2mod_Dg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "850c37f7-7c07-4cb0-9552-3f3f2b52ef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Input given to trace ====\n",
      "== original module ==\n",
      "tensor([[[ 0.6397, -0.1648,  1.3174,  ..., -0.1638, -0.2060,  0.1671],\n",
      "         [ 0.8286,  0.2880, -0.0818,  ...,  0.5814, -0.6506,  0.8376],\n",
      "         [ 0.6993, -0.7192, -0.1985,  ...,  0.3657, -0.7127,  0.6591]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "== inlined one ==\n",
      "tensor([[[ 0.6397, -0.1648,  1.3174,  ..., -0.1638, -0.2060,  0.1671],\n",
      "         [ 0.8286,  0.2880, -0.0818,  ...,  0.5814, -0.6506,  0.8376],\n",
      "         [ 0.6993, -0.7192, -0.1985,  ...,  0.3657, -0.7127,  0.6591]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "==== Different input ====\n",
      "== original module ==\n",
      "tensor([[[ 0.7016, -1.0133,  0.6081,  ..., -0.2734, -0.7781,  0.2357],\n",
      "         [ 0.5102, -0.9240, -0.1811,  ...,  0.1698, -1.1526,  0.8724],\n",
      "         [ 0.7101, -1.5677,  0.1003,  ..., -0.1023, -0.7853,  0.1423],\n",
      "         [ 0.0051, -0.2722,  0.4042,  ..., -0.5499, -0.5823,  0.5711],\n",
      "         [-0.3649,  0.7561,  1.0420,  ...,  0.0585, -0.5862,  0.6292],\n",
      "         [ 0.2242,  0.5596,  0.4911,  ..., -0.0851,  0.6871,  0.5228]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "== inlined one ==\n",
      "tensor([[[ 0.7016, -1.0133,  0.6081,  ..., -0.2734, -0.7781,  0.2357],\n",
      "         [ 0.5102, -0.9240, -0.1811,  ...,  0.1698, -1.1526,  0.8724],\n",
      "         [ 0.7101, -1.5677,  0.1003,  ..., -0.1023, -0.7853,  0.1423],\n",
      "         [ 0.0051, -0.2722,  0.4042,  ..., -0.5499, -0.5823,  0.5711],\n",
      "         [-0.3649,  0.7561,  1.0420,  ...,  0.0585, -0.5862,  0.6292],\n",
      "         [ 0.2242,  0.5596,  0.4911,  ..., -0.0851,  0.6871,  0.5228]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "=== max diff ===\n",
      "tensor(0., grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "reload(Btools)\n",
    "print(\"==== Input given to trace ====\")\n",
    "print(\"== original module ==\")\n",
    "print(model2.forward(context1))\n",
    "print(\"== inlined one ==\")\n",
    "print(Btools.test_code(GPT2mod_Dg2,model2,{\"src\":context1}))\n",
    "print(\"==== Different input ====\")\n",
    "print(\"== original module ==\")\n",
    "print(model2.forward(context2))\n",
    "print(\"== inlined one ==\")\n",
    "print(Btools.test_code(GPT2mod_Dg2,model2,{\"src\":context2}))\n",
    "print(\"=== max diff ===\")\n",
    "print(torch.max(torch.abs(model2.forward(context2) - Btools.test_code(GPT2mod_Dg2,model2,{\"src\":context2}))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15ed42-a0eb-45ac-be00-867fc9c65738",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# graph test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22ca60da-f9ba-4454-8487-21f7cc05b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(evince:12087): dbind-WARNING **: 11:47:09.040: Couldn't connect to accessibility bus: Failed to connect to socket /run/user/1000/at-spi/bus: Permission denied\n"
     ]
    }
   ],
   "source": [
    "reload(Btools)\n",
    "Btools.print_graph(mymod_Dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18682e9b-acfa-445f-9dc4-4f7926e4cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Btools.print_graph(modtf_Dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acae244e-4371-4e07-ad3a-8a6cc177d548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(evince:12139): dbind-WARNING **: 11:48:42.874: Couldn't connect to accessibility bus: Failed to connect to socket /run/user/1000/at-spi/bus: Permission denied\n"
     ]
    }
   ],
   "source": [
    "Btools.print_graph(GPT2mod_Dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302bbfc-f807-4875-b35a-3dcac68faf44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
