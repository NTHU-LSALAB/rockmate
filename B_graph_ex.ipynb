{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c044db-f13a-4ef1-8d35-12c1b2fdcb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import read_trace_code\n",
    "import tools_on_B_graph as Btools\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c623a-c360-49d5-98e1-ae95177f3a53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test on mymod :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52ce50ca-6a8a-4f37-adc9-cd305b6e99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubMod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential (\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,512),\n",
    "        )\n",
    "    \n",
    "    def forward(self,p1,p2,p3):\n",
    "        y1 = self.linear_stack(p1)\n",
    "        y2 = self.linear_stack(p2)\n",
    "        y3 = self.linear_stack(p3)\n",
    "        return y1+y2,y1-y2+y3,y1\n",
    "\n",
    "class MyMod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.op = SubMod()\n",
    "    def forward(self,x):\n",
    "        (z1,z2,z3) = self.op(x,-x,p3=torch.ones_like(x))\n",
    "        return z1 + 2*z3 + z2*x.size(-1)\n",
    "\n",
    "mymod = MyMod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8a1263a-3fba-4547-9c6f-018d227fbc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== MYMOD =====\n",
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  op = self.op\n",
      "  input = torch.neg(x)\n",
      "  input0 = torch.ones_like(x, dtype=6, layout=0, device=torch.device(\"cpu\"), pin_memory=False)\n",
      "  _0, _1, _2, = (op).forward(x, input, input0, )\n",
      "  _3 = torch.add(_1, torch.mul(_0, CONSTANTS.c0))\n",
      "  _4 = ops.prim.NumToTensor(torch.size(x, -1))\n",
      "  return torch.add(_3, torch.mul(_2, _4))\n",
      "\n",
      "===== SUB CODE : self.op.forward =====\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    input: Tensor,\n",
      "    input0: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
      "  linear_stack = self.linear_stack\n",
      "  _0 = (linear_stack).forward(x, )\n",
      "  _1 = (linear_stack).forward1(input, )\n",
      "  _2 = (linear_stack).forward2(input0, )\n",
      "  z1 = torch.add(_0, _1)\n",
      "  z2 = torch.add(torch.sub(_0, _1), _2)\n",
      "  return (_0, z1, z2)\n",
      "\n",
      "===== SUB SUB CODE =====\n",
      "def forward1(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  _1 = getattr(self, \"1\")\n",
      "  _0 = getattr(self, \"0\")\n",
      "  _2 = (_1).forward1((_0).forward1(input, ), )\n",
      "  return _2\n",
      "\n",
      "===== SUB SUB SUB CODE =====\n",
      "== to debug : getattr(self.op.linear_stack,\"1\").forward2 ==\n",
      "def forward2(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  bias = self.bias\n",
      "  weight = self.weight\n",
      "  y3 = torch.linear(argument_1, weight, bias)\n",
      "  return y3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_mymod = torch.rand((128))\n",
    "script_mymod = torch.jit.trace_module(mymod, {'forward': (src_mymod,)},check_trace=False)\n",
    "print(\"===== MYMOD =====\")\n",
    "print(script_mymod.forward.code)\n",
    "\n",
    "print(\"===== SUB CODE : self.op.forward =====\")\n",
    "print(script_mymod.op.code)\n",
    "\n",
    "print(\"===== SUB SUB CODE =====\")\n",
    "print(script_mymod.op.linear_stack.forward1.code)\n",
    "\n",
    "print(\"===== SUB SUB SUB CODE =====\")\n",
    "print(\"== to debug : getattr(self.op.linear_stack,\\\"1\\\").forward2 ==\")\n",
    "print(getattr(script_mymod.op.linear_stack,\"1\").forward2.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10c08759-bec7-4227-b6de-6375fa19dffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "def main(x):\n",
      "\t__10_fv = torch.relu(x)\n",
      "\t__13_y1 = torch.nn.functional.linear(__10_fv,self.op.linear_stack[1].weight,self.op.linear_stack[1].bias)\n",
      "\t__2_input = torch.neg(x)\n",
      "\t__18_fv = torch.relu(__2_input)\n",
      "\t__21_y2 = torch.nn.functional.linear(__18_fv,self.op.linear_stack[1].weight,self.op.linear_stack[1].bias)\n",
      "\t__30_z1 = torch.add(__13_y1,__21_y2)\n",
      "\t__32_fv = torch.sub(__13_y1,__21_y2)\n",
      "\t__3_input0 = torch.ones_like(x,device = torch.device(\"cpu\"),pin_memory = False)\n",
      "\t__26_fv = torch.relu(__3_input0)\n",
      "\t__29_y3 = torch.nn.functional.linear(__26_fv,self.op.linear_stack[1].weight,self.op.linear_stack[1].bias)\n",
      "\t__31_z2 = torch.add(__32_fv,__29_y3)\n",
      "\t__33_fv = (__13_y1,__30_z1,__31_z2)\n",
      "\t__35__1 = __33_fv[1]\n",
      "\t__34__0 = __33_fv[0]\n",
      "\t__38_fv = torch.mul(__34__0,tensor(2))\n",
      "\t__37__3 = torch.add(__35__1,__38_fv)\n",
      "\t__36__2 = __33_fv[2]\n",
      "\t__39__4 = torch.Tensor.size(x,-1)\n",
      "\t__40_fv = torch.mul(__36__2,__39__4)\n",
      "\t__41_fv = torch.add(__37__3,__40_fv)\n",
      "\treturn __41_fv\n"
     ]
    }
   ],
   "source": [
    "reload(read_trace_code)\n",
    "reload(Btools)\n",
    "mymod_Bg = read_trace_code.main(mymod,(src_mymod,))\n",
    "#Btools.print_all_nodes(mymod_Bg)\n",
    "mymod_Dg = Btools.B_to_D(mymod_Bg)\n",
    "Btools.print_code(mymod_Dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46788840-e78c-4da6-a5df-c9ea2f96d451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Original module ==\n",
      "tensor([ 109.5877,  -16.9878, -108.7730,   90.9153, -121.8676,  -25.9335,\n",
      "         153.3468,  -78.8924,   31.2294,  136.2355], grad_fn=<SliceBackward0>)\n",
      "== Through D_graph ==\n",
      "tensor([ 109.5877,  -16.9878, -108.7730,   90.9153, -121.8676,  -25.9335,\n",
      "         153.3468,  -78.8924,   31.2294,  136.2355], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "reload(Btools)\n",
    "print(\"== Original module ==\")\n",
    "print(mymod(src_mymod)[:10])\n",
    "print(\"== Through D_graph ==\")\n",
    "print(Btools.test_code(mymod_Dg,mymod,{\"x\":src_mymod})[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83f8b8-dbcc-43f1-bdee-88580e64a0e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test on torch.nn.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f8989c-fd89-4f87-a903-739c1f7a62d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In self.forward try to sub open self.encoder.forward\n",
      "In self.encoder.forward try to sub open self.encoder.layers[0].forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].self_attn.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].dropout1.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].norm1.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].linear1.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].dropout.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].linear2.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].dropout2.forward\n",
      "In self.encoder.layers[0].forward try to sub open self.encoder.layers[0].norm2.forward\n",
      "In self.encoder.forward try to sub open self.encoder.norm.forward\n",
      "In self.forward try to sub open self.decoder.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[0].forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].self_attn.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].dropout1.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].norm1.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].multihead_attn.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].dropout2.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].norm2.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].linear1.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].dropout.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].linear2.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].dropout3.forward\n",
      "In self.decoder.layers[0].forward try to sub open self.decoder.layers[0].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[1].forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].self_attn.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].dropout1.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].norm1.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].multihead_attn.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].dropout2.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].norm2.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].linear1.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].dropout.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].linear2.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].dropout3.forward\n",
      "In self.decoder.layers[1].forward try to sub open self.decoder.layers[1].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[2].forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].self_attn.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].dropout1.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].norm1.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].multihead_attn.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].dropout2.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].norm2.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].linear1.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].dropout.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].linear2.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].dropout3.forward\n",
      "In self.decoder.layers[2].forward try to sub open self.decoder.layers[2].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[3].forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].self_attn.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].dropout1.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].norm1.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].multihead_attn.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].dropout2.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].norm2.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].linear1.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].dropout.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].linear2.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].dropout3.forward\n",
      "In self.decoder.layers[3].forward try to sub open self.decoder.layers[3].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[4].forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].self_attn.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].dropout1.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].norm1.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].multihead_attn.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].dropout2.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].norm2.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].linear1.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].dropout.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].linear2.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].dropout3.forward\n",
      "In self.decoder.layers[4].forward try to sub open self.decoder.layers[4].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.layers[5].forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].self_attn.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].dropout1.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].norm1.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].multihead_attn.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].dropout2.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].norm2.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].linear1.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].dropout.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].linear2.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].dropout3.forward\n",
      "In self.decoder.layers[5].forward try to sub open self.decoder.layers[5].norm3.forward\n",
      "In self.decoder.forward try to sub open self.decoder.norm.forward\n",
      "def main(tgt,src):\n",
      "\t__135__7 = torch.nn.functional.linear(tgt,self.decoder.layers[0].self_attn.in_proj_weight,self.decoder.layers[0].self_attn.in_proj_bias)\n",
      "\t__136_fv = torch.chunk(__135__7,3,-1)\n",
      "\t__137_q = __136_fv[0]\n",
      "\t__140__8 = torch.Tensor.contiguous(__137_q)\n",
      "\t__124_tgt_len = torch.Tensor.size(tgt,0)\n",
      "\t__127_bsz = torch.Tensor.size(tgt,1)\n",
      "\t__142_fv = torch.mul(__127_bsz,tensor(16))\n",
      "\t__129_embed_dim = torch.Tensor.size(tgt,2)\n",
      "\t__131_head_dim = torch.div(__129_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__141__9 = [__124_tgt_len,__142_fv,__131_head_dim]\n",
      "\t__144_fv = torch.Tensor.view(__140__8,__141__9)\n",
      "\t__143_q0 = torch.transpose(__144_fv,0,1)\n",
      "\t__157_q1 = torch.div(__143_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__138_k = __136_fv[1]\n",
      "\t__145__10 = torch.Tensor.contiguous(__138_k)\n",
      "\t__146__11 = torch.Tensor.size(__138_k,0)\n",
      "\t__148_fv = torch.mul(__127_bsz,tensor(16))\n",
      "\t__147__12 = [__146__11,__148_fv,__131_head_dim]\n",
      "\t__150_fv = torch.Tensor.view(__145__10,__147__12)\n",
      "\t__149_k0 = torch.transpose(__150_fv,0,1)\n",
      "\t__159_fv = torch.transpose(__149_k0,-2,-1)\n",
      "\t__158_input = torch.bmm(__157_q1,__159_fv)\n",
      "\t__160_input0 = torch.softmax(__158_input,-1)\n",
      "\t__161_attn = torch.dropout(__160_input0,0.1,True)\n",
      "\t__139_v = __136_fv[2]\n",
      "\t__151__13 = torch.Tensor.contiguous(__139_v)\n",
      "\t__152__14 = torch.Tensor.size(__139_v,0)\n",
      "\t__154_fv = torch.mul(__127_bsz,tensor(16))\n",
      "\t__153__15 = [__152__14,__154_fv,__131_head_dim]\n",
      "\t__156_fv = torch.Tensor.view(__151__13,__153__15)\n",
      "\t__155_v0 = torch.transpose(__156_fv,0,1)\n",
      "\t__162_attn_output = torch.bmm(__161_attn,__155_v0)\n",
      "\t__164_fv = torch.transpose(__162_attn_output,0,1)\n",
      "\t__163__16 = torch.Tensor.contiguous(__164_fv)\n",
      "\t__166_fv = [__124_tgt_len,__127_bsz,__129_embed_dim]\n",
      "\t__165_attn_output0 = torch.Tensor.view(__163__16,__166_fv)\n",
      "\t__167_input1 = torch.nn.functional.linear(__165_attn_output0,self.decoder.layers[0].self_attn.out_proj.weight,self.decoder.layers[0].self_attn.out_proj.bias)\n",
      "\t__168__0 = torch.dropout(__167_input1,0.1,True)\n",
      "\t__169_input = torch.add(tgt,__168__0)\n",
      "\t__174_fv = [512]\n",
      "\t__173_query = torch.layer_norm(__169_input,__174_fv,self.decoder.layers[0].norm1.weight,self.decoder.layers[0].norm1.bias)\n",
      "\t__193_E = torch.Tensor.size(__173_query,-1)\n",
      "\t__196_fv = torch.mul(__193_E,tensor(2))\n",
      "\t__195__8 = [__193_E,__196_fv]\n",
      "\t__197__9 = torch.split_with_sizes(self.decoder.layers[0].multihead_attn.in_proj_weight,__195__8)\n",
      "\t__199_w_q = __197__9[0]\n",
      "\t__203_fv = torch.mul(__193_E,tensor(2))\n",
      "\t__202_fv = [__193_E,__203_fv]\n",
      "\t__201__10 = torch.split_with_sizes(self.decoder.layers[0].multihead_attn.in_proj_bias,__202_fv)\n",
      "\t__205_b_q = __201__10[0]\n",
      "\t__207_q = torch.nn.functional.linear(__173_query,__199_w_q,__205_b_q)\n",
      "\t__213_q0 = torch.Tensor.contiguous(__207_q)\n",
      "\t__182_tgt_len = torch.Tensor.size(__173_query,0)\n",
      "\t__185_bsz = torch.Tensor.size(__173_query,1)\n",
      "\t__215_fv = torch.mul(__185_bsz,tensor(16))\n",
      "\t__187_embed_dim = torch.Tensor.size(__173_query,2)\n",
      "\t__189_head_dim = torch.div(__187_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__214__12 = [__182_tgt_len,__215_fv,__189_head_dim]\n",
      "\t__217_fv = torch.Tensor.view(__213_q0,__214__12)\n",
      "\t__216_q1 = torch.transpose(__217_fv,0,1)\n",
      "\t__230_q2 = torch.div(__216_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__33__7 = torch.nn.functional.linear(src,self.encoder.layers[0].self_attn.in_proj_weight,self.encoder.layers[0].self_attn.in_proj_bias)\n",
      "\t__34_fv = torch.chunk(__33__7,3,-1)\n",
      "\t__35_q = __34_fv[0]\n",
      "\t__38__8 = torch.Tensor.contiguous(__35_q)\n",
      "\t__22_tgt_len = torch.Tensor.size(src,0)\n",
      "\t__25_bsz = torch.Tensor.size(src,1)\n",
      "\t__40_fv = torch.mul(__25_bsz,tensor(16))\n",
      "\t__27_embed_dim = torch.Tensor.size(src,2)\n",
      "\t__29_head_dim = torch.div(__27_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__39__9 = [__22_tgt_len,__40_fv,__29_head_dim]\n",
      "\t__42_fv = torch.Tensor.view(__38__8,__39__9)\n",
      "\t__41_q0 = torch.transpose(__42_fv,0,1)\n",
      "\t__55_q1 = torch.div(__41_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__36_k = __34_fv[1]\n",
      "\t__43__10 = torch.Tensor.contiguous(__36_k)\n",
      "\t__44__11 = torch.Tensor.size(__36_k,0)\n",
      "\t__46_fv = torch.mul(__25_bsz,tensor(16))\n",
      "\t__45__12 = [__44__11,__46_fv,__29_head_dim]\n",
      "\t__48_fv = torch.Tensor.view(__43__10,__45__12)\n",
      "\t__47_k0 = torch.transpose(__48_fv,0,1)\n",
      "\t__57_fv = torch.transpose(__47_k0,-2,-1)\n",
      "\t__56_input = torch.bmm(__55_q1,__57_fv)\n",
      "\t__58_input0 = torch.softmax(__56_input,-1)\n",
      "\t__59_attn = torch.dropout(__58_input0,0.1,True)\n",
      "\t__37_v = __34_fv[2]\n",
      "\t__49__13 = torch.Tensor.contiguous(__37_v)\n",
      "\t__50__14 = torch.Tensor.size(__37_v,0)\n",
      "\t__52_fv = torch.mul(__25_bsz,tensor(16))\n",
      "\t__51__15 = [__50__14,__52_fv,__29_head_dim]\n",
      "\t__54_fv = torch.Tensor.view(__49__13,__51__15)\n",
      "\t__53_v0 = torch.transpose(__54_fv,0,1)\n",
      "\t__60_attn_output = torch.bmm(__59_attn,__53_v0)\n",
      "\t__62_fv = torch.transpose(__60_attn_output,0,1)\n",
      "\t__61__16 = torch.Tensor.contiguous(__62_fv)\n",
      "\t__64_fv = [__22_tgt_len,__25_bsz,__27_embed_dim]\n",
      "\t__63_attn_output0 = torch.Tensor.view(__61__16,__64_fv)\n",
      "\t__65_input1 = torch.nn.functional.linear(__63_attn_output0,self.encoder.layers[0].self_attn.out_proj.weight,self.encoder.layers[0].self_attn.out_proj.bias)\n",
      "\t__66__0 = torch.dropout(__65_input1,0.1,True)\n",
      "\t__67_input = torch.add(src,__66__0)\n",
      "\t__72_fv = [512]\n",
      "\t__71_input0 = torch.layer_norm(__67_input,__72_fv,self.encoder.layers[0].norm1.weight,self.encoder.layers[0].norm1.bias)\n",
      "\t__76_input = torch.nn.functional.linear(__71_input0,self.encoder.layers[0].linear1.weight,self.encoder.layers[0].linear1.bias)\n",
      "\t__73_input0 = torch.relu(__76_input)\n",
      "\t__78_input0 = torch.dropout(__73_input0,0.1,True)\n",
      "\t__81_input = torch.nn.functional.linear(__78_input0,self.encoder.layers[0].linear2.weight,self.encoder.layers[0].linear2.bias)\n",
      "\t__83__0 = torch.dropout(__81_input,0.1,True)\n",
      "\t__82_input1 = torch.add(__71_input0,__83__0)\n",
      "\t__87_fv = [512]\n",
      "\t__86_input0 = torch.layer_norm(__82_input1,__87_fv,self.encoder.layers[0].norm2.weight,self.encoder.layers[0].norm2.bias)\n",
      "\t__91_fv = [512]\n",
      "\t__90_key = torch.layer_norm(__86_input0,__91_fv,self.encoder.norm.weight,self.encoder.norm.bias)\n",
      "\t__200_w_kv = __197__9[1]\n",
      "\t__206_b_kv = __201__10[1]\n",
      "\t__209_fv = torch.nn.functional.linear(__90_key,__200_w_kv,__206_b_kv)\n",
      "\t__208__11 = torch.chunk(__209_fv,2,-1)\n",
      "\t__211_k = __208__11[0]\n",
      "\t__218__13 = torch.Tensor.contiguous(__211_k)\n",
      "\t__219__14 = torch.Tensor.size(__211_k,0)\n",
      "\t__221_fv = torch.mul(__185_bsz,tensor(16))\n",
      "\t__220__15 = [__219__14,__221_fv,__189_head_dim]\n",
      "\t__223_fv = torch.Tensor.view(__218__13,__220__15)\n",
      "\t__222_k0 = torch.transpose(__223_fv,0,1)\n",
      "\t__232_fv = torch.transpose(__222_k0,-2,-1)\n",
      "\t__231_input = torch.bmm(__230_q2,__232_fv)\n",
      "\t__233_input0 = torch.softmax(__231_input,-1)\n",
      "\t__234_attn = torch.dropout(__233_input0,0.1,True)\n",
      "\t__212_v = __208__11[1]\n",
      "\t__224__16 = torch.Tensor.contiguous(__212_v)\n",
      "\t__225__17 = torch.Tensor.size(__212_v,0)\n",
      "\t__227_fv = torch.mul(__185_bsz,tensor(16))\n",
      "\t__226__18 = [__225__17,__227_fv,__189_head_dim]\n",
      "\t__229_fv = torch.Tensor.view(__224__16,__226__18)\n",
      "\t__228_v0 = torch.transpose(__229_fv,0,1)\n",
      "\t__235_attn_output = torch.bmm(__234_attn,__228_v0)\n",
      "\t__237_fv = torch.transpose(__235_attn_output,0,1)\n",
      "\t__236__19 = torch.Tensor.contiguous(__237_fv)\n",
      "\t__239_fv = [__182_tgt_len,__185_bsz,__187_embed_dim]\n",
      "\t__238_attn_output0 = torch.Tensor.view(__236__19,__239_fv)\n",
      "\t__240_input1 = torch.nn.functional.linear(__238_attn_output0,self.decoder.layers[0].multihead_attn.out_proj.weight,self.decoder.layers[0].multihead_attn.out_proj.bias)\n",
      "\t__242__0 = torch.dropout(__240_input1,0.1,True)\n",
      "\t__241_input0 = torch.add(__173_query,__242__0)\n",
      "\t__247_fv = [512]\n",
      "\t__246_input0 = torch.layer_norm(__241_input0,__247_fv,self.decoder.layers[0].norm2.weight,self.decoder.layers[0].norm2.bias)\n",
      "\t__251_input = torch.nn.functional.linear(__246_input0,self.decoder.layers[0].linear1.weight,self.decoder.layers[0].linear1.bias)\n",
      "\t__248_input1 = torch.relu(__251_input)\n",
      "\t__253_input0 = torch.dropout(__248_input1,0.1,True)\n",
      "\t__256_input = torch.nn.functional.linear(__253_input0,self.decoder.layers[0].linear2.weight,self.decoder.layers[0].linear2.bias)\n",
      "\t__258__0 = torch.dropout(__256_input,0.1,True)\n",
      "\t__257_input2 = torch.add(__246_input0,__258__0)\n",
      "\t__262_fv = [512]\n",
      "\t__261_query = torch.layer_norm(__257_input2,__262_fv,self.decoder.layers[0].norm3.weight,self.decoder.layers[0].norm3.bias)\n",
      "\t__292__7 = torch.nn.functional.linear(__261_query,self.decoder.layers[1].self_attn.in_proj_weight,self.decoder.layers[1].self_attn.in_proj_bias)\n",
      "\t__293_fv = torch.chunk(__292__7,3,-1)\n",
      "\t__294_q = __293_fv[0]\n",
      "\t__297__8 = torch.Tensor.contiguous(__294_q)\n",
      "\t__281_tgt_len = torch.Tensor.size(__261_query,0)\n",
      "\t__284_bsz = torch.Tensor.size(__261_query,1)\n",
      "\t__299_fv = torch.mul(__284_bsz,tensor(16))\n",
      "\t__286_embed_dim = torch.Tensor.size(__261_query,2)\n",
      "\t__288_head_dim = torch.div(__286_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__298__9 = [__281_tgt_len,__299_fv,__288_head_dim]\n",
      "\t__301_fv = torch.Tensor.view(__297__8,__298__9)\n",
      "\t__300_q0 = torch.transpose(__301_fv,0,1)\n",
      "\t__314_q1 = torch.div(__300_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__295_k = __293_fv[1]\n",
      "\t__302__10 = torch.Tensor.contiguous(__295_k)\n",
      "\t__303__11 = torch.Tensor.size(__295_k,0)\n",
      "\t__305_fv = torch.mul(__284_bsz,tensor(16))\n",
      "\t__304__12 = [__303__11,__305_fv,__288_head_dim]\n",
      "\t__307_fv = torch.Tensor.view(__302__10,__304__12)\n",
      "\t__306_k0 = torch.transpose(__307_fv,0,1)\n",
      "\t__316_fv = torch.transpose(__306_k0,-2,-1)\n",
      "\t__315_input = torch.bmm(__314_q1,__316_fv)\n",
      "\t__317_input0 = torch.softmax(__315_input,-1)\n",
      "\t__318_attn = torch.dropout(__317_input0,0.1,True)\n",
      "\t__296_v = __293_fv[2]\n",
      "\t__308__13 = torch.Tensor.contiguous(__296_v)\n",
      "\t__309__14 = torch.Tensor.size(__296_v,0)\n",
      "\t__311_fv = torch.mul(__284_bsz,tensor(16))\n",
      "\t__310__15 = [__309__14,__311_fv,__288_head_dim]\n",
      "\t__313_fv = torch.Tensor.view(__308__13,__310__15)\n",
      "\t__312_v0 = torch.transpose(__313_fv,0,1)\n",
      "\t__319_attn_output = torch.bmm(__318_attn,__312_v0)\n",
      "\t__321_fv = torch.transpose(__319_attn_output,0,1)\n",
      "\t__320__16 = torch.Tensor.contiguous(__321_fv)\n",
      "\t__323_fv = [__281_tgt_len,__284_bsz,__286_embed_dim]\n",
      "\t__322_attn_output0 = torch.Tensor.view(__320__16,__323_fv)\n",
      "\t__324_input1 = torch.nn.functional.linear(__322_attn_output0,self.decoder.layers[1].self_attn.out_proj.weight,self.decoder.layers[1].self_attn.out_proj.bias)\n",
      "\t__325__0 = torch.dropout(__324_input1,0.1,True)\n",
      "\t__326_input = torch.add(__261_query,__325__0)\n",
      "\t__331_fv = [512]\n",
      "\t__330_query = torch.layer_norm(__326_input,__331_fv,self.decoder.layers[1].norm1.weight,self.decoder.layers[1].norm1.bias)\n",
      "\t__350_E = torch.Tensor.size(__330_query,-1)\n",
      "\t__353_fv = torch.mul(__350_E,tensor(2))\n",
      "\t__352__8 = [__350_E,__353_fv]\n",
      "\t__354__9 = torch.split_with_sizes(self.decoder.layers[1].multihead_attn.in_proj_weight,__352__8)\n",
      "\t__356_w_q = __354__9[0]\n",
      "\t__360_fv = torch.mul(__350_E,tensor(2))\n",
      "\t__359_fv = [__350_E,__360_fv]\n",
      "\t__358__10 = torch.split_with_sizes(self.decoder.layers[1].multihead_attn.in_proj_bias,__359_fv)\n",
      "\t__362_b_q = __358__10[0]\n",
      "\t__364_q = torch.nn.functional.linear(__330_query,__356_w_q,__362_b_q)\n",
      "\t__370_q0 = torch.Tensor.contiguous(__364_q)\n",
      "\t__339_tgt_len = torch.Tensor.size(__330_query,0)\n",
      "\t__342_bsz = torch.Tensor.size(__330_query,1)\n",
      "\t__372_fv = torch.mul(__342_bsz,tensor(16))\n",
      "\t__344_embed_dim = torch.Tensor.size(__330_query,2)\n",
      "\t__346_head_dim = torch.div(__344_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__371__12 = [__339_tgt_len,__372_fv,__346_head_dim]\n",
      "\t__374_fv = torch.Tensor.view(__370_q0,__371__12)\n",
      "\t__373_q1 = torch.transpose(__374_fv,0,1)\n",
      "\t__387_q2 = torch.div(__373_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__357_w_kv = __354__9[1]\n",
      "\t__363_b_kv = __358__10[1]\n",
      "\t__366_fv = torch.nn.functional.linear(__90_key,__357_w_kv,__363_b_kv)\n",
      "\t__365__11 = torch.chunk(__366_fv,2,-1)\n",
      "\t__368_k = __365__11[0]\n",
      "\t__375__13 = torch.Tensor.contiguous(__368_k)\n",
      "\t__376__14 = torch.Tensor.size(__368_k,0)\n",
      "\t__378_fv = torch.mul(__342_bsz,tensor(16))\n",
      "\t__377__15 = [__376__14,__378_fv,__346_head_dim]\n",
      "\t__380_fv = torch.Tensor.view(__375__13,__377__15)\n",
      "\t__379_k0 = torch.transpose(__380_fv,0,1)\n",
      "\t__389_fv = torch.transpose(__379_k0,-2,-1)\n",
      "\t__388_input = torch.bmm(__387_q2,__389_fv)\n",
      "\t__390_input0 = torch.softmax(__388_input,-1)\n",
      "\t__391_attn = torch.dropout(__390_input0,0.1,True)\n",
      "\t__369_v = __365__11[1]\n",
      "\t__381__16 = torch.Tensor.contiguous(__369_v)\n",
      "\t__382__17 = torch.Tensor.size(__369_v,0)\n",
      "\t__384_fv = torch.mul(__342_bsz,tensor(16))\n",
      "\t__383__18 = [__382__17,__384_fv,__346_head_dim]\n",
      "\t__386_fv = torch.Tensor.view(__381__16,__383__18)\n",
      "\t__385_v0 = torch.transpose(__386_fv,0,1)\n",
      "\t__392_attn_output = torch.bmm(__391_attn,__385_v0)\n",
      "\t__394_fv = torch.transpose(__392_attn_output,0,1)\n",
      "\t__393__19 = torch.Tensor.contiguous(__394_fv)\n",
      "\t__396_fv = [__339_tgt_len,__342_bsz,__344_embed_dim]\n",
      "\t__395_attn_output0 = torch.Tensor.view(__393__19,__396_fv)\n",
      "\t__397_input1 = torch.nn.functional.linear(__395_attn_output0,self.decoder.layers[1].multihead_attn.out_proj.weight,self.decoder.layers[1].multihead_attn.out_proj.bias)\n",
      "\t__399__0 = torch.dropout(__397_input1,0.1,True)\n",
      "\t__398_input0 = torch.add(__330_query,__399__0)\n",
      "\t__404_fv = [512]\n",
      "\t__403_input0 = torch.layer_norm(__398_input0,__404_fv,self.decoder.layers[1].norm2.weight,self.decoder.layers[1].norm2.bias)\n",
      "\t__408_input = torch.nn.functional.linear(__403_input0,self.decoder.layers[1].linear1.weight,self.decoder.layers[1].linear1.bias)\n",
      "\t__405_input1 = torch.relu(__408_input)\n",
      "\t__410_input0 = torch.dropout(__405_input1,0.1,True)\n",
      "\t__413_input = torch.nn.functional.linear(__410_input0,self.decoder.layers[1].linear2.weight,self.decoder.layers[1].linear2.bias)\n",
      "\t__415__0 = torch.dropout(__413_input,0.1,True)\n",
      "\t__414_input2 = torch.add(__403_input0,__415__0)\n",
      "\t__419_fv = [512]\n",
      "\t__418_query = torch.layer_norm(__414_input2,__419_fv,self.decoder.layers[1].norm3.weight,self.decoder.layers[1].norm3.bias)\n",
      "\t__450__7 = torch.nn.functional.linear(__418_query,self.decoder.layers[2].self_attn.in_proj_weight,self.decoder.layers[2].self_attn.in_proj_bias)\n",
      "\t__451_fv = torch.chunk(__450__7,3,-1)\n",
      "\t__452_q = __451_fv[0]\n",
      "\t__455__8 = torch.Tensor.contiguous(__452_q)\n",
      "\t__439_tgt_len = torch.Tensor.size(__418_query,0)\n",
      "\t__442_bsz = torch.Tensor.size(__418_query,1)\n",
      "\t__457_fv = torch.mul(__442_bsz,tensor(16))\n",
      "\t__444_embed_dim = torch.Tensor.size(__418_query,2)\n",
      "\t__446_head_dim = torch.div(__444_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__456__9 = [__439_tgt_len,__457_fv,__446_head_dim]\n",
      "\t__459_fv = torch.Tensor.view(__455__8,__456__9)\n",
      "\t__458_q0 = torch.transpose(__459_fv,0,1)\n",
      "\t__472_q1 = torch.div(__458_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__453_k = __451_fv[1]\n",
      "\t__460__10 = torch.Tensor.contiguous(__453_k)\n",
      "\t__461__11 = torch.Tensor.size(__453_k,0)\n",
      "\t__463_fv = torch.mul(__442_bsz,tensor(16))\n",
      "\t__462__12 = [__461__11,__463_fv,__446_head_dim]\n",
      "\t__465_fv = torch.Tensor.view(__460__10,__462__12)\n",
      "\t__464_k0 = torch.transpose(__465_fv,0,1)\n",
      "\t__474_fv = torch.transpose(__464_k0,-2,-1)\n",
      "\t__473_input = torch.bmm(__472_q1,__474_fv)\n",
      "\t__475_input0 = torch.softmax(__473_input,-1)\n",
      "\t__476_attn = torch.dropout(__475_input0,0.1,True)\n",
      "\t__454_v = __451_fv[2]\n",
      "\t__466__13 = torch.Tensor.contiguous(__454_v)\n",
      "\t__467__14 = torch.Tensor.size(__454_v,0)\n",
      "\t__469_fv = torch.mul(__442_bsz,tensor(16))\n",
      "\t__468__15 = [__467__14,__469_fv,__446_head_dim]\n",
      "\t__471_fv = torch.Tensor.view(__466__13,__468__15)\n",
      "\t__470_v0 = torch.transpose(__471_fv,0,1)\n",
      "\t__477_attn_output = torch.bmm(__476_attn,__470_v0)\n",
      "\t__479_fv = torch.transpose(__477_attn_output,0,1)\n",
      "\t__478__16 = torch.Tensor.contiguous(__479_fv)\n",
      "\t__481_fv = [__439_tgt_len,__442_bsz,__444_embed_dim]\n",
      "\t__480_attn_output0 = torch.Tensor.view(__478__16,__481_fv)\n",
      "\t__482_input1 = torch.nn.functional.linear(__480_attn_output0,self.decoder.layers[2].self_attn.out_proj.weight,self.decoder.layers[2].self_attn.out_proj.bias)\n",
      "\t__483__0 = torch.dropout(__482_input1,0.1,True)\n",
      "\t__484_input = torch.add(__418_query,__483__0)\n",
      "\t__489_fv = [512]\n",
      "\t__488_query = torch.layer_norm(__484_input,__489_fv,self.decoder.layers[2].norm1.weight,self.decoder.layers[2].norm1.bias)\n",
      "\t__508_E = torch.Tensor.size(__488_query,-1)\n",
      "\t__511_fv = torch.mul(__508_E,tensor(2))\n",
      "\t__510__8 = [__508_E,__511_fv]\n",
      "\t__512__9 = torch.split_with_sizes(self.decoder.layers[2].multihead_attn.in_proj_weight,__510__8)\n",
      "\t__514_w_q = __512__9[0]\n",
      "\t__518_fv = torch.mul(__508_E,tensor(2))\n",
      "\t__517_fv = [__508_E,__518_fv]\n",
      "\t__516__10 = torch.split_with_sizes(self.decoder.layers[2].multihead_attn.in_proj_bias,__517_fv)\n",
      "\t__520_b_q = __516__10[0]\n",
      "\t__522_q = torch.nn.functional.linear(__488_query,__514_w_q,__520_b_q)\n",
      "\t__528_q0 = torch.Tensor.contiguous(__522_q)\n",
      "\t__497_tgt_len = torch.Tensor.size(__488_query,0)\n",
      "\t__500_bsz = torch.Tensor.size(__488_query,1)\n",
      "\t__530_fv = torch.mul(__500_bsz,tensor(16))\n",
      "\t__502_embed_dim = torch.Tensor.size(__488_query,2)\n",
      "\t__504_head_dim = torch.div(__502_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__529__12 = [__497_tgt_len,__530_fv,__504_head_dim]\n",
      "\t__532_fv = torch.Tensor.view(__528_q0,__529__12)\n",
      "\t__531_q1 = torch.transpose(__532_fv,0,1)\n",
      "\t__545_q2 = torch.div(__531_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__515_w_kv = __512__9[1]\n",
      "\t__521_b_kv = __516__10[1]\n",
      "\t__524_fv = torch.nn.functional.linear(__90_key,__515_w_kv,__521_b_kv)\n",
      "\t__523__11 = torch.chunk(__524_fv,2,-1)\n",
      "\t__526_k = __523__11[0]\n",
      "\t__533__13 = torch.Tensor.contiguous(__526_k)\n",
      "\t__534__14 = torch.Tensor.size(__526_k,0)\n",
      "\t__536_fv = torch.mul(__500_bsz,tensor(16))\n",
      "\t__535__15 = [__534__14,__536_fv,__504_head_dim]\n",
      "\t__538_fv = torch.Tensor.view(__533__13,__535__15)\n",
      "\t__537_k0 = torch.transpose(__538_fv,0,1)\n",
      "\t__547_fv = torch.transpose(__537_k0,-2,-1)\n",
      "\t__546_input = torch.bmm(__545_q2,__547_fv)\n",
      "\t__548_input0 = torch.softmax(__546_input,-1)\n",
      "\t__549_attn = torch.dropout(__548_input0,0.1,True)\n",
      "\t__527_v = __523__11[1]\n",
      "\t__539__16 = torch.Tensor.contiguous(__527_v)\n",
      "\t__540__17 = torch.Tensor.size(__527_v,0)\n",
      "\t__542_fv = torch.mul(__500_bsz,tensor(16))\n",
      "\t__541__18 = [__540__17,__542_fv,__504_head_dim]\n",
      "\t__544_fv = torch.Tensor.view(__539__16,__541__18)\n",
      "\t__543_v0 = torch.transpose(__544_fv,0,1)\n",
      "\t__550_attn_output = torch.bmm(__549_attn,__543_v0)\n",
      "\t__552_fv = torch.transpose(__550_attn_output,0,1)\n",
      "\t__551__19 = torch.Tensor.contiguous(__552_fv)\n",
      "\t__554_fv = [__497_tgt_len,__500_bsz,__502_embed_dim]\n",
      "\t__553_attn_output0 = torch.Tensor.view(__551__19,__554_fv)\n",
      "\t__555_input1 = torch.nn.functional.linear(__553_attn_output0,self.decoder.layers[2].multihead_attn.out_proj.weight,self.decoder.layers[2].multihead_attn.out_proj.bias)\n",
      "\t__557__0 = torch.dropout(__555_input1,0.1,True)\n",
      "\t__556_input0 = torch.add(__488_query,__557__0)\n",
      "\t__562_fv = [512]\n",
      "\t__561_input0 = torch.layer_norm(__556_input0,__562_fv,self.decoder.layers[2].norm2.weight,self.decoder.layers[2].norm2.bias)\n",
      "\t__566_input = torch.nn.functional.linear(__561_input0,self.decoder.layers[2].linear1.weight,self.decoder.layers[2].linear1.bias)\n",
      "\t__563_input1 = torch.relu(__566_input)\n",
      "\t__568_input0 = torch.dropout(__563_input1,0.1,True)\n",
      "\t__571_input = torch.nn.functional.linear(__568_input0,self.decoder.layers[2].linear2.weight,self.decoder.layers[2].linear2.bias)\n",
      "\t__573__0 = torch.dropout(__571_input,0.1,True)\n",
      "\t__572_input2 = torch.add(__561_input0,__573__0)\n",
      "\t__577_fv = [512]\n",
      "\t__576_query = torch.layer_norm(__572_input2,__577_fv,self.decoder.layers[2].norm3.weight,self.decoder.layers[2].norm3.bias)\n",
      "\t__607__7 = torch.nn.functional.linear(__576_query,self.decoder.layers[3].self_attn.in_proj_weight,self.decoder.layers[3].self_attn.in_proj_bias)\n",
      "\t__608_fv = torch.chunk(__607__7,3,-1)\n",
      "\t__609_q = __608_fv[0]\n",
      "\t__612__8 = torch.Tensor.contiguous(__609_q)\n",
      "\t__596_tgt_len = torch.Tensor.size(__576_query,0)\n",
      "\t__599_bsz = torch.Tensor.size(__576_query,1)\n",
      "\t__614_fv = torch.mul(__599_bsz,tensor(16))\n",
      "\t__601_embed_dim = torch.Tensor.size(__576_query,2)\n",
      "\t__603_head_dim = torch.div(__601_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__613__9 = [__596_tgt_len,__614_fv,__603_head_dim]\n",
      "\t__616_fv = torch.Tensor.view(__612__8,__613__9)\n",
      "\t__615_q0 = torch.transpose(__616_fv,0,1)\n",
      "\t__629_q1 = torch.div(__615_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__610_k = __608_fv[1]\n",
      "\t__617__10 = torch.Tensor.contiguous(__610_k)\n",
      "\t__618__11 = torch.Tensor.size(__610_k,0)\n",
      "\t__620_fv = torch.mul(__599_bsz,tensor(16))\n",
      "\t__619__12 = [__618__11,__620_fv,__603_head_dim]\n",
      "\t__622_fv = torch.Tensor.view(__617__10,__619__12)\n",
      "\t__621_k0 = torch.transpose(__622_fv,0,1)\n",
      "\t__631_fv = torch.transpose(__621_k0,-2,-1)\n",
      "\t__630_input = torch.bmm(__629_q1,__631_fv)\n",
      "\t__632_input0 = torch.softmax(__630_input,-1)\n",
      "\t__633_attn = torch.dropout(__632_input0,0.1,True)\n",
      "\t__611_v = __608_fv[2]\n",
      "\t__623__13 = torch.Tensor.contiguous(__611_v)\n",
      "\t__624__14 = torch.Tensor.size(__611_v,0)\n",
      "\t__626_fv = torch.mul(__599_bsz,tensor(16))\n",
      "\t__625__15 = [__624__14,__626_fv,__603_head_dim]\n",
      "\t__628_fv = torch.Tensor.view(__623__13,__625__15)\n",
      "\t__627_v0 = torch.transpose(__628_fv,0,1)\n",
      "\t__634_attn_output = torch.bmm(__633_attn,__627_v0)\n",
      "\t__636_fv = torch.transpose(__634_attn_output,0,1)\n",
      "\t__635__16 = torch.Tensor.contiguous(__636_fv)\n",
      "\t__638_fv = [__596_tgt_len,__599_bsz,__601_embed_dim]\n",
      "\t__637_attn_output0 = torch.Tensor.view(__635__16,__638_fv)\n",
      "\t__639_input1 = torch.nn.functional.linear(__637_attn_output0,self.decoder.layers[3].self_attn.out_proj.weight,self.decoder.layers[3].self_attn.out_proj.bias)\n",
      "\t__640__0 = torch.dropout(__639_input1,0.1,True)\n",
      "\t__641_input = torch.add(__576_query,__640__0)\n",
      "\t__646_fv = [512]\n",
      "\t__645_query = torch.layer_norm(__641_input,__646_fv,self.decoder.layers[3].norm1.weight,self.decoder.layers[3].norm1.bias)\n",
      "\t__665_E = torch.Tensor.size(__645_query,-1)\n",
      "\t__668_fv = torch.mul(__665_E,tensor(2))\n",
      "\t__667__8 = [__665_E,__668_fv]\n",
      "\t__669__9 = torch.split_with_sizes(self.decoder.layers[3].multihead_attn.in_proj_weight,__667__8)\n",
      "\t__671_w_q = __669__9[0]\n",
      "\t__675_fv = torch.mul(__665_E,tensor(2))\n",
      "\t__674_fv = [__665_E,__675_fv]\n",
      "\t__673__10 = torch.split_with_sizes(self.decoder.layers[3].multihead_attn.in_proj_bias,__674_fv)\n",
      "\t__677_b_q = __673__10[0]\n",
      "\t__679_q = torch.nn.functional.linear(__645_query,__671_w_q,__677_b_q)\n",
      "\t__685_q0 = torch.Tensor.contiguous(__679_q)\n",
      "\t__654_tgt_len = torch.Tensor.size(__645_query,0)\n",
      "\t__657_bsz = torch.Tensor.size(__645_query,1)\n",
      "\t__687_fv = torch.mul(__657_bsz,tensor(16))\n",
      "\t__659_embed_dim = torch.Tensor.size(__645_query,2)\n",
      "\t__661_head_dim = torch.div(__659_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__686__12 = [__654_tgt_len,__687_fv,__661_head_dim]\n",
      "\t__689_fv = torch.Tensor.view(__685_q0,__686__12)\n",
      "\t__688_q1 = torch.transpose(__689_fv,0,1)\n",
      "\t__702_q2 = torch.div(__688_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__672_w_kv = __669__9[1]\n",
      "\t__678_b_kv = __673__10[1]\n",
      "\t__681_fv = torch.nn.functional.linear(__90_key,__672_w_kv,__678_b_kv)\n",
      "\t__680__11 = torch.chunk(__681_fv,2,-1)\n",
      "\t__683_k = __680__11[0]\n",
      "\t__690__13 = torch.Tensor.contiguous(__683_k)\n",
      "\t__691__14 = torch.Tensor.size(__683_k,0)\n",
      "\t__693_fv = torch.mul(__657_bsz,tensor(16))\n",
      "\t__692__15 = [__691__14,__693_fv,__661_head_dim]\n",
      "\t__695_fv = torch.Tensor.view(__690__13,__692__15)\n",
      "\t__694_k0 = torch.transpose(__695_fv,0,1)\n",
      "\t__704_fv = torch.transpose(__694_k0,-2,-1)\n",
      "\t__703_input = torch.bmm(__702_q2,__704_fv)\n",
      "\t__705_input0 = torch.softmax(__703_input,-1)\n",
      "\t__706_attn = torch.dropout(__705_input0,0.1,True)\n",
      "\t__684_v = __680__11[1]\n",
      "\t__696__16 = torch.Tensor.contiguous(__684_v)\n",
      "\t__697__17 = torch.Tensor.size(__684_v,0)\n",
      "\t__699_fv = torch.mul(__657_bsz,tensor(16))\n",
      "\t__698__18 = [__697__17,__699_fv,__661_head_dim]\n",
      "\t__701_fv = torch.Tensor.view(__696__16,__698__18)\n",
      "\t__700_v0 = torch.transpose(__701_fv,0,1)\n",
      "\t__707_attn_output = torch.bmm(__706_attn,__700_v0)\n",
      "\t__709_fv = torch.transpose(__707_attn_output,0,1)\n",
      "\t__708__19 = torch.Tensor.contiguous(__709_fv)\n",
      "\t__711_fv = [__654_tgt_len,__657_bsz,__659_embed_dim]\n",
      "\t__710_attn_output0 = torch.Tensor.view(__708__19,__711_fv)\n",
      "\t__712_input1 = torch.nn.functional.linear(__710_attn_output0,self.decoder.layers[3].multihead_attn.out_proj.weight,self.decoder.layers[3].multihead_attn.out_proj.bias)\n",
      "\t__714__0 = torch.dropout(__712_input1,0.1,True)\n",
      "\t__713_input0 = torch.add(__645_query,__714__0)\n",
      "\t__719_fv = [512]\n",
      "\t__718_input0 = torch.layer_norm(__713_input0,__719_fv,self.decoder.layers[3].norm2.weight,self.decoder.layers[3].norm2.bias)\n",
      "\t__723_input = torch.nn.functional.linear(__718_input0,self.decoder.layers[3].linear1.weight,self.decoder.layers[3].linear1.bias)\n",
      "\t__720_input1 = torch.relu(__723_input)\n",
      "\t__725_input0 = torch.dropout(__720_input1,0.1,True)\n",
      "\t__728_input = torch.nn.functional.linear(__725_input0,self.decoder.layers[3].linear2.weight,self.decoder.layers[3].linear2.bias)\n",
      "\t__730__0 = torch.dropout(__728_input,0.1,True)\n",
      "\t__729_input2 = torch.add(__718_input0,__730__0)\n",
      "\t__734_fv = [512]\n",
      "\t__733_query = torch.layer_norm(__729_input2,__734_fv,self.decoder.layers[3].norm3.weight,self.decoder.layers[3].norm3.bias)\n",
      "\t__765__7 = torch.nn.functional.linear(__733_query,self.decoder.layers[4].self_attn.in_proj_weight,self.decoder.layers[4].self_attn.in_proj_bias)\n",
      "\t__766_fv = torch.chunk(__765__7,3,-1)\n",
      "\t__767_q = __766_fv[0]\n",
      "\t__770__8 = torch.Tensor.contiguous(__767_q)\n",
      "\t__754_tgt_len = torch.Tensor.size(__733_query,0)\n",
      "\t__757_bsz = torch.Tensor.size(__733_query,1)\n",
      "\t__772_fv = torch.mul(__757_bsz,tensor(16))\n",
      "\t__759_embed_dim = torch.Tensor.size(__733_query,2)\n",
      "\t__761_head_dim = torch.div(__759_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__771__9 = [__754_tgt_len,__772_fv,__761_head_dim]\n",
      "\t__774_fv = torch.Tensor.view(__770__8,__771__9)\n",
      "\t__773_q0 = torch.transpose(__774_fv,0,1)\n",
      "\t__787_q1 = torch.div(__773_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__768_k = __766_fv[1]\n",
      "\t__775__10 = torch.Tensor.contiguous(__768_k)\n",
      "\t__776__11 = torch.Tensor.size(__768_k,0)\n",
      "\t__778_fv = torch.mul(__757_bsz,tensor(16))\n",
      "\t__777__12 = [__776__11,__778_fv,__761_head_dim]\n",
      "\t__780_fv = torch.Tensor.view(__775__10,__777__12)\n",
      "\t__779_k0 = torch.transpose(__780_fv,0,1)\n",
      "\t__789_fv = torch.transpose(__779_k0,-2,-1)\n",
      "\t__788_input = torch.bmm(__787_q1,__789_fv)\n",
      "\t__790_input0 = torch.softmax(__788_input,-1)\n",
      "\t__791_attn = torch.dropout(__790_input0,0.1,True)\n",
      "\t__769_v = __766_fv[2]\n",
      "\t__781__13 = torch.Tensor.contiguous(__769_v)\n",
      "\t__782__14 = torch.Tensor.size(__769_v,0)\n",
      "\t__784_fv = torch.mul(__757_bsz,tensor(16))\n",
      "\t__783__15 = [__782__14,__784_fv,__761_head_dim]\n",
      "\t__786_fv = torch.Tensor.view(__781__13,__783__15)\n",
      "\t__785_v0 = torch.transpose(__786_fv,0,1)\n",
      "\t__792_attn_output = torch.bmm(__791_attn,__785_v0)\n",
      "\t__794_fv = torch.transpose(__792_attn_output,0,1)\n",
      "\t__793__16 = torch.Tensor.contiguous(__794_fv)\n",
      "\t__796_fv = [__754_tgt_len,__757_bsz,__759_embed_dim]\n",
      "\t__795_attn_output0 = torch.Tensor.view(__793__16,__796_fv)\n",
      "\t__797_input1 = torch.nn.functional.linear(__795_attn_output0,self.decoder.layers[4].self_attn.out_proj.weight,self.decoder.layers[4].self_attn.out_proj.bias)\n",
      "\t__798__0 = torch.dropout(__797_input1,0.1,True)\n",
      "\t__799_input = torch.add(__733_query,__798__0)\n",
      "\t__804_fv = [512]\n",
      "\t__803_query = torch.layer_norm(__799_input,__804_fv,self.decoder.layers[4].norm1.weight,self.decoder.layers[4].norm1.bias)\n",
      "\t__823_E = torch.Tensor.size(__803_query,-1)\n",
      "\t__826_fv = torch.mul(__823_E,tensor(2))\n",
      "\t__825__8 = [__823_E,__826_fv]\n",
      "\t__827__9 = torch.split_with_sizes(self.decoder.layers[4].multihead_attn.in_proj_weight,__825__8)\n",
      "\t__829_w_q = __827__9[0]\n",
      "\t__833_fv = torch.mul(__823_E,tensor(2))\n",
      "\t__832_fv = [__823_E,__833_fv]\n",
      "\t__831__10 = torch.split_with_sizes(self.decoder.layers[4].multihead_attn.in_proj_bias,__832_fv)\n",
      "\t__835_b_q = __831__10[0]\n",
      "\t__837_q = torch.nn.functional.linear(__803_query,__829_w_q,__835_b_q)\n",
      "\t__843_q0 = torch.Tensor.contiguous(__837_q)\n",
      "\t__812_tgt_len = torch.Tensor.size(__803_query,0)\n",
      "\t__815_bsz = torch.Tensor.size(__803_query,1)\n",
      "\t__845_fv = torch.mul(__815_bsz,tensor(16))\n",
      "\t__817_embed_dim = torch.Tensor.size(__803_query,2)\n",
      "\t__819_head_dim = torch.div(__817_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__844__12 = [__812_tgt_len,__845_fv,__819_head_dim]\n",
      "\t__847_fv = torch.Tensor.view(__843_q0,__844__12)\n",
      "\t__846_q1 = torch.transpose(__847_fv,0,1)\n",
      "\t__860_q2 = torch.div(__846_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__830_w_kv = __827__9[1]\n",
      "\t__836_b_kv = __831__10[1]\n",
      "\t__839_fv = torch.nn.functional.linear(__90_key,__830_w_kv,__836_b_kv)\n",
      "\t__838__11 = torch.chunk(__839_fv,2,-1)\n",
      "\t__841_k = __838__11[0]\n",
      "\t__848__13 = torch.Tensor.contiguous(__841_k)\n",
      "\t__849__14 = torch.Tensor.size(__841_k,0)\n",
      "\t__851_fv = torch.mul(__815_bsz,tensor(16))\n",
      "\t__850__15 = [__849__14,__851_fv,__819_head_dim]\n",
      "\t__853_fv = torch.Tensor.view(__848__13,__850__15)\n",
      "\t__852_k0 = torch.transpose(__853_fv,0,1)\n",
      "\t__862_fv = torch.transpose(__852_k0,-2,-1)\n",
      "\t__861_input = torch.bmm(__860_q2,__862_fv)\n",
      "\t__863_input0 = torch.softmax(__861_input,-1)\n",
      "\t__864_attn = torch.dropout(__863_input0,0.1,True)\n",
      "\t__842_v = __838__11[1]\n",
      "\t__854__16 = torch.Tensor.contiguous(__842_v)\n",
      "\t__855__17 = torch.Tensor.size(__842_v,0)\n",
      "\t__857_fv = torch.mul(__815_bsz,tensor(16))\n",
      "\t__856__18 = [__855__17,__857_fv,__819_head_dim]\n",
      "\t__859_fv = torch.Tensor.view(__854__16,__856__18)\n",
      "\t__858_v0 = torch.transpose(__859_fv,0,1)\n",
      "\t__865_attn_output = torch.bmm(__864_attn,__858_v0)\n",
      "\t__867_fv = torch.transpose(__865_attn_output,0,1)\n",
      "\t__866__19 = torch.Tensor.contiguous(__867_fv)\n",
      "\t__869_fv = [__812_tgt_len,__815_bsz,__817_embed_dim]\n",
      "\t__868_attn_output0 = torch.Tensor.view(__866__19,__869_fv)\n",
      "\t__870_input1 = torch.nn.functional.linear(__868_attn_output0,self.decoder.layers[4].multihead_attn.out_proj.weight,self.decoder.layers[4].multihead_attn.out_proj.bias)\n",
      "\t__872__0 = torch.dropout(__870_input1,0.1,True)\n",
      "\t__871_input0 = torch.add(__803_query,__872__0)\n",
      "\t__877_fv = [512]\n",
      "\t__876_input0 = torch.layer_norm(__871_input0,__877_fv,self.decoder.layers[4].norm2.weight,self.decoder.layers[4].norm2.bias)\n",
      "\t__881_input = torch.nn.functional.linear(__876_input0,self.decoder.layers[4].linear1.weight,self.decoder.layers[4].linear1.bias)\n",
      "\t__878_input1 = torch.relu(__881_input)\n",
      "\t__883_input0 = torch.dropout(__878_input1,0.1,True)\n",
      "\t__886_input = torch.nn.functional.linear(__883_input0,self.decoder.layers[4].linear2.weight,self.decoder.layers[4].linear2.bias)\n",
      "\t__888__0 = torch.dropout(__886_input,0.1,True)\n",
      "\t__887_input2 = torch.add(__876_input0,__888__0)\n",
      "\t__892_fv = [512]\n",
      "\t__891_query = torch.layer_norm(__887_input2,__892_fv,self.decoder.layers[4].norm3.weight,self.decoder.layers[4].norm3.bias)\n",
      "\t__922__7 = torch.nn.functional.linear(__891_query,self.decoder.layers[5].self_attn.in_proj_weight,self.decoder.layers[5].self_attn.in_proj_bias)\n",
      "\t__923_fv = torch.chunk(__922__7,3,-1)\n",
      "\t__924_q = __923_fv[0]\n",
      "\t__927__8 = torch.Tensor.contiguous(__924_q)\n",
      "\t__911_tgt_len = torch.Tensor.size(__891_query,0)\n",
      "\t__914_bsz = torch.Tensor.size(__891_query,1)\n",
      "\t__929_fv = torch.mul(__914_bsz,tensor(16))\n",
      "\t__916_embed_dim = torch.Tensor.size(__891_query,2)\n",
      "\t__918_head_dim = torch.div(__916_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__928__9 = [__911_tgt_len,__929_fv,__918_head_dim]\n",
      "\t__931_fv = torch.Tensor.view(__927__8,__928__9)\n",
      "\t__930_q0 = torch.transpose(__931_fv,0,1)\n",
      "\t__944_q1 = torch.div(__930_q0,tensor(5.6569, dtype=torch.float64))\n",
      "\t__925_k = __923_fv[1]\n",
      "\t__932__10 = torch.Tensor.contiguous(__925_k)\n",
      "\t__933__11 = torch.Tensor.size(__925_k,0)\n",
      "\t__935_fv = torch.mul(__914_bsz,tensor(16))\n",
      "\t__934__12 = [__933__11,__935_fv,__918_head_dim]\n",
      "\t__937_fv = torch.Tensor.view(__932__10,__934__12)\n",
      "\t__936_k0 = torch.transpose(__937_fv,0,1)\n",
      "\t__946_fv = torch.transpose(__936_k0,-2,-1)\n",
      "\t__945_input = torch.bmm(__944_q1,__946_fv)\n",
      "\t__947_input0 = torch.softmax(__945_input,-1)\n",
      "\t__948_attn = torch.dropout(__947_input0,0.1,True)\n",
      "\t__926_v = __923_fv[2]\n",
      "\t__938__13 = torch.Tensor.contiguous(__926_v)\n",
      "\t__939__14 = torch.Tensor.size(__926_v,0)\n",
      "\t__941_fv = torch.mul(__914_bsz,tensor(16))\n",
      "\t__940__15 = [__939__14,__941_fv,__918_head_dim]\n",
      "\t__943_fv = torch.Tensor.view(__938__13,__940__15)\n",
      "\t__942_v0 = torch.transpose(__943_fv,0,1)\n",
      "\t__949_attn_output = torch.bmm(__948_attn,__942_v0)\n",
      "\t__951_fv = torch.transpose(__949_attn_output,0,1)\n",
      "\t__950__16 = torch.Tensor.contiguous(__951_fv)\n",
      "\t__953_fv = [__911_tgt_len,__914_bsz,__916_embed_dim]\n",
      "\t__952_attn_output0 = torch.Tensor.view(__950__16,__953_fv)\n",
      "\t__954_input1 = torch.nn.functional.linear(__952_attn_output0,self.decoder.layers[5].self_attn.out_proj.weight,self.decoder.layers[5].self_attn.out_proj.bias)\n",
      "\t__955__0 = torch.dropout(__954_input1,0.1,True)\n",
      "\t__956_input = torch.add(__891_query,__955__0)\n",
      "\t__961_fv = [512]\n",
      "\t__960_query = torch.layer_norm(__956_input,__961_fv,self.decoder.layers[5].norm1.weight,self.decoder.layers[5].norm1.bias)\n",
      "\t__980_E = torch.Tensor.size(__960_query,-1)\n",
      "\t__983_fv = torch.mul(__980_E,tensor(2))\n",
      "\t__982__8 = [__980_E,__983_fv]\n",
      "\t__984__9 = torch.split_with_sizes(self.decoder.layers[5].multihead_attn.in_proj_weight,__982__8)\n",
      "\t__986_w_q = __984__9[0]\n",
      "\t__990_fv = torch.mul(__980_E,tensor(2))\n",
      "\t__989_fv = [__980_E,__990_fv]\n",
      "\t__988__10 = torch.split_with_sizes(self.decoder.layers[5].multihead_attn.in_proj_bias,__989_fv)\n",
      "\t__992_b_q = __988__10[0]\n",
      "\t__994_q = torch.nn.functional.linear(__960_query,__986_w_q,__992_b_q)\n",
      "\t__1000_q0 = torch.Tensor.contiguous(__994_q)\n",
      "\t__969_tgt_len = torch.Tensor.size(__960_query,0)\n",
      "\t__972_bsz = torch.Tensor.size(__960_query,1)\n",
      "\t__1002_fv = torch.mul(__972_bsz,tensor(16))\n",
      "\t__974_embed_dim = torch.Tensor.size(__960_query,2)\n",
      "\t__976_head_dim = torch.div(__974_embed_dim,tensor(16),rounding_mode = \"trunc\")\n",
      "\t__1001__12 = [__969_tgt_len,__1002_fv,__976_head_dim]\n",
      "\t__1004_fv = torch.Tensor.view(__1000_q0,__1001__12)\n",
      "\t__1003_q1 = torch.transpose(__1004_fv,0,1)\n",
      "\t__1017_q2 = torch.div(__1003_q1,tensor(5.6569, dtype=torch.float64))\n",
      "\t__987_w_kv = __984__9[1]\n",
      "\t__993_b_kv = __988__10[1]\n",
      "\t__996_fv = torch.nn.functional.linear(__90_key,__987_w_kv,__993_b_kv)\n",
      "\t__995__11 = torch.chunk(__996_fv,2,-1)\n",
      "\t__998_k = __995__11[0]\n",
      "\t__1005__13 = torch.Tensor.contiguous(__998_k)\n",
      "\t__1006__14 = torch.Tensor.size(__998_k,0)\n",
      "\t__1008_fv = torch.mul(__972_bsz,tensor(16))\n",
      "\t__1007__15 = [__1006__14,__1008_fv,__976_head_dim]\n",
      "\t__1010_fv = torch.Tensor.view(__1005__13,__1007__15)\n",
      "\t__1009_k0 = torch.transpose(__1010_fv,0,1)\n",
      "\t__1019_fv = torch.transpose(__1009_k0,-2,-1)\n",
      "\t__1018_input = torch.bmm(__1017_q2,__1019_fv)\n",
      "\t__1020_input0 = torch.softmax(__1018_input,-1)\n",
      "\t__1021_attn = torch.dropout(__1020_input0,0.1,True)\n",
      "\t__999_v = __995__11[1]\n",
      "\t__1011__16 = torch.Tensor.contiguous(__999_v)\n",
      "\t__1012__17 = torch.Tensor.size(__999_v,0)\n",
      "\t__1014_fv = torch.mul(__972_bsz,tensor(16))\n",
      "\t__1013__18 = [__1012__17,__1014_fv,__976_head_dim]\n",
      "\t__1016_fv = torch.Tensor.view(__1011__16,__1013__18)\n",
      "\t__1015_v0 = torch.transpose(__1016_fv,0,1)\n",
      "\t__1022_attn_output = torch.bmm(__1021_attn,__1015_v0)\n",
      "\t__1024_fv = torch.transpose(__1022_attn_output,0,1)\n",
      "\t__1023__19 = torch.Tensor.contiguous(__1024_fv)\n",
      "\t__1026_fv = [__969_tgt_len,__972_bsz,__974_embed_dim]\n",
      "\t__1025_attn_output0 = torch.Tensor.view(__1023__19,__1026_fv)\n",
      "\t__1027_input1 = torch.nn.functional.linear(__1025_attn_output0,self.decoder.layers[5].multihead_attn.out_proj.weight,self.decoder.layers[5].multihead_attn.out_proj.bias)\n",
      "\t__1029__0 = torch.dropout(__1027_input1,0.1,True)\n",
      "\t__1028_input0 = torch.add(__960_query,__1029__0)\n",
      "\t__1034_fv = [512]\n",
      "\t__1033_input0 = torch.layer_norm(__1028_input0,__1034_fv,self.decoder.layers[5].norm2.weight,self.decoder.layers[5].norm2.bias)\n",
      "\t__1038_input = torch.nn.functional.linear(__1033_input0,self.decoder.layers[5].linear1.weight,self.decoder.layers[5].linear1.bias)\n",
      "\t__1035_input1 = torch.relu(__1038_input)\n",
      "\t__1040_input0 = torch.dropout(__1035_input1,0.1,True)\n",
      "\t__1043_input = torch.nn.functional.linear(__1040_input0,self.decoder.layers[5].linear2.weight,self.decoder.layers[5].linear2.bias)\n",
      "\t__1045__0 = torch.dropout(__1043_input,0.1,True)\n",
      "\t__1044_input2 = torch.add(__1033_input0,__1045__0)\n",
      "\t__1049_fv = [512]\n",
      "\t__1048_input0 = torch.layer_norm(__1044_input2,__1049_fv,self.decoder.layers[5].norm3.weight,self.decoder.layers[5].norm3.bias)\n",
      "\t__1053_fv = [512]\n",
      "\t__1052__0 = torch.layer_norm(__1048_input0,__1053_fv,self.decoder.norm.weight,self.decoder.norm.bias)\n",
      "\treturn __1052__0\n"
     ]
    }
   ],
   "source": [
    "mod_tf = nn.Transformer(nhead=16, num_encoder_layers=1)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((10, 32, 512))\n",
    "modtf_Bg = read_trace_code.main(mod_tf,(src,tgt),show_debug=True)\n",
    "modtf_Dg = Btools.B_to_D(modtf_Bg)\n",
    "Btools.print_code(modtf_Dg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24947c92-ff0a-4d0e-8b9a-f7c2e79d428f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test on GPT2 made from scratch with random and nlayers=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13addc3-bf67-40ee-b2d9-90eaf1db1f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import ModuleList\n",
    "from torch.nn.modules.normalization import LayerNorm\n",
    "\n",
    "class Conv1D(nn.Module):\n",
    "    def __init__(self, nx, nf):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        w = torch.empty(nx, nf)\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "        x = x.view(size_out)\n",
    "        return x\n",
    "    \n",
    "# Examples :\n",
    "\"\"\"\n",
    "d_model = 768\n",
    "conv1d  = Conv1D(d_model, d_model*3)\n",
    "x       = torch.rand(1,4,d_model) #represents a sequence of batch_size=1, seq_len=4 and embedding_sz=768, something like \"Hello how are you\"\n",
    "x       = conv1d(x)\n",
    "print(x.shape)\n",
    "\n",
    "query, key, value = x.split(d_model, dim=-1)\n",
    "\n",
    "print(query.shape, key.shape, value.shape)\n",
    "\"\"\"\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dropout, d_model=768, nx=768*4):\n",
    "        super().__init__()\n",
    "        self.c_fc    = Conv1D(d_model, nx)\n",
    "        self.c_proj  = Conv1D(nx, d_model)\n",
    "        self.act     = F.gelu\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.c_proj(self.act(self.c_fc(x))))\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, n_ctx=1024, d_head=64, bias=True, scale=False):\n",
    "        super().__init__()\n",
    "        self.n_head  = n_head\n",
    "        self.d_model = d_model\n",
    "        self.c_attn  = Conv1D(d_model, d_model*3)\n",
    "        self.scale   = scale\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.c_proj  = Conv1D(d_model, d_model)\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        \"return shape [`batch`, `head`, `sequence`, `features`]\"\n",
    "        new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head) \n",
    "        x = x.view(new_shape)\n",
    "        return x.permute(0, 2, 1, 3) \n",
    "    \n",
    "    def _attn(self, q, k, v, attn_mask=None):\n",
    "        scores  = torch.matmul(q, k.transpose(-2, -1))\n",
    "        if self.scale: scores = scores/math.sqrt(v.size(-1))\n",
    "        nd, ns  = scores.size(-2), scores.size(-1)\n",
    "        if attn_mask is not None: scores = scores + attn_mask\n",
    "        scores  = self.softmax(scores)\n",
    "        scores  = self.dropout(scores)\n",
    "        outputs = torch.matmul(scores, v)\n",
    "        return outputs\n",
    "    \n",
    "    def merge_heads(self, x):\n",
    "        x         = x.permute(0, 2, 1, 3).contiguous()\n",
    "        new_shape = x.size()[:-2] + (x.size(-2)*x.size(-1),)\n",
    "        return x.view(new_shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x        = self.c_attn(x) #new `x` shape - `[1,3,2304]`\n",
    "        q, k, v  = x.split(self.d_model, dim=2)\n",
    "        q, k, v  = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "        out      = self._attn(q, k, v)\n",
    "        out      = self.merge_heads(out)\n",
    "        out      = self.c_proj(out)\n",
    "        return out\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn        = Attention(d_model=768, n_head=12, d_head=64, n_ctx=1024, bias=True, scale=False)\n",
    "        self.feedforward = FeedForward(dropout=0.1, d_model=768, nx=768*4)\n",
    "        self.ln_1        = LayerNorm(d_model)\n",
    "        self.ln_2        = LayerNorm(d_model)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.feedforward(self.ln_2(x))\n",
    "        return x\n",
    "    \n",
    "def _get_clones(module, n):\n",
    "    return ModuleList([copy.deepcopy(module) for i in range(n)])\n",
    "\n",
    "class GPT2(nn.Module):\n",
    "    def __init__(self, nlayers=12, n_ctx=1024, d_model=768, vcb_sz=50257):\n",
    "        super(GPT2, self).__init__()\n",
    "        self.nlayers = nlayers\n",
    "        block        = TransformerBlock(d_model=768, n_head=12, dropout=0.1)\n",
    "        self.h       = _get_clones(block, 12)\n",
    "        self.wte     = nn.Embedding(vcb_sz, d_model)\n",
    "        self.wpe     = nn.Embedding(n_ctx, d_model)\n",
    "        self.drop    = nn.Dropout(0.1)\n",
    "        self.ln_f    = LayerNorm(d_model)\n",
    "        self.out     = nn.Linear(d_model, vcb_sz, bias=False)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.out.weight = self.wte.weight\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding, Conv1D)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if isinstance(module, (nn.Linear, Conv1D)) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, src, labels=None, pos_ids=None):\n",
    "        if pos_ids is None: pos_ids = torch.arange(0, src.size(-1)).unsqueeze(0)\n",
    "        inp = self.drop((self.wte(src)+self.wpe(pos_ids)))\n",
    "        for i in range(self.nlayers): inp = self.h[i](inp)\n",
    "        inp     = self.ln_f(inp)\n",
    "        logits  = self.out(inp)\n",
    "        outputs = (logits,) + (inp,)\n",
    "        \n",
    "        if labels is not None:\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            loss = self.loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "            return outputs\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb9c80c4-936b-41e9-9f41-035632acb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2(nlayers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "720d6915-4695-49f8-a4ed-68d92d689f18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "# load pretrained_weights from hugging face\n",
    "# download file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin to `.`\n",
    "\n",
    "model_dict = model.state_dict() #currently with random initialization\n",
    "state_dict = torch.load(\"./gpt2-pytorch_model.bin\") #pretrained weights\n",
    "\n",
    "old_keys = []\n",
    "new_keys = []\n",
    "for key in state_dict.keys(): \n",
    "    if \"mlp\" in key: #The hugging face state dict references the feedforward network as mlp, need to replace to `feedforward` be able to reuse these weights\n",
    "        new_key = key.replace(\"mlp\", \"feedforward\")\n",
    "        new_keys.append(new_key)\n",
    "        old_keys.append(key)\n",
    "\n",
    "for old_key, new_key in zip(old_keys, new_keys): \n",
    "    state_dict[new_key]=state_dict.pop(old_key)\n",
    "\n",
    "pretrained_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d342fb8-c558-4822-99ba-d38ba4e7e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "context1  = torch.tensor([tokenizer.encode(\"The planet earth\")])\n",
    "context2  = torch.tensor([tokenizer.encode(\"I'm upset with those tools\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ad9eaa0-6c77-4dd1-b24e-cdaddc51ff4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  feedforward = self.feedforward\n",
      "  attn = self.attn\n",
      "  ln_2 = self.ln_2\n",
      "  ln_1 = self.ln_1\n",
      "  _0 = (ln_1).forward(argument_1, )\n",
      "  _1 = (ln_2).forward(argument_1, )\n",
      "  x = torch.add(argument_1, (attn).forward(_0, ))\n",
      "  input = torch.add(x, (feedforward).forward(_1, ))\n",
      "  return input\n",
      "\n",
      "In self.forward try to sub open self.wte.forward\n",
      "In self.forward try to sub open self.wpe.forward\n",
      "In self.forward try to sub open self.drop.forward\n",
      "In self.forward try to sub open self.h[0].forward\n",
      "In self.h[0].forward try to sub open self.h[0].ln_1.forward\n",
      "In self.h[0].forward try to sub open self.h[0].ln_2.forward\n",
      "In self.h[0].forward try to sub open self.h[0].attn.forward\n",
      "In self.h[0].attn.forward try to sub open self.h[0].attn.c_attn.forward\n",
      "In self.h[0].attn.forward try to sub open self.h[0].attn.softmax.forward\n",
      "In self.h[0].attn.forward try to sub open self.h[0].attn.dropout.forward\n",
      "In self.h[0].attn.forward try to sub open self.h[0].attn.c_proj.forward\n",
      "In self.h[0].forward try to sub open self.h[0].feedforward.forward\n",
      "In self.h[0].feedforward.forward try to sub open self.h[0].feedforward.c_fc.forward\n",
      "In self.h[0].feedforward.forward try to sub open self.h[0].feedforward.c_proj.forward\n",
      "In self.h[0].feedforward.forward try to sub open self.h[0].feedforward.dropout.forward\n",
      "In self.forward try to sub open self.h[0].forward1\n",
      "In self.h[0].forward1 try to sub open self.h[0].ln_1.forward1\n",
      "In self.h[0].forward1 try to sub open self.h[0].ln_2.forward1\n",
      "In self.h[0].forward1 try to sub open self.h[0].attn.forward1\n",
      "In self.h[0].attn.forward1 try to sub open self.h[0].attn.c_attn.forward1\n",
      "In self.h[0].attn.forward1 try to sub open self.h[0].attn.softmax.forward1\n",
      "In self.h[0].attn.forward1 try to sub open self.h[0].attn.dropout.forward1\n",
      "In self.h[0].attn.forward1 try to sub open self.h[0].attn.c_proj.forward1\n",
      "In self.h[0].forward1 try to sub open self.h[0].feedforward.forward1\n",
      "In self.h[0].feedforward.forward1 try to sub open self.h[0].feedforward.c_fc.forward1\n",
      "In self.h[0].feedforward.forward1 try to sub open self.h[0].feedforward.c_proj.forward1\n",
      "In self.h[0].feedforward.forward1 try to sub open self.h[0].feedforward.dropout.forward1\n",
      "In self.forward try to sub open self.ln_f.forward\n",
      "In self.forward try to sub open self.out.forward\n",
      "{}\n",
      "def main(src):\n",
      "\t__16_fv = torch.embedding(self.wte.weight,src)\n",
      "\t__10__1 = torch.Tensor.size(src,-1)\n",
      "\t__11__2 = torch.arange(0,__10__1,1,dtype = None,device = torch.device(\"cpu\"),pin_memory = False)\n",
      "\t__13_input = torch.unsqueeze(__11__2,0)\n",
      "\t__18_fv = torch.embedding(self.wpe.weight,__13_input)\n",
      "\t__14_input0 = torch.add(__16_fv,__18_fv)\n",
      "\t__20_input0 = torch.dropout(__14_input0,0.1,False)\n",
      "\t__28_x = torch.layer_norm(__20_input0,[768],self.h[0].ln_1.weight,self.h[0].ln_1.bias)\n",
      "\t__47__4 = torch.Tensor.size(__28_x,-1)\n",
      "\t__49_fv = [-1,__47__4]\n",
      "\t__50_fv = torch.Tensor.view(__28_x,__49_fv)\n",
      "\t__48_x = torch.addmm(self.h[0].attn.c_attn.bias,__50_fv,self.h[0].attn.c_attn.weight)\n",
      "\t__43__0 = torch.Tensor.size(__28_x,0)\n",
      "\t__45__2 = torch.Tensor.size(__28_x,1)\n",
      "\t__51_fv = [__43__0,__45__2,2304]\n",
      "\t__52_fv = torch.Tensor.view(__48_x,__51_fv)\n",
      "\t__40__0 = torch.split(__52_fv,768,2)\n",
      "\t__54_x = __40__0[0]\n",
      "\t__57__1 = torch.Tensor.size(__54_x,0)\n",
      "\t__59__3 = torch.Tensor.size(__54_x,1)\n",
      "\t__61__5 = torch.Tensor.size(__54_x,-1)\n",
      "\t__62__6 = torch.div(__61__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__64_fv = [__57__1,__59__3,12,__62__6]\n",
      "\t__63_x2 = torch.Tensor.view(__54_x,__64_fv)\n",
      "\t__65_q = torch.permute(__63_x2,[0,2,1,3])\n",
      "\t__55_x0 = __40__0[1]\n",
      "\t__67__7 = torch.Tensor.size(__55_x0,0)\n",
      "\t__69__9 = torch.Tensor.size(__55_x0,1)\n",
      "\t__71__11 = torch.Tensor.size(__55_x0,-1)\n",
      "\t__72__12 = torch.div(__71__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__74_fv = [__67__7,__69__9,12,__72__12]\n",
      "\t__73_x3 = torch.Tensor.view(__55_x0,__74_fv)\n",
      "\t__75_k = torch.permute(__73_x3,[0,2,1,3])\n",
      "\t__88_fv = torch.transpose(__75_k,-2,-1)\n",
      "\t__87_scores = torch.matmul(__65_q,__88_fv)\n",
      "\t__90_fv = torch.softmax(__87_scores,-1)\n",
      "\t__91_scores = torch.dropout(__90_fv,0.1,False)\n",
      "\t__56_x1 = __40__0[2]\n",
      "\t__77__13 = torch.Tensor.size(__56_x1,0)\n",
      "\t__79__15 = torch.Tensor.size(__56_x1,1)\n",
      "\t__81__17 = torch.Tensor.size(__56_x1,-1)\n",
      "\t__82__18 = torch.div(__81__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__84_fv = [__77__13,__79__15,12,__82__18]\n",
      "\t__83_x4 = torch.Tensor.view(__56_x1,__84_fv)\n",
      "\t__85_v = torch.permute(__83_x4,[0,2,1,3])\n",
      "\t__92_x5 = torch.matmul(__91_scores,__85_v)\n",
      "\t__95_fv = torch.permute(__92_x5,[0,2,1,3])\n",
      "\t__93_x6 = torch.Tensor.contiguous(__95_fv)\n",
      "\t__96__20 = torch.Tensor.size(__93_x6,0)\n",
      "\t__98__22 = torch.Tensor.size(__93_x6,1)\n",
      "\t__100__24 = torch.Tensor.size(__93_x6,-2)\n",
      "\t__101__25 = torch.Tensor.size(__93_x6,-1)\n",
      "\t__104_fv = torch.mul(__100__24,__101__25)\n",
      "\t__103_fv = [__96__20,__98__22,__104_fv]\n",
      "\t__102_x7 = torch.Tensor.view(__93_x6,__103_fv)\n",
      "\t__111__4 = torch.Tensor.size(__102_x7,-1)\n",
      "\t__113_fv = [-1,__111__4]\n",
      "\t__114_fv = torch.Tensor.view(__102_x7,__113_fv)\n",
      "\t__112_x0 = torch.addmm(self.h[0].attn.c_proj.bias,__114_fv,self.h[0].attn.c_proj.weight)\n",
      "\t__107__0 = torch.Tensor.size(__102_x7,0)\n",
      "\t__109__2 = torch.Tensor.size(__102_x7,1)\n",
      "\t__115_fv = [__107__0,__109__2,768]\n",
      "\t__116_fv = torch.Tensor.view(__112_x0,__115_fv)\n",
      "\t__35_x = torch.add(__20_input0,__116_fv)\n",
      "\t__33_x = torch.layer_norm(__20_input0,[768],self.h[0].ln_2.weight,self.h[0].ln_2.bias)\n",
      "\t__128__4 = torch.Tensor.size(__33_x,-1)\n",
      "\t__130_fv = [-1,__128__4]\n",
      "\t__131_fv = torch.Tensor.view(__33_x,__130_fv)\n",
      "\t__129_x = torch.addmm(self.h[0].feedforward.c_fc.bias,__131_fv,self.h[0].feedforward.c_fc.weight)\n",
      "\t__124__0 = torch.Tensor.size(__33_x,0)\n",
      "\t__126__2 = torch.Tensor.size(__33_x,1)\n",
      "\t__132_fv = [__124__0,__126__2,3072]\n",
      "\t__133_fv = torch.Tensor.view(__129_x,__132_fv)\n",
      "\t__121_x = torch.nn.functional.gelu(__133_fv)\n",
      "\t__141__4 = torch.Tensor.size(__121_x,-1)\n",
      "\t__143_fv = [-1,__141__4]\n",
      "\t__144_fv = torch.Tensor.view(__121_x,__143_fv)\n",
      "\t__142_x0 = torch.addmm(self.h[0].feedforward.c_proj.bias,__144_fv,self.h[0].feedforward.c_proj.weight)\n",
      "\t__137__0 = torch.Tensor.size(__121_x,0)\n",
      "\t__139__2 = torch.Tensor.size(__121_x,1)\n",
      "\t__145_fv = [__137__0,__139__2,768]\n",
      "\t__146_fv = torch.Tensor.view(__142_x0,__145_fv)\n",
      "\t__147__0 = torch.dropout(__146_fv,0.1,False)\n",
      "\t__117_input = torch.add(__35_x,__147__0)\n",
      "\t__156_x = torch.layer_norm(__117_input,[768],self.h[0].ln_1.weight,self.h[0].ln_1.bias)\n",
      "\t__175__4 = torch.Tensor.size(__156_x,-1)\n",
      "\t__177_fv = [-1,__175__4]\n",
      "\t__178_fv = torch.Tensor.view(__156_x,__177_fv)\n",
      "\t__176_x = torch.addmm(self.h[0].attn.c_attn.bias,__178_fv,self.h[0].attn.c_attn.weight)\n",
      "\t__171__0 = torch.Tensor.size(__156_x,0)\n",
      "\t__173__2 = torch.Tensor.size(__156_x,1)\n",
      "\t__179_fv = [__171__0,__173__2,2304]\n",
      "\t__180_fv = torch.Tensor.view(__176_x,__179_fv)\n",
      "\t__168__0 = torch.split(__180_fv,768,2)\n",
      "\t__182_x = __168__0[0]\n",
      "\t__185__1 = torch.Tensor.size(__182_x,0)\n",
      "\t__187__3 = torch.Tensor.size(__182_x,1)\n",
      "\t__189__5 = torch.Tensor.size(__182_x,-1)\n",
      "\t__190__6 = torch.div(__189__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__192_fv = [__185__1,__187__3,12,__190__6]\n",
      "\t__191_x2 = torch.Tensor.view(__182_x,__192_fv)\n",
      "\t__193_q = torch.permute(__191_x2,[0,2,1,3])\n",
      "\t__183_x0 = __168__0[1]\n",
      "\t__195__7 = torch.Tensor.size(__183_x0,0)\n",
      "\t__197__9 = torch.Tensor.size(__183_x0,1)\n",
      "\t__199__11 = torch.Tensor.size(__183_x0,-1)\n",
      "\t__200__12 = torch.div(__199__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__202_fv = [__195__7,__197__9,12,__200__12]\n",
      "\t__201_x3 = torch.Tensor.view(__183_x0,__202_fv)\n",
      "\t__203_k = torch.permute(__201_x3,[0,2,1,3])\n",
      "\t__216_fv = torch.transpose(__203_k,-2,-1)\n",
      "\t__215_scores = torch.matmul(__193_q,__216_fv)\n",
      "\t__218_fv = torch.softmax(__215_scores,-1)\n",
      "\t__219_scores = torch.dropout(__218_fv,0.1,False)\n",
      "\t__184_x1 = __168__0[2]\n",
      "\t__205__13 = torch.Tensor.size(__184_x1,0)\n",
      "\t__207__15 = torch.Tensor.size(__184_x1,1)\n",
      "\t__209__17 = torch.Tensor.size(__184_x1,-1)\n",
      "\t__210__18 = torch.div(__209__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__212_fv = [__205__13,__207__15,12,__210__18]\n",
      "\t__211_x4 = torch.Tensor.view(__184_x1,__212_fv)\n",
      "\t__213_v = torch.permute(__211_x4,[0,2,1,3])\n",
      "\t__220_x5 = torch.matmul(__219_scores,__213_v)\n",
      "\t__223_fv = torch.permute(__220_x5,[0,2,1,3])\n",
      "\t__221_x6 = torch.Tensor.contiguous(__223_fv)\n",
      "\t__224__20 = torch.Tensor.size(__221_x6,0)\n",
      "\t__226__22 = torch.Tensor.size(__221_x6,1)\n",
      "\t__228__24 = torch.Tensor.size(__221_x6,-2)\n",
      "\t__229__25 = torch.Tensor.size(__221_x6,-1)\n",
      "\t__232_fv = torch.mul(__228__24,__229__25)\n",
      "\t__231_fv = [__224__20,__226__22,__232_fv]\n",
      "\t__230_x7 = torch.Tensor.view(__221_x6,__231_fv)\n",
      "\t__239__4 = torch.Tensor.size(__230_x7,-1)\n",
      "\t__241_fv = [-1,__239__4]\n",
      "\t__242_fv = torch.Tensor.view(__230_x7,__241_fv)\n",
      "\t__240_x0 = torch.addmm(self.h[0].attn.c_proj.bias,__242_fv,self.h[0].attn.c_proj.weight)\n",
      "\t__235__0 = torch.Tensor.size(__230_x7,0)\n",
      "\t__237__2 = torch.Tensor.size(__230_x7,1)\n",
      "\t__243_fv = [__235__0,__237__2,768]\n",
      "\t__244_fv = torch.Tensor.view(__240_x0,__243_fv)\n",
      "\t__163_x = torch.add(__117_input,__244_fv)\n",
      "\t__161_x = torch.layer_norm(__117_input,[768],self.h[0].ln_2.weight,self.h[0].ln_2.bias)\n",
      "\t__256__4 = torch.Tensor.size(__161_x,-1)\n",
      "\t__258_fv = [-1,__256__4]\n",
      "\t__259_fv = torch.Tensor.view(__161_x,__258_fv)\n",
      "\t__257_x = torch.addmm(self.h[0].feedforward.c_fc.bias,__259_fv,self.h[0].feedforward.c_fc.weight)\n",
      "\t__252__0 = torch.Tensor.size(__161_x,0)\n",
      "\t__254__2 = torch.Tensor.size(__161_x,1)\n",
      "\t__260_fv = [__252__0,__254__2,3072]\n",
      "\t__261_fv = torch.Tensor.view(__257_x,__260_fv)\n",
      "\t__249_x = torch.nn.functional.gelu(__261_fv)\n",
      "\t__269__4 = torch.Tensor.size(__249_x,-1)\n",
      "\t__271_fv = [-1,__269__4]\n",
      "\t__272_fv = torch.Tensor.view(__249_x,__271_fv)\n",
      "\t__270_x0 = torch.addmm(self.h[0].feedforward.c_proj.bias,__272_fv,self.h[0].feedforward.c_proj.weight)\n",
      "\t__265__0 = torch.Tensor.size(__249_x,0)\n",
      "\t__267__2 = torch.Tensor.size(__249_x,1)\n",
      "\t__273_fv = [__265__0,__267__2,768]\n",
      "\t__274_fv = torch.Tensor.view(__270_x0,__273_fv)\n",
      "\t__275__0 = torch.dropout(__274_fv,0.1,False)\n",
      "\t__245_input = torch.add(__163_x,__275__0)\n",
      "\t__278_input = torch.layer_norm(__245_input,[768],self.ln_f.weight,self.ln_f.bias)\n",
      "\t__280_fv = torch.nn.functional.linear(__278_input,self.wte.weight)\n",
      "\treturn __280_fv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16439/4289802552.py:43: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head)\n"
     ]
    }
   ],
   "source": [
    "jit_tr_GPT2 = torch.jit.trace_module(model, inputs={\"forward\":context1},check_trace=False)\n",
    "print(getattr(getattr(jit_tr_GPT2,\"h\"),\"0\").code)\n",
    "reload(read_trace_code)\n",
    "reload(Btools)\n",
    "GPT2mod_Bg = read_trace_code.main(model,(context1,),show_debug=True)\n",
    "GPT2mod_Dg = Btools.B_to_D(GPT2mod_Bg)\n",
    "Btools.print_code(GPT2mod_Dg)\n",
    "#print(Btools.test_code(GPT2mod_Dg,model,{\"src\":context1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db982be3-9967-49ac-9bc4-a0cd818219a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Deterministic GPT2 from scratch n_layer=1, tests OK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2800776-bfd0-400b-9e6f-281a0cc48072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv1D(nn.Module):\n",
    "    def __init__(self, nx, nf):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        w = torch.empty(nx, nf)\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "        x = x.view(size_out)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dropout, d_model=768, nx=768*4):\n",
    "        super().__init__()\n",
    "        self.c_fc    = Conv1D(d_model, nx)\n",
    "        self.c_proj  = Conv1D(nx, d_model)\n",
    "        self.act     = F.gelu\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.c_proj(self.act(self.c_fc(x))))\n",
    "    \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, n_ctx=1024, d_head=64, bias=True, scale=False, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_head  = n_head\n",
    "        self.d_model = d_model\n",
    "        self.c_attn  = Conv1D(d_model, d_model*3)\n",
    "        self.scale   = scale\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.c_proj  = Conv1D(d_model, d_model)\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        \"return shape [`batch`, `head`, `sequence`, `features`]\"\n",
    "        new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head) \n",
    "        x = x.view(new_shape)\n",
    "        return x.permute(0, 2, 1, 3) \n",
    "    \n",
    "    def _attn(self, q, k, v, attn_mask=None):\n",
    "        scores  = torch.matmul(q, k.transpose(-2, -1))\n",
    "        if self.scale: scores = scores/math.sqrt(v.size(-1))\n",
    "        nd, ns  = scores.size(-2), scores.size(-1)\n",
    "        if attn_mask is not None: scores = scores + attn_mask\n",
    "        scores  = self.softmax(scores)\n",
    "        scores  = self.dropout(scores)\n",
    "        outputs = torch.matmul(scores, v)\n",
    "        return outputs\n",
    "    \n",
    "    def merge_heads(self, x):\n",
    "        x         = x.permute(0, 2, 1, 3).contiguous()\n",
    "        new_shape = x.size()[:-2] + (x.size(-2)*x.size(-1),)\n",
    "        return x.view(new_shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x        = self.c_attn(x) #new `x` shape - `[1,3,2304]`\n",
    "        q, k, v  = x.split(self.d_model, dim=2)\n",
    "        q, k, v  = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "        # out      = self._attn(q, k, v)\n",
    "        scores  = torch.matmul(q, k.transpose(-2, -1))\n",
    "        # if self.scale: scores = scores/math.sqrt(v.size(-1))\n",
    "        nd, ns  = scores.size(-2), scores.size(-1)\n",
    "        # if attn_mask is not None: scores = scores + attn_mask\n",
    "        scores  = self.softmax(scores)\n",
    "        scores  = self.dropout(scores)\n",
    "        out = torch.matmul(scores, v)\n",
    "        \n",
    "        out      = self.merge_heads(out)\n",
    "        out      = self.c_proj(out)\n",
    "        return out\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn        = Attention(d_model=d_model, n_head=n_head, d_head=64, n_ctx=1024, bias=True, scale=False, dropout=dropout)\n",
    "        self.feedforward = FeedForward(dropout=dropout, d_model=d_model, nx=d_model*4)\n",
    "        self.ln_1        = LayerNorm(d_model)\n",
    "        self.ln_2        = LayerNorm(d_model)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x1 = self.ln_1(x)\n",
    "        x2 = self.ln_2(x)\n",
    "        x = x + self.attn(x1)\n",
    "        x = x + self.feedforward(x2)\n",
    "        return x\n",
    "    \n",
    "def _get_clones(module, n):\n",
    "    return ModuleList([copy.deepcopy(module) for i in range(n)])\n",
    "\n",
    "class GPT2(nn.Module):\n",
    "    def __init__(self, nlayers=12, n_ctx=1024, d_model=768, vcb_sz=50257, dropout=0.1):\n",
    "        super(GPT2, self).__init__()\n",
    "        self.nlayers = nlayers\n",
    "        block        = TransformerBlock(d_model=d_model, n_head=12, dropout=dropout)\n",
    "        self.h       = _get_clones(block, nlayers)\n",
    "        self.wte     = nn.Embedding(vcb_sz, d_model)\n",
    "        self.wpe     = nn.Embedding(n_ctx, d_model)\n",
    "        self.drop    = nn.Dropout(dropout)\n",
    "        self.ln_f    = LayerNorm(d_model)\n",
    "        self.out     = nn.Linear(d_model, vcb_sz, bias=False)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.out.weight = self.wte.weight\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding, Conv1D)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if isinstance(module, (nn.Linear, Conv1D)) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, src, labels=None, pos_ids=None, return_inp=False, dropout=0.1):\n",
    "        if pos_ids is None: pos_ids = torch.arange(0, src.size(-1)).unsqueeze(0)\n",
    "        inp = self.drop((self.wte(src)+self.wpe(pos_ids)))\n",
    "        if return_inp: return inp \n",
    "        for i in range(self.nlayers): inp = self.h[0](inp)\n",
    "        inp     = self.ln_f(inp)\n",
    "        logits  = self.out(inp)\n",
    "        outputs = (logits,) + (inp,)\n",
    "        \n",
    "        if labels is not None:\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            loss = self.loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "            return outputs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba3c7b2f-935e-4cbd-aff3-58f85811a27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "def main(src):\n",
      "\t__16_fv = torch.embedding(self.wte.weight,src)\n",
      "\t__10__1 = torch.Tensor.size(src,-1)\n",
      "\t__11__2 = torch.arange(0,__10__1,1,dtype = None,device = torch.device(\"cpu\"),pin_memory = False)\n",
      "\t__13_input = torch.unsqueeze(__11__2,0)\n",
      "\t__18_fv = torch.embedding(self.wpe.weight,__13_input)\n",
      "\t__14_input0 = torch.add(__16_fv,__18_fv)\n",
      "\t__20_fv = torch.dropout(__14_input0,0.0,False)\n",
      "\t__28_x = torch.layer_norm(__20_fv,[768],self.h[0].ln_1.weight,self.h[0].ln_1.bias)\n",
      "\t__47__4 = torch.Tensor.size(__28_x,-1)\n",
      "\t__49_fv = [-1,__47__4]\n",
      "\t__50_fv = torch.Tensor.view(__28_x,__49_fv)\n",
      "\t__48_x = torch.addmm(self.h[0].attn.c_attn.bias,__50_fv,self.h[0].attn.c_attn.weight)\n",
      "\t__43__0 = torch.Tensor.size(__28_x,0)\n",
      "\t__45__2 = torch.Tensor.size(__28_x,1)\n",
      "\t__51_fv = [__43__0,__45__2,2304]\n",
      "\t__52_fv = torch.Tensor.view(__48_x,__51_fv)\n",
      "\t__40__0 = torch.split(__52_fv,768,2)\n",
      "\t__54_x = __40__0[0]\n",
      "\t__57__1 = torch.Tensor.size(__54_x,0)\n",
      "\t__59__3 = torch.Tensor.size(__54_x,1)\n",
      "\t__61__5 = torch.Tensor.size(__54_x,-1)\n",
      "\t__62__6 = torch.div(__61__5,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__64_fv = [__57__1,__59__3,12,__62__6]\n",
      "\t__63_x2 = torch.Tensor.view(__54_x,__64_fv)\n",
      "\t__65_q = torch.permute(__63_x2,[0,2,1,3])\n",
      "\t__55_x0 = __40__0[1]\n",
      "\t__67__7 = torch.Tensor.size(__55_x0,0)\n",
      "\t__69__9 = torch.Tensor.size(__55_x0,1)\n",
      "\t__71__11 = torch.Tensor.size(__55_x0,-1)\n",
      "\t__72__12 = torch.div(__71__11,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__74_fv = [__67__7,__69__9,12,__72__12]\n",
      "\t__73_x3 = torch.Tensor.view(__55_x0,__74_fv)\n",
      "\t__75_k = torch.permute(__73_x3,[0,2,1,3])\n",
      "\t__88_fv = torch.transpose(__75_k,-2,-1)\n",
      "\t__87_scores = torch.matmul(__65_q,__88_fv)\n",
      "\t__90_fv = torch.softmax(__87_scores,-1)\n",
      "\t__91_fv = torch.dropout(__90_fv,0.0,False)\n",
      "\t__56_x1 = __40__0[2]\n",
      "\t__77__13 = torch.Tensor.size(__56_x1,0)\n",
      "\t__79__15 = torch.Tensor.size(__56_x1,1)\n",
      "\t__81__17 = torch.Tensor.size(__56_x1,-1)\n",
      "\t__82__18 = torch.div(__81__17,tensor(12),rounding_mode = \"trunc\")\n",
      "\t__84_fv = [__77__13,__79__15,12,__82__18]\n",
      "\t__83_x4 = torch.Tensor.view(__56_x1,__84_fv)\n",
      "\t__85_v = torch.permute(__83_x4,[0,2,1,3])\n",
      "\t__92_x5 = torch.matmul(__91_fv,__85_v)\n",
      "\t__95_fv = torch.permute(__92_x5,[0,2,1,3])\n",
      "\t__93_x6 = torch.Tensor.contiguous(__95_fv)\n",
      "\t__96__20 = torch.Tensor.size(__93_x6,0)\n",
      "\t__98__22 = torch.Tensor.size(__93_x6,1)\n",
      "\t__100__24 = torch.Tensor.size(__93_x6,-2)\n",
      "\t__101__25 = torch.Tensor.size(__93_x6,-1)\n",
      "\t__104_fv = torch.mul(__100__24,__101__25)\n",
      "\t__103_fv = [__96__20,__98__22,__104_fv]\n",
      "\t__102_x7 = torch.Tensor.view(__93_x6,__103_fv)\n",
      "\t__111__4 = torch.Tensor.size(__102_x7,-1)\n",
      "\t__113_fv = [-1,__111__4]\n",
      "\t__114_fv = torch.Tensor.view(__102_x7,__113_fv)\n",
      "\t__112_x0 = torch.addmm(self.h[0].attn.c_proj.bias,__114_fv,self.h[0].attn.c_proj.weight)\n",
      "\t__107__0 = torch.Tensor.size(__102_x7,0)\n",
      "\t__109__2 = torch.Tensor.size(__102_x7,1)\n",
      "\t__115_fv = [__107__0,__109__2,768]\n",
      "\t__116_fv = torch.Tensor.view(__112_x0,__115_fv)\n",
      "\t__35_x = torch.add(__20_fv,__116_fv)\n",
      "\t__33_x = torch.layer_norm(__20_fv,[768],self.h[0].ln_2.weight,self.h[0].ln_2.bias)\n",
      "\t__128__4 = torch.Tensor.size(__33_x,-1)\n",
      "\t__130_fv = [-1,__128__4]\n",
      "\t__131_fv = torch.Tensor.view(__33_x,__130_fv)\n",
      "\t__129_x = torch.addmm(self.h[0].feedforward.c_fc.bias,__131_fv,self.h[0].feedforward.c_fc.weight)\n",
      "\t__124__0 = torch.Tensor.size(__33_x,0)\n",
      "\t__126__2 = torch.Tensor.size(__33_x,1)\n",
      "\t__132_fv = [__124__0,__126__2,3072]\n",
      "\t__133_fv = torch.Tensor.view(__129_x,__132_fv)\n",
      "\t__121_x = torch.nn.functional.gelu(__133_fv)\n",
      "\t__141__4 = torch.Tensor.size(__121_x,-1)\n",
      "\t__143_fv = [-1,__141__4]\n",
      "\t__144_fv = torch.Tensor.view(__121_x,__143_fv)\n",
      "\t__142_x0 = torch.addmm(self.h[0].feedforward.c_proj.bias,__144_fv,self.h[0].feedforward.c_proj.weight)\n",
      "\t__137__0 = torch.Tensor.size(__121_x,0)\n",
      "\t__139__2 = torch.Tensor.size(__121_x,1)\n",
      "\t__145_fv = [__137__0,__139__2,768]\n",
      "\t__146_fv = torch.Tensor.view(__142_x0,__145_fv)\n",
      "\t__147_fv = torch.dropout(__146_fv,0.0,False)\n",
      "\t__117_input = torch.add(__35_x,__147_fv)\n",
      "\t__151_input = torch.layer_norm(__117_input,[768],self.ln_f.weight,self.ln_f.bias)\n",
      "\t__153_fv = torch.nn.functional.linear(__151_input,self.wte.weight)\n",
      "\treturn __153_fv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16439/4289802552.py:43: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head)\n"
     ]
    }
   ],
   "source": [
    "model2 = GPT2(nlayers=1,dropout=0)\n",
    "model2.eval()\n",
    "reload(read_trace_code)\n",
    "reload(Btools)\n",
    "GPT2mod_Bg2 = read_trace_code.main(model2,(context1,))\n",
    "GPT2mod_Dg2 = Btools.B_to_D(GPT2mod_Bg2)\n",
    "Btools.print_code(GPT2mod_Dg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "850c37f7-7c07-4cb0-9552-3f3f2b52ef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Input given to trace ====\n",
      "== original module ==\n",
      "tensor([[[ 0.2554,  0.6872,  0.2827,  ..., -0.7994, -0.1798,  0.0058],\n",
      "         [ 0.0950, -0.6459,  0.2680,  ..., -0.8535,  0.4181,  0.4415],\n",
      "         [-0.4555, -0.4671, -0.8191,  ..., -0.7316,  0.7050,  0.3359]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "== inlined one ==\n",
      "tensor([[[ 0.2554,  0.6872,  0.2827,  ..., -0.7994, -0.1798,  0.0058],\n",
      "         [ 0.0950, -0.6459,  0.2680,  ..., -0.8535,  0.4181,  0.4415],\n",
      "         [-0.4555, -0.4671, -0.8191,  ..., -0.7316,  0.7050,  0.3359]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "==== Different input ====\n",
      "== original module ==\n",
      "tensor([[[ 0.4519,  0.2199,  0.5297,  ..., -0.5190,  0.1597,  0.1830],\n",
      "         [ 0.5211, -1.0295,  0.2236,  ..., -1.2898, -0.3731, -0.3505],\n",
      "         [-0.7956,  0.0936,  0.2735,  ..., -0.7342,  0.4147, -1.4049],\n",
      "         [ 0.1327,  0.2959,  0.1717,  ..., -0.2245,  0.3296,  0.5362],\n",
      "         [ 0.2036,  1.0526, -0.4413,  ..., -0.4234,  0.8908, -0.7402],\n",
      "         [ 0.3833,  0.0731,  0.3802,  ..., -0.3899,  0.9771, -0.5826]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "== inlined one ==\n",
      "tensor([[[ 0.4519,  0.2199,  0.5297,  ..., -0.5190,  0.1597,  0.1830],\n",
      "         [ 0.5211, -1.0295,  0.2236,  ..., -1.2898, -0.3731, -0.3505],\n",
      "         [-0.7956,  0.0936,  0.2735,  ..., -0.7342,  0.4147, -1.4049],\n",
      "         [ 0.1327,  0.2959,  0.1717,  ..., -0.2245,  0.3296,  0.5362],\n",
      "         [ 0.2036,  1.0526, -0.4413,  ..., -0.4234,  0.8908, -0.7402],\n",
      "         [ 0.3833,  0.0731,  0.3802,  ..., -0.3899,  0.9771, -0.5826]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "=== max diff ===\n",
      "tensor(0., grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "reload(Btools)\n",
    "print(\"==== Input given to trace ====\")\n",
    "print(\"== original module ==\")\n",
    "print(model2.forward(context1))\n",
    "print(\"== inlined one ==\")\n",
    "print(Btools.test_code(GPT2mod_Dg2,model2,{\"src\":context1}))\n",
    "print(\"==== Different input ====\")\n",
    "print(\"== original module ==\")\n",
    "print(model2.forward(context2))\n",
    "print(\"== inlined one ==\")\n",
    "print(Btools.test_code(GPT2mod_Dg2,model2,{\"src\":context2}))\n",
    "print(\"=== max diff ===\")\n",
    "print(torch.max(torch.abs(model2.forward(context2) - Btools.test_code(GPT2mod_Dg2,model2,{\"src\":context2}))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c2636-0ce4-4d0f-ba84-5a975a5e424f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# small ex with random operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4f6cd09-8675-4684-ac70-600223244d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMod2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(128,128)\n",
    "    def forward(self,x):\n",
    "        a = torch.randn(x.shape)\n",
    "        return self.lin(x) + a + a\n",
    "mymod2 = MyMod2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9474ddd-9637-4b8d-9892-b7087da928db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x) : [INPUT] : x = INPUT\n",
      "(__2__0) : [torch.Tensor.size] : __2__0 = torch.Tensor.size(x,0)\n",
      "(__4__2) : [torch.Tensor.size] : __4__2 = torch.Tensor.size(x,1)\n",
      "(__6_fv) : [list constructor] : __6_fv = [__2__0,__4__2]\n",
      "(__5_a) : [torch.randn] : __5_a = torch.randn(__6_fv,device = torch.device(\"cpu\"),pin_memory = False)\n",
      "(__7_fv) : [torch.device] : __7_fv = torch.device(\"cpu\")\n",
      "(__11_fv) : [torch.nn.functional.linear] : __11_fv = torch.nn.functional.linear(x,self.lin.weight,self.lin.bias)\n",
      "(__12_fv) : [torch.add] : __12_fv = torch.add(__11_fv,__5_a)\n",
      "(__8__3) : [torch.add] : __8__3 = torch.add(__12_fv,__5_a)\n",
      "{}\n",
      "def main(x):\n",
      "\t__11_fv = torch.nn.functional.linear(x,self.lin.weight,self.lin.bias)\n",
      "\t__2__0 = torch.Tensor.size(x,0)\n",
      "\t__4__2 = torch.Tensor.size(x,1)\n",
      "\t__6_fv = [__2__0,__4__2]\n",
      "\t__5_a = torch.randn(__6_fv,device = torch.device(\"cpu\"),pin_memory = False)\n",
      "\t__12_fv = torch.add(__11_fv,__5_a)\n",
      "\t__8__3 = torch.add(__12_fv,__5_a)\n",
      "\treturn __8__3\n"
     ]
    }
   ],
   "source": [
    "reload(read_trace_code)\n",
    "reload(Btools)\n",
    "mymod2_Bg = read_trace_code.main(mymod2,(src_mymod.reshape([1,-1]),))\n",
    "Btools.print_all_nodes(mymod2_Bg)\n",
    "mymod2_Dg = Btools.B_to_D(mymod2_Bg)\n",
    "Btools.print_code(mymod2_Dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55ad6600-7cc7-4d28-9f90-81b9dae62609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Original module ==\n",
      "tensor([ 109.5877,  -16.9878, -108.7730,   90.9153, -121.8676,  -25.9335,\n",
      "         153.3468,  -78.8924,   31.2294,  136.2355, -179.5932, -105.4476,\n",
      "          51.3675,  -64.3355,  -33.6735,  173.4930,   91.6603, -167.5324,\n",
      "         181.0147,   -6.6440], grad_fn=<SliceBackward0>)\n",
      "== Through D_graph ==\n",
      "tensor([ 109.5877,  -16.9878, -108.7730,   90.9153, -121.8676,  -25.9335,\n",
      "         153.3468,  -78.8924,   31.2294,  136.2355, -179.5932, -105.4476,\n",
      "          51.3675,  -64.3355,  -33.6735,  173.4930,   91.6603, -167.5324,\n",
      "         181.0147,   -6.6440], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "reload(Btools)\n",
    "print(\"== Original module ==\")\n",
    "torch.manual_seed(1515)\n",
    "print(mymod(src_mymod)[:20])\n",
    "print(\"== Through D_graph ==\")\n",
    "torch.manual_seed(1515)\n",
    "print(Btools.test_code(mymod_Dg,mymod,{\"x\":src_mymod})[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15ed42-a0eb-45ac-be00-867fc9c65738",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# graph test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22ca60da-f9ba-4454-8487-21f7cc05b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(evince:12087): dbind-WARNING **: 11:47:09.040: Couldn't connect to accessibility bus: Failed to connect to socket /run/user/1000/at-spi/bus: Permission denied\n"
     ]
    }
   ],
   "source": [
    "reload(Btools)\n",
    "Btools.print_graph(mymod_Dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18682e9b-acfa-445f-9dc4-4f7926e4cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Btools.print_graph(modtf_Dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acae244e-4371-4e07-ad3a-8a6cc177d548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(evince:20656): dbind-WARNING **: 18:24:28.207: Couldn't connect to accessibility bus: Failed to connect to socket /run/user/1000/at-spi/bus: Permission denied\n"
     ]
    }
   ],
   "source": [
    "Btools.print_graph(GPT2mod_Dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302bbfc-f807-4875-b35a-3dcac68faf44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
